{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zongheng/anaconda/envs/ray-0321/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "# TODO(zongheng): visualization via tensorboard.\n",
    "# TODO(zongheng): print some prediction from test set\n",
    "\n",
    "dropout_keepprob = None\n",
    "\n",
    "# With gaussian weights.\n",
    "# 500 training pts; 1000 testing.\n",
    "PATH = \"5rel-10numAttrs-22totalAttrs-100maxTblSize-10buckets-3000.csv\"\n",
    "NUM_FIELDS = 34\n",
    "TRAIN_PATH = \"data/train-{}\".format(PATH)\n",
    "TEST_PATH = \"data/test-{}\".format(PATH)\n",
    "net = [64,64]; lr =  1e-3\n",
    "batch_size = 500\n",
    "num_steps = 5500\n",
    "\n",
    "# With 5 random op types.\n",
    "PATH = \"5rel-10numAttrs-28totalAttrs-100maxTblSize-10buckets-3000-1526330982.csv\"\n",
    "NUM_FIELDS = 40\n",
    "TRAIN_PATH = \"data/train-{}\".format(PATH)\n",
    "TEST_PATH = \"data/test-{}\".format(PATH)\n",
    "net = [128,128]; lr =  5e-3\n",
    "batch_size = 1024\n",
    "\n",
    "# 5 random op types.  Larger maxTblSize & buckets. \n",
    "PATH = \"5rel-10numAttrs-24totalAttrs-1000maxTblSize-100buckets-3000-1526336271.csv\"\n",
    "NUM_FIELDS = 36\n",
    "TRAIN_PATH = \"data/train-{}\".format(PATH)\n",
    "TEST_PATH = \"data/test-{}\".format(PATH)\n",
    "net = [128,128]; lr =  3e-3\n",
    "lr_bounds = [2000, 6000,]; lr_vals = [3e-3, 1e-3, 5e-4]\n",
    "batch_size = 512\n",
    "dropout_keepprob = 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1526336271\n",
    "no whitening, net = [128,128]; lr =  3e-3; batch_size = 512; dropout_keepprob = 0.9\n",
    "![sup](./1.png)\n",
    "lr_bounds = [2000, 6000,]; lr_vals = [3e-3, 1e-3, 5e-4]\n",
    "![inf](./2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tf.float32, tf.float32)\n",
      "(TensorShape([Dimension(None), Dimension(35)]), TensorShape([Dimension(None)]))\n",
      "(tf.float32, tf.float32)\n",
      "(TensorShape([Dimension(None), Dimension(35)]), TensorShape([Dimension(None)]))\n"
     ]
    }
   ],
   "source": [
    "def DatasetFromPath(pathname):\n",
    "    dataset = tf.data.TextLineDataset(pathname)\n",
    "\n",
    "    def ParseLine(line):\n",
    "        fields = tf.decode_csv(line, [[0.0]] * NUM_FIELDS)\n",
    "        # Last number is label.\n",
    "        return tf.reshape(tf.stack(fields[:-1]), [-1]), fields[-1]\n",
    "\n",
    "    def MeanCenterBatch(feat, lab):\n",
    "        feat_mean, feat_var = tf.nn.moments(feat, axes=[0])\n",
    "        lab_mean, lab_var = tf.nn.moments(lab, axes=[0])\n",
    "        feat = (feat - feat_mean) / (tf.sqrt(feat_var) + 1e-8)\n",
    "        lab = (lab - lab_mean) / (tf.sqrt(lab_var) + 1e-8)\n",
    "        return feat, lab\n",
    "    \n",
    "#     # K-point dataset, for sanity checking.\n",
    "#     K = 10\n",
    "#     dataset = dataset.take(K).map(ParseLine)\n",
    "#     dataset = dataset.shuffle(20000, reshuffle_each_iteration=False) \\\n",
    "#         .batch(K).map(MeanCenterBatch) \\\n",
    "#         .repeat()\n",
    "\n",
    "    dataset = dataset.map(ParseLine).cache()\n",
    "    dataset = dataset.shuffle(20000, reshuffle_each_iteration=True) \\\n",
    "        .repeat() \\\n",
    "        .batch(batch_size) #\\\n",
    "#         .map(MeanCenterBatch) \n",
    "\n",
    "    print(dataset.output_types)\n",
    "    print(dataset.output_shapes)\n",
    "    return dataset\n",
    "\n",
    "# Train.\n",
    "dataset = DatasetFromPath(TRAIN_PATH)\n",
    "iterator = tf.data.Iterator.from_structure(\n",
    "    dataset.output_types, dataset.output_shapes)\n",
    "iterator_init = iterator.make_initializer(dataset)\n",
    "# Test.\n",
    "test_dataset = DatasetFromPath(TEST_PATH)\n",
    "test_iterator_init = iterator.make_initializer(test_dataset)\n",
    "# Shared.\n",
    "feature_batch, label_batch = iterator.get_next()\n",
    "\n",
    "    \n",
    "\n",
    "# mean, var = tf.nn.moments(feature_batch, axes=[0])\n",
    "# feature_batch = (feature_batch - mean) / tf.sqrt(var)\n",
    "# mean, var = tf.nn.moments(label_batch, axes=[0])\n",
    "# label_batch = (label_batch - mean) / var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'learning_rate:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def manual_stepping(global_step, boundaries, rates):\n",
    "  \"\"\"Manually stepped learning rate schedule.\n",
    "\n",
    "  This function provides fine grained control over learning rates.  One must\n",
    "  specify a sequence of learning rates as well as a set of integer steps\n",
    "  at which the current learning rate must transition to the next.  For example,\n",
    "  if boundaries = [5, 10] and rates = [.1, .01, .001], then the learning\n",
    "  rate returned by this function is .1 for global_step=0,...,4, .01 for\n",
    "  global_step=5...9, and .001 for global_step=10 and onward.\n",
    "\n",
    "  Args:\n",
    "    global_step: int64 (scalar) tensor representing global step.\n",
    "    boundaries: a list of global steps at which to switch learning\n",
    "      rates.  This list is assumed to consist of increasing positive integers.\n",
    "    rates: a list of (float) learning rates corresponding to intervals between\n",
    "      the boundaries.  The length of this list must be exactly\n",
    "      len(boundaries) + 1.\n",
    "\n",
    "  Returns:\n",
    "    a (scalar) float tensor representing learning rate\n",
    "  Raises:\n",
    "    ValueError: if one of the following checks fails:\n",
    "      1. boundaries is a strictly increasing list of positive integers\n",
    "      2. len(rates) == len(boundaries) + 1\n",
    "  \"\"\"\n",
    "  if any([b < 0 for b in boundaries]) or any(\n",
    "      [not isinstance(b, int) for b in boundaries]):\n",
    "    raise ValueError('boundaries must be a list of positive integers')\n",
    "  if any([bnext <= b for bnext, b in zip(boundaries[1:], boundaries[:-1])]):\n",
    "    raise ValueError('Entries in boundaries must be strictly increasing.')\n",
    "  if any([not isinstance(r, float) for r in rates]):\n",
    "    raise ValueError('Learning rates must be floats')\n",
    "  if len(rates) != len(boundaries) + 1:\n",
    "    raise ValueError('Number of provided learning rates must exceed '\n",
    "                     'number of boundary points by exactly 1.')\n",
    "  step_boundaries = tf.constant(boundaries, tf.int64)\n",
    "  learning_rates = tf.constant(rates, tf.float32)\n",
    "  unreached_boundaries = tf.reshape(\n",
    "      tf.where(tf.greater(step_boundaries, global_step)), [-1])\n",
    "  unreached_boundaries = tf.concat([unreached_boundaries, [len(boundaries)]], 0)\n",
    "  index = tf.reshape(tf.reduce_min(unreached_boundaries), [1])\n",
    "  return tf.reshape(tf.slice(learning_rates, index, [1]), [])\n",
    "\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "lr = manual_stepping(global_step, lr_bounds, lr_vals)\n",
    "\n",
    "# lr = tf.train.exponential_decay(learning_rate=1e-3, \n",
    "#                                 global_step=global_step, \n",
    "#                                 decay_steps=5000, \n",
    "#                                 decay_rate=0.9, \n",
    "#                                 staircase=True)\n",
    "# lr = 1e-3\n",
    "tf.summary.scalar('learning_rate', lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zongheng/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "out Tensor(\"dense_2/BiasAdd:0\", shape=(?, 1), dtype=float32) label_batch Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=float32)\n",
      "INFO:tensorflow:Summary name Train Loss is illegal; using Train_Loss instead.\n",
      "INFO:tensorflow:Summary name dense/kernel:0 is illegal; using dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense/bias:0 is illegal; using dense/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0 is illegal; using dense_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0 is illegal; using dense_2/bias_0 instead.\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Graph definition.\n",
    "dense = feature_batch\n",
    "for i in range(len(net)):\n",
    "    dense = tf.layers.dense(\n",
    "        dense,\n",
    "        net[i],\n",
    "#         kernel_initializer=tf.truncated_normal_initializer(stddev=20.0),\n",
    "#         kernel_initializer=tf.initializers.variance_scaling(scale=10.0),\n",
    "        kernel_initializer=tf.initializers.variance_scaling(),\n",
    "#         kernel_initializer=tf.initializers.orthogonal(),\n",
    "#         kernel_initializer=tf.initializers.uniform_unit_scaling(),\n",
    "#         kernel_initializer=tf.initializers.random_normal(stddev=10),\n",
    "#         kernel_initializer=tf.initializers.random_uniform(-100, 100),\n",
    "#         kernel_initializer=tf.initializers.zeros(),\n",
    "#         bias_initializer=tf.initializers.zeros(),\n",
    "#         activation=tf.nn.sigmoid,\n",
    "        activation=tf.nn.relu,\n",
    "#         activation=tf.nn.tanh,\n",
    "    )\n",
    "    if dropout_keepprob is not None:\n",
    "        dense = tf.nn.dropout(dense, dropout_keepprob, seed=1234)\n",
    "out = tf.layers.dense(\n",
    "    dense,\n",
    "    1,\n",
    "#         kernel_initializer=tf.truncated_normal_initializer(stddev=20.0),\n",
    "#         kernel_initializer=tf.initializers.variance_scaling(scale=10.0),\n",
    "#         kernel_initializer=tf.initializers.orthogonal(),\n",
    "#         kernel_initializer=tf.initializers.uniform_unit_scaling(),\n",
    "#         kernel_initializer=tf.initializers.random_normal(stddev=10),\n",
    "        kernel_initializer=tf.initializers.variance_scaling(),\n",
    "#         kernel_initializer=tf.initializers.random_uniform(-100, 100),\n",
    "#         kernel_initializer=tf.initializers.zeros(),\n",
    "#         bias_initializer=tf.initializers.zeros(),\n",
    ")\n",
    "\n",
    "\n",
    "all_vars = tf.trainable_variables()\n",
    "regularizer = tf.contrib.layers.l1_regularizer(scale=0.0)  # TODO: scale=?\n",
    "# regularizer = tf.contrib.layers.l1_l2_regularizer()\n",
    "regularization_penalty = tf.contrib.layers.apply_regularization(\n",
    "    regularizer, all_vars)\n",
    "print('out', out, 'label_batch', label_batch)\n",
    "# NOTE: critical to reshape / or keep the order correct...\n",
    "# out: [B, 1]\n",
    "# label_batch [B]\n",
    "# loss = tf.reduce_mean(tf.square(out - label_batch))\n",
    "# loss = tf.reduce_mean(tf.square(out - label_batch)) \n",
    "loss = tf.reduce_mean(tf.abs(\n",
    "    tf.reshape(out,[-1]) - label_batch)) + regularization_penalty\n",
    "\n",
    "# loss = tf.reduce_mean(tf.abs(tf.reshape(out,[-1]) - label_batch))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train_step = optimizer.minimize(\n",
    "    loss, global_step=global_step)\n",
    "\n",
    "# For visualization.\n",
    "tf.summary.scalar('Train Loss', loss)\n",
    "for v in all_vars:\n",
    "    tf.summary.histogram(v.name, v)\n",
    "all_vars_norms = [tf.norm(v) for v in all_vars]\n",
    "print(len(all_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt-9224\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 9224 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 9225 , loss 26.554825\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    1.    0.    0.    4.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    1.  617.]]\n",
      " true labels train [  97.  100.  208.    1. 1000.  952.   75.  473.  847.    1.]\n",
      " pred labels train [1.1651e+02 1.1014e+02 2.1713e+02 1.1369e+00 9.7329e+02 7.4121e+02\n",
      " 3.4838e+01 4.6547e+02 8.5836e+02 3.2353e-01]\n",
      " all vars norms [135.10675, 0.53609526, 32.9421, 7.4531474, 11.071078, 0.7830061]\n",
      "global_step 9325 , loss 20.776258\n",
      "global_step 9425 , loss 23.882273\n",
      "global_step 9525 , loss 24.182053\n",
      "global_step 9625 , loss 22.547764\n",
      "global_step 9725 , loss 22.21477\n",
      "global_step 9825 , loss 21.461369\n",
      "global_step 9925 , loss 25.023336\n",
      "global_step 10025 , loss 22.31891\n",
      "global_step 10125 , loss 24.12255\n",
      "global_step 10225 , loss 26.004494\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  239.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  299.]]\n",
      " true labels train [246.   9. 100.  43.   1. 595. 611.  10.  71.   2.]\n",
      " pred labels train [2.3768e+02 9.5524e+00 8.3449e+01 5.9156e+00 3.0395e+00 6.3896e+02\n",
      " 6.2351e+02 8.9180e+00 7.4289e+01 5.3990e-01]\n",
      " all vars norms [136.08775, 0.5357, 34.644596, 7.7393966, 11.5609455, 0.8270284]\n",
      "global_step 10325 , loss 18.909576\n",
      "global_step 10425 , loss 21.886826\n",
      "global_step 10525 , loss 21.854218\n",
      "global_step 10625 , loss 25.69411\n",
      "global_step 10725 , loss 22.609417\n",
      "global_step 10825 , loss 22.756685\n",
      "global_step 10925 , loss 19.82999\n",
      "global_step 11025 , loss 21.48665\n",
      "global_step 11125 , loss 19.425165\n",
      "global_step 11225 , loss 24.74488\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  472.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  921.]]\n",
      " true labels train [521.   1.  11.  14.   1.  12.  83.  14. 287. 380.]\n",
      " pred labels train [535.7532   0.857    8.5062  10.4758   1.2034  10.8454  82.8631  11.9262\n",
      " 271.2109 370.6861]\n",
      " all vars norms [136.98474, 0.53547233, 36.364277, 8.005879, 11.994985, 0.86911666]\n",
      "global_step 11325 , loss 21.614763\n",
      "global_step 11425 , loss 21.503405\n",
      "global_step 11525 , loss 23.519285\n",
      "global_step 11625 , loss 20.147522\n",
      "global_step 11725 , loss 21.223095\n",
      "global_step 11825 , loss 20.734734\n",
      "global_step 11925 , loss 25.152685\n",
      "global_step 12025 , loss 21.185585\n",
      "global_step 12125 , loss 21.769604\n",
      "global_step 12225 , loss 18.771597\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  286.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  886.]]\n",
      " true labels train [271. 133. 438.   8. 100. 100.   9.  13.  14.  10.]\n",
      " pred labels train [255.9364 125.1177 411.8427   9.456   85.1109 138.4285   4.0164  17.0701\n",
      "  13.37     6.8378]\n",
      " all vars norms [137.89166, 0.53607726, 38.12129, 8.263881, 12.400871, 0.9158098]\n",
      "global_step 12325 , loss 17.991581\n",
      "global_step 12425 , loss 21.887169\n",
      "global_step 12525 , loss 19.583733\n",
      "global_step 12625 , loss 20.456781\n",
      "global_step 12725 , loss 20.15438\n",
      "global_step 12825 , loss 20.043808\n",
      "global_step 12925 , loss 21.449753\n",
      "global_step 13025 , loss 18.533997\n",
      "global_step 13125 , loss 19.459536\n",
      "global_step 13225 , loss 18.50517\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   81.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   82.]]\n",
      " true labels train [108.   1.   1.  10. 902.  14. 486. 617. 859.   1.]\n",
      " pred labels train [1.6958e+02 3.0903e-01 1.0896e+00 8.5183e+00 8.9894e+02 1.1229e+01\n",
      " 5.1162e+02 6.4335e+02 8.3132e+02 1.1586e+00]\n",
      " all vars norms [138.72716, 0.5358454, 39.916386, 8.528591, 12.793666, 0.96962655]\n",
      "global_step 13325 , loss 19.530321\n",
      "global_step 13425 , loss 20.215347\n",
      "global_step 13525 , loss 19.026047\n",
      "global_step 13625 , loss 19.197163\n",
      "global_step 13725 , loss 19.444225\n",
      "global_step 13825 , loss 20.804485\n",
      "global_step 13925 , loss 20.683147\n",
      "global_step 14025 , loss 19.523693\n",
      "global_step 14125 , loss 22.2113\n",
      "INFO:tensorflow:global_step/sec: 356.714\n",
      "global_step 14225 , loss 15.89883\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    1.    0.    0.   71.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   84.]]\n",
      " true labels train [ 30.   7. 593.  10. 756.  10. 543. 442.  12. 118.]\n",
      " pred labels train [ 18.6834   5.5796 592.212    9.6749 717.256    7.1785 477.5976 427.8833\n",
      "  14.1761 111.781 ]\n",
      " all vars norms [139.55429, 0.53579, 41.6829, 8.768954, 13.146095, 1.0202565]\n",
      "global_step 14325 , loss 19.444332\n",
      "global_step 14425 , loss 18.994663\n",
      "global_step 14525 , loss 15.021883\n",
      "global_step 14625 , loss 20.012175\n",
      "global_step 14725 , loss 20.551525\n",
      "global_step 14825 , loss 20.269716\n",
      "global_step 14925 , loss 19.730892\n",
      "global_step 15025 , loss 18.23807\n",
      "global_step 15125 , loss 18.045376\n",
      "global_step 15225 , loss 18.134583\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  107.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  323.]]\n",
      " true labels train [  1. 315. 108.  10. 956. 533.  10. 737.   1.   1.]\n",
      " pred labels train [1.1709e-01 3.0793e+02 1.3818e+02 1.1808e+01 9.2984e+02 5.5157e+02\n",
      " 1.2650e+01 7.8013e+02 9.6676e-01 1.0101e+01]\n",
      " all vars norms [140.42953, 0.53620076, 43.368706, 9.020145, 13.474965, 1.0461304]\n",
      "global_step 15325 , loss 17.657875\n",
      "global_step 15425 , loss 21.678898\n",
      "global_step 15525 , loss 20.32994\n",
      "global_step 15625 , loss 18.870056\n",
      "global_step 15725 , loss 16.557993\n",
      "global_step 15825 , loss 18.133995\n",
      "global_step 15925 , loss 18.80259\n",
      "global_step 16025 , loss 20.38874\n",
      "global_step 16125 , loss 17.801378\n",
      "global_step 16225 , loss 17.31746\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  708.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  103.]]\n",
      " true labels train [  1.   1.   1. 100. 444.   1.  60.  71. 155.  11.]\n",
      " pred labels train [  1.0096   0.9501  -3.1302 107.8859 414.7526   1.0053  33.7883  89.7198\n",
      " 172.2391   8.0113]\n",
      " all vars norms [141.29878, 0.5358701, 45.054085, 9.263963, 13.793229, 1.0381167]\n",
      "global_step 16325 , loss 19.091965\n",
      "global_step 16425 , loss 16.675394\n",
      "global_step 16525 , loss 18.58628\n",
      "global_step 16625 , loss 19.91417\n",
      "global_step 16725 , loss 18.02678\n",
      "global_step 16825 , loss 16.023266\n",
      "global_step 16925 , loss 15.199883\n",
      "global_step 17025 , loss 15.207062\n",
      "global_step 17125 , loss 18.629293\n",
      "global_step 17225 , loss 15.442917\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  627.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  604.]]\n",
      " true labels train [ 397.  401.    1.   10.   86. 1000.  325.  589.  969.  708.]\n",
      " pred labels train [ 4.1170e+02  3.7050e+02 -4.8476e-01  1.0944e+01  8.4567e+01  9.8621e+02\n",
      "  2.9933e+02  5.4716e+02  9.4031e+02  7.2224e+02]\n",
      " all vars norms [142.20876, 0.5360777, 46.65285, 9.493411, 14.080443, 1.0327082]\n",
      "global_step 17325 , loss 19.076088\n",
      "global_step 17425 , loss 20.328262\n",
      "global_step 17525 , loss 18.85887\n",
      "global_step 17625 , loss 19.97915\n",
      "global_step 17725 , loss 20.097145\n",
      "global_step 17825 , loss 19.641129\n",
      "global_step 17925 , loss 15.992757\n",
      "global_step 18025 , loss 16.14067\n",
      "global_step 18125 , loss 18.34768\n",
      "global_step 18225 , loss 19.707863\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    1.    0.    0.   88.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  464.]]\n",
      " true labels train [ 11. 455. 335.  10.   8.  83. 100.  11. 381. 497.]\n",
      " pred labels train [ 17.3989 498.3343 369.831   11.7359  12.6879  81.781   95.1977  20.7959\n",
      " 392.3503 528.6177]\n",
      " all vars norms [143.00977, 0.53581184, 48.23677, 9.719718, 14.354431, 1.0246899]\n",
      "global_step 18325 , loss 15.805984\n",
      "global_step 18425 , loss 17.5724\n",
      "global_step 18525 , loss 17.64849\n",
      "global_step 18625 , loss 15.300681\n",
      "global_step 18725 , loss 16.48956\n",
      "global_step 18825 , loss 16.366032\n",
      "global_step 18925 , loss 18.167519\n",
      "global_step 19025 , loss 15.58674\n",
      "global_step 19125 , loss 21.66212\n",
      "INFO:tensorflow:global_step/sec: 372.96\n",
      "global_step 19225 , loss 20.745815\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  929.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  205.]]\n",
      " true labels train [941. 792.  14.   9. 599. 653. 670.  10.   1.  10.]\n",
      " pred labels train [919.4922 827.9448  20.565    9.6124 591.2529 601.2318 592.0963   8.924\n",
      "  11.2103  12.1689]\n",
      " all vars norms [143.87134, 0.53596824, 49.735348, 9.93758, 14.611293, 1.0191588]\n",
      "global_step 19325 , loss 15.206804\n",
      "global_step 19425 , loss 15.622051\n",
      "global_step 19525 , loss 18.00793\n",
      "global_step 19625 , loss 16.97615\n",
      "global_step 19725 , loss 14.981192\n",
      "global_step 19825 , loss 19.057861\n",
      "global_step 19925 , loss 16.509146\n",
      "global_step 20025 , loss 13.827304\n",
      "global_step 20125 , loss 19.017334\n",
      "global_step 20225 , loss 16.519194\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  172.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  408.]]\n",
      " true labels train [ 10. 603.  10. 922.   1.  11. 100. 854.   1. 335.]\n",
      " pred labels train [  6.936  603.4518  10.3305 928.8445   1.8151  10.845   77.6235 870.2256\n",
      "   2.9629 300.1524]\n",
      " all vars norms [144.70154, 0.5356478, 51.279285, 10.148085, 14.861655, 1.0121597]\n",
      "global_step 20325 , loss 16.410503\n",
      "global_step 20425 , loss 16.984905\n",
      "global_step 20525 , loss 15.673323\n",
      "global_step 20625 , loss 18.096783\n",
      "global_step 20725 , loss 18.771591\n",
      "global_step 20825 , loss 17.514658\n",
      "global_step 20925 , loss 17.554249\n",
      "global_step 21025 , loss 17.881256\n",
      "global_step 21125 , loss 18.635868\n",
      "global_step 21225 , loss 18.76279\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  134.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  753.]]\n",
      " true labels train [  13.  255.   83.  197.    1.   84. 1000.   80.   10.  195.]\n",
      " pred labels train [  11.0296  273.9026   68.7321  175.6356  -26.6255   98.7038 1009.4821\n",
      "   65.6531    9.8241  173.4465]\n",
      " all vars norms [145.54062, 0.5356579, 52.763916, 10.362454, 15.102487, 1.0022069]\n",
      "global_step 21325 , loss 16.041183\n",
      "global_step 21425 , loss 15.801876\n",
      "global_step 21525 , loss 16.595472\n",
      "global_step 21625 , loss 14.872101\n",
      "global_step 21725 , loss 14.412329\n",
      "global_step 21825 , loss 15.643076\n",
      "global_step 21925 , loss 17.171303\n",
      "global_step 22025 , loss 13.051422\n",
      "global_step 22125 , loss 14.617878\n",
      "global_step 22225 , loss 15.141956\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   32.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  309.]]\n",
      " true labels train [969.   1.  33.  14.   1. 885.  13.   1.  13. 831.]\n",
      " pred labels train [979.867    1.0007  27.9139  10.7479   8.7168 843.2682  12.0447   1.3779\n",
      "   7.5457 817.4843]\n",
      " all vars norms [146.37054, 0.535643, 54.11761, 10.57184, 15.312917, 0.9999097]\n",
      "global_step 22325 , loss 14.857037\n",
      "global_step 22425 , loss 15.634371\n",
      "global_step 22525 , loss 16.438068\n",
      "global_step 22625 , loss 15.512239\n",
      "global_step 22725 , loss 15.655703\n",
      "global_step 22825 , loss 13.145932\n",
      "global_step 22925 , loss 14.332124\n",
      "global_step 23025 , loss 14.126679\n",
      "global_step 23125 , loss 15.091354\n",
      "global_step 23225 , loss 15.039393\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  956.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  459.]]\n",
      " true labels train [  11.  561.  359.   10.   89.  100.    1.  100.  801. 1000.]\n",
      " pred labels train [  12.7175  589.3524  366.2465    5.9114   83.4479  101.4992   -5.069\n",
      "   99.1729  842.3022 1099.532 ]\n",
      " all vars norms [147.2182, 0.53565747, 55.531357, 10.774324, 15.529961, 1.0000678]\n",
      "global_step 23325 , loss 14.652093\n",
      "global_step 23425 , loss 14.327327\n",
      "global_step 23525 , loss 15.575182\n",
      "global_step 23625 , loss 17.070839\n",
      "global_step 23725 , loss 16.63918\n",
      "global_step 23825 , loss 17.03796\n",
      "global_step 23925 , loss 17.562788\n",
      "global_step 24025 , loss 16.749878\n",
      "global_step 24125 , loss 13.410163\n",
      "INFO:tensorflow:global_step/sec: 379.089\n",
      "global_step 24225 , loss 17.111092\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  900.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  305.]]\n",
      " true labels train [  12.  710.    1.  165. 1000.   10.  918.    1.   85.    4.]\n",
      " pred labels train [8.9464e+00 6.6975e+02 1.0001e+00 1.5698e+02 1.0407e+03 6.9739e+00\n",
      " 8.9580e+02 1.0001e+00 8.5456e+01 1.4251e+02]\n",
      " all vars norms [148.04616, 0.5356502, 56.803635, 10.983997, 15.755587, 1.0001047]\n",
      "global_step 24325 , loss 13.275039\n",
      "global_step 24425 , loss 15.538204\n",
      "global_step 24525 , loss 16.968006\n",
      "global_step 24625 , loss 16.882557\n",
      "global_step 24725 , loss 13.799227\n",
      "global_step 24825 , loss 16.247868\n",
      "global_step 24925 , loss 13.411527\n",
      "global_step 25025 , loss 14.9884615\n",
      "global_step 25125 , loss 18.936377\n",
      "global_step 25225 , loss 12.126914\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  137.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  959.]]\n",
      " true labels train [871.  10.   8.   1. 118.   1. 629. 454.  10.  10.]\n",
      " pred labels train [872.5364   9.6881   9.6366   1.5718 140.7321   3.354  581.327  440.6914\n",
      "   4.5495   9.5935]\n",
      " all vars norms [148.86205, 0.53576124, 58.064053, 11.190507, 15.958073, 1.000142]\n",
      "global_step 25325 , loss 15.763153\n",
      "global_step 25425 , loss 15.179916\n",
      "global_step 25525 , loss 15.950987\n",
      "global_step 25625 , loss 14.745261\n",
      "global_step 25725 , loss 17.528118\n",
      "global_step 25825 , loss 15.838227\n",
      "global_step 25925 , loss 15.321007\n",
      "global_step 26025 , loss 12.710614\n",
      "global_step 26125 , loss 14.674078\n",
      "global_step 26225 , loss 16.887606\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  144.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   73.]]\n",
      " true labels train [ 154.    1. 1000.    1. 1000.    1.    1.  105.  380.   10.]\n",
      " pred labels train [145.9453   0.9997 904.7787 -20.2249 987.4001   0.9997   1.0215 118.5343\n",
      " 354.3852  10.5895]\n",
      " all vars norms [149.68732, 0.5353786, 59.330036, 11.390596, 16.156807, 0.9997988]\n",
      "global_step 26325 , loss 18.32491\n",
      "global_step 26425 , loss 15.1334915\n",
      "global_step 26525 , loss 12.19015\n",
      "global_step 26625 , loss 14.735961\n",
      "global_step 26725 , loss 12.703553\n",
      "global_step 26825 , loss 14.815569\n",
      "global_step 26925 , loss 13.881113\n",
      "global_step 27025 , loss 17.353888\n",
      "global_step 27125 , loss 13.884365\n",
      "global_step 27225 , loss 12.591184\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  671.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  583.]]\n",
      " true labels train [   1.  420.   79.   10.    1. 1000. 1000.    1.  343.  654.]\n",
      " pred labels train [  0.9997 446.8694  78.9652   9.5178  -1.0473 995.4276 879.6672   0.9997\n",
      " 353.2136 646.9886]\n",
      " all vars norms [150.51015, 0.53544146, 60.556595, 11.58746, 16.351227, 0.99966896]\n",
      "global_step 27325 , loss 12.886095\n",
      "global_step 27425 , loss 16.730083\n",
      "global_step 27525 , loss 13.197586\n",
      "global_step 27625 , loss 12.837164\n",
      "global_step 27725 , loss 12.244598\n",
      "global_step 27825 , loss 16.465855\n",
      "global_step 27925 , loss 15.141562\n",
      "global_step 28025 , loss 12.915531\n",
      "global_step 28125 , loss 14.091963\n",
      "global_step 28225 , loss 13.915956\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  629.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  320.]]\n",
      " true labels train [371. 325.   1. 685.   1.  93.  14. 585. 100. 725.]\n",
      " pred labels train [3.7791e+02 3.3409e+02 8.7955e-01 6.9362e+02 7.3500e-01 9.1981e+01\n",
      " 1.1287e+01 6.0461e+02 9.9201e+01 7.7204e+02]\n",
      " all vars norms [151.32549, 0.53535295, 61.74439, 11.7686615, 16.54194, 1.0000528]\n",
      "global_step 28325 , loss 13.654191\n",
      "global_step 28425 , loss 14.733458\n",
      "global_step 28525 , loss 13.64318\n",
      "global_step 28625 , loss 15.631821\n",
      "global_step 28725 , loss 12.465359\n",
      "global_step 28825 , loss 14.402322\n",
      "global_step 28925 , loss 16.109074\n",
      "global_step 29025 , loss 11.33146\n",
      "global_step 29125 , loss 14.9620285\n",
      "INFO:tensorflow:global_step/sec: 370.411\n",
      "global_step 29225 , loss 13.258612\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    1.    0.    0.    0.    0.   71.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  341.]]\n",
      " true labels train [  2.   1. 848. 486.   9.   1. 815.  10.   1.   1.]\n",
      " pred labels train [1.8984e+00 1.0001e+00 8.2061e+02 4.7554e+02 1.0597e+01 1.0001e+00\n",
      " 7.8466e+02 1.4115e+01 3.2905e+00 5.6818e-01]\n",
      " all vars norms [152.11728, 0.53543806, 62.89293, 11.95161, 16.71861, 1.0000787]\n",
      "global_step 29325 , loss 12.278982\n",
      "global_step 29425 , loss 15.716921\n",
      "global_step 29525 , loss 12.719209\n",
      "global_step 29625 , loss 11.445871\n",
      "global_step 29725 , loss 16.214064\n",
      "global_step 29825 , loss 12.646034\n",
      "global_step 29925 , loss 14.556333\n",
      "global_step 30025 , loss 14.185131\n",
      "global_step 30125 , loss 14.463811\n",
      "global_step 30225 , loss 13.40257\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  808.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  411.]]\n",
      " true labels train [817.   1.   1.   9.   1.   1. 961.   1.  21.  10.]\n",
      " pred labels train [848.6757  41.2667   1.0002   7.2594   1.0002   2.4324 973.8958   1.0002\n",
      "  24.4102   9.5268]\n",
      " all vars norms [152.99223, 0.5354812, 64.05854, 12.128398, 16.903429, 1.000241]\n",
      "global_step 30325 , loss 13.104032\n",
      "global_step 30425 , loss 16.304003\n",
      "global_step 30525 , loss 13.346588\n",
      "global_step 30625 , loss 12.376466\n",
      "global_step 30725 , loss 14.9700575\n",
      "global_step 30825 , loss 10.322929\n",
      "global_step 30925 , loss 12.289064\n",
      "global_step 31025 , loss 14.344463\n",
      "global_step 31125 , loss 14.077471\n",
      "global_step 31225 , loss 14.122032\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   55.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   73.]]\n",
      " true labels train [ 81.  10. 100.   1.  15.  13. 922.  10. 165.   1.]\n",
      " pred labels train [1.0852e+02 1.0168e+01 1.1052e+02 7.7854e-01 1.2493e+01 1.0649e+01\n",
      " 9.2983e+02 1.2684e+01 1.5901e+02 1.1996e+00]\n",
      " all vars norms [153.77495, 0.5354054, 65.137596, 12.304958, 17.082052, 1.0000614]\n",
      "global_step 31325 , loss 13.831751\n",
      "INFO:tensorflow:Saving checkpoints for 31419 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 31425 , loss 12.391323\n",
      "global_step 31525 , loss 16.26506\n",
      "global_step 31625 , loss 13.074162\n",
      "global_step 31725 , loss 15.247873\n",
      "global_step 31825 , loss 12.851237\n",
      "global_step 31925 , loss 13.074972\n",
      "global_step 32025 , loss 13.273399\n",
      "global_step 32125 , loss 11.318657\n",
      "global_step 32225 , loss 14.595007\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  803.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  399.]]\n",
      " true labels train [ 785.  391.   10.    1.   18.   10.  130.   10.   89. 1000.]\n",
      " pred labels train [774.1091 380.7567   9.796    1.       9.8405   8.4745 143.7784   8.8935\n",
      "  83.0431 944.1353]\n",
      " all vars norms [154.61276, 0.53539467, 66.293274, 12.476401, 17.238626, 1.0001066]\n",
      "global_step 32325 , loss 14.921272\n",
      "global_step 32425 , loss 13.429355\n",
      "global_step 32525 , loss 15.142411\n",
      "global_step 32625 , loss 12.096458\n",
      "global_step 32725 , loss 15.488627\n",
      "global_step 32825 , loss 11.363804\n",
      "global_step 32925 , loss 12.341069\n",
      "global_step 33025 , loss 13.428915\n",
      "global_step 33125 , loss 14.209812\n",
      "global_step 33225 , loss 11.765211\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  699.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  162.]]\n",
      " true labels train [322.   1. 426. 389. 100.  14.  70. 447. 574. 203.]\n",
      " pred labels train [360.7115   1.     448.6405 410.1599  91.4572  16.0564  67.4784 438.2587\n",
      " 568.3182 191.9165]\n",
      " all vars norms [155.43626, 0.53533727, 67.397316, 12.646324, 17.415768, 0.99987894]\n",
      "global_step 33325 , loss 13.030172\n",
      "global_step 33425 , loss 13.545514\n",
      "global_step 33525 , loss 10.847895\n",
      "global_step 33625 , loss 13.497487\n",
      "global_step 33725 , loss 15.199636\n",
      "global_step 33825 , loss 13.127996\n",
      "global_step 33925 , loss 11.899846\n",
      "global_step 34025 , loss 12.488577\n",
      "global_step 34125 , loss 13.093924\n",
      "INFO:tensorflow:global_step/sec: 357.085\n",
      "global_step 34225 , loss 13.43314\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  856.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  690.]]\n",
      " true labels train [ 12. 680.  10.   1.   1.  10.   1. 818.  38. 255.]\n",
      " pred labels train [ 13.586  675.9158  11.4111   8.5984   0.9997   8.7843   0.9997 816.8484\n",
      "  33.6188 285.8873]\n",
      " all vars norms [156.24278, 0.535276, 68.436295, 12.806149, 17.568192, 0.99973786]\n",
      "global_step 34325 , loss 15.233296\n",
      "global_step 34425 , loss 13.718695\n",
      "global_step 34525 , loss 14.343117\n",
      "global_step 34625 , loss 11.136179\n",
      "global_step 34725 , loss 12.959394\n",
      "global_step 34825 , loss 15.467239\n",
      "global_step 34925 , loss 13.127643\n",
      "global_step 35025 , loss 11.563418\n",
      "global_step 35125 , loss 11.564868\n",
      "global_step 35225 , loss 13.207143\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  380.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  304.]]\n",
      " true labels train [  1. 308.   9. 816.  10. 343.  10.   1. 250.  10.]\n",
      " pred labels train [  1.0001 299.5551   9.9167 730.5342   8.7916 353.1277   4.9044   1.0001\n",
      " 263.3852   9.822 ]\n",
      " all vars norms [157.0712, 0.5353294, 69.46238, 12.962984, 17.737545, 0.9999481]\n",
      "global_step 35325 , loss 13.601861\n",
      "global_step 35425 , loss 12.573759\n",
      "global_step 35525 , loss 15.250406\n",
      "global_step 35625 , loss 13.610208\n",
      "global_step 35725 , loss 13.519324\n",
      "global_step 35825 , loss 12.252055\n",
      "global_step 35925 , loss 13.965777\n",
      "global_step 36025 , loss 14.441313\n",
      "global_step 36125 , loss 15.859728\n",
      "global_step 36225 , loss 14.788142\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  613.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  692.]]\n",
      " true labels train [1000.  696.   14.  962.    1.   73.  249.  518.  364.    1.]\n",
      " pred labels train [946.2942 681.838    9.5647 921.1012   0.9999  76.131  187.9261 464.0123\n",
      " 361.4218  26.9954]\n",
      " all vars norms [157.92667, 0.53549904, 70.43072, 13.124759, 17.899065, 0.9999282]\n",
      "global_step 36325 , loss 15.116612\n",
      "global_step 36425 , loss 11.658959\n",
      "global_step 36525 , loss 11.601402\n",
      "global_step 36625 , loss 11.639254\n",
      "global_step 36725 , loss 14.2624855\n",
      "global_step 36825 , loss 13.915077\n",
      "global_step 36925 , loss 13.157082\n",
      "global_step 37025 , loss 13.611803\n",
      "global_step 37125 , loss 16.938404\n",
      "global_step 37225 , loss 12.941819\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    1.    0.  950.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    1.    0.    0.    0.    0.  846.]]\n",
      " true labels train [ 100.    1.  556.    9.  100. 1000.  733.  426.   10.    1.]\n",
      " pred labels train [101.3981   0.9999 542.2618   7.9117 107.5755 976.3434 711.9728 378.7685\n",
      "  10.7386   0.9999]\n",
      " all vars norms [158.79622, 0.53516936, 71.40448, 13.2852955, 18.037191, 0.99994844]\n",
      "global_step 37325 , loss 10.523354\n",
      "global_step 37425 , loss 12.23949\n",
      "global_step 37525 , loss 14.26738\n",
      "global_step 37625 , loss 10.778126\n",
      "global_step 37725 , loss 14.16062\n",
      "global_step 37825 , loss 12.167776\n",
      "global_step 37925 , loss 12.79516\n",
      "global_step 38025 , loss 12.734293\n",
      "global_step 38125 , loss 12.72442\n",
      "global_step 38225 , loss 10.088766\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    1.    0.    0.    0.    0.  860.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  112.]]\n",
      " true labels train [  1.   1.  12. 124.  10.   1. 562.  74.  10.  10.]\n",
      " pred labels train [  0.9999  -7.8626  13.0809 118.8606   9.994    0.9999 578.7087  54.7444\n",
      "  10.0098  10.084 ]\n",
      " all vars norms [159.58836, 0.5351892, 72.25196, 13.424795, 18.178522, 0.99984545]\n",
      "global_step 38325 , loss 12.122599\n",
      "global_step 38425 , loss 15.496473\n",
      "global_step 38525 , loss 12.091833\n",
      "global_step 38625 , loss 11.615866\n",
      "global_step 38725 , loss 15.966766\n",
      "global_step 38825 , loss 13.501837\n",
      "global_step 38925 , loss 11.721333\n",
      "global_step 39025 , loss 10.250658\n",
      "global_step 39125 , loss 11.126778\n",
      "INFO:tensorflow:global_step/sec: 364.784\n",
      "global_step 39225 , loss 13.772554\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  429.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    1.    0.    0.    0.    0.  871.]]\n",
      " true labels train [  12.    1.  497.    1.  100.   56.  250. 1000.   14.  134.]\n",
      " pred labels train [ 10.8143   0.9997 537.5067   0.9997 100.675   42.089  217.9725 930.4251\n",
      "  13.7408 130.2639]\n",
      " all vars norms [160.36084, 0.53543556, 73.16083, 13.573085, 18.325554, 0.99968016]\n",
      "global_step 39325 , loss 11.895065\n",
      "global_step 39425 , loss 12.366312\n",
      "global_step 39525 , loss 12.848975\n",
      "global_step 39625 , loss 13.59087\n",
      "global_step 39725 , loss 11.950377\n",
      "global_step 39825 , loss 15.827118\n",
      "global_step 39925 , loss 11.788084\n",
      "global_step 40025 , loss 11.3238735\n",
      "global_step 40125 , loss 10.921049\n",
      "global_step 40225 , loss 11.455234\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  962.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  795.]]\n",
      " true labels train [ 10.  10.  10.   1. 680. 347. 355.  10.   1. 242.]\n",
      " pred labels train [ 10.3382  13.0282   9.3349   1.     678.6595 342.448  390.6897   5.2011\n",
      "   1.       1.    ]\n",
      " all vars norms [161.17911, 0.5351453, 74.02404, 13.709106, 18.482122, 1.0001032]\n",
      "global_step 40325 , loss 13.4182205\n",
      "global_step 40425 , loss 12.25831\n",
      "global_step 40525 , loss 14.615198\n",
      "global_step 40625 , loss 11.054724\n",
      "global_step 40725 , loss 11.652695\n",
      "global_step 40825 , loss 11.717971\n",
      "global_step 40925 , loss 11.946439\n",
      "global_step 41025 , loss 13.334036\n",
      "global_step 41125 , loss 10.797064\n",
      "global_step 41225 , loss 11.542137\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    1.    0.    0.    1.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  713.]]\n",
      " true labels train [ 100.  280.   39. 1000.    1. 1000.   84.  490.   13.    1.]\n",
      " pred labels train [9.4356e+01 2.8615e+02 4.2886e+01 9.7483e+02 9.9999e-01 1.0255e+03\n",
      " 8.9020e+01 4.4033e+02 1.3142e+01 9.7497e+00]\n",
      " all vars norms [162.09691, 0.5352921, 74.91046, 13.852691, 18.652716, 0.9999828]\n",
      "global_step 41325 , loss 11.971528\n",
      "global_step 41425 , loss 12.523695\n",
      "global_step 41525 , loss 13.442217\n",
      "global_step 41625 , loss 12.996765\n",
      "global_step 41725 , loss 10.940544\n",
      "global_step 41825 , loss 9.380837\n",
      "global_step 41925 , loss 12.114645\n",
      "global_step 42025 , loss 11.64348\n",
      "global_step 42125 , loss 13.755089\n",
      "global_step 42225 , loss 11.753532\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  657.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  313.]]\n",
      " true labels train [355.  10.   1.  10. 100.   9.  97. 817. 353. 732.]\n",
      " pred labels train [3.5787e+02 8.3839e+00 6.2886e-01 1.3420e+02 1.0963e+02 1.2320e+01\n",
      " 1.1237e+02 8.5255e+02 3.6763e+02 7.2614e+02]\n",
      " all vars norms [162.94725, 0.53542864, 75.738556, 13.996623, 18.793045, 0.99993783]\n",
      "global_step 42325 , loss 11.286586\n",
      "global_step 42425 , loss 12.992746\n",
      "global_step 42525 , loss 13.08429\n",
      "global_step 42625 , loss 13.781225\n",
      "global_step 42725 , loss 10.053796\n",
      "global_step 42825 , loss 13.120948\n",
      "global_step 42925 , loss 13.587315\n",
      "global_step 43025 , loss 10.102667\n",
      "global_step 43125 , loss 12.504989\n",
      "global_step 43225 , loss 10.458681\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    1.  617.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  395.]]\n",
      " true labels train [ 100.    1. 1000.  952.    1.  384.  447.    1.   10.    1.]\n",
      " pred labels train [101.9218   1.0002 999.5096 933.9969   1.7546 398.1402 412.6029   1.0002\n",
      "   5.0657   1.0002]\n",
      " all vars norms [163.71251, 0.53503835, 76.5426, 14.140417, 18.944326, 1.0002099]\n",
      "global_step 43325 , loss 9.111134\n",
      "global_step 43425 , loss 10.845798\n",
      "global_step 43525 , loss 13.62175\n",
      "global_step 43625 , loss 13.108323\n",
      "global_step 43725 , loss 13.138151\n",
      "global_step 43825 , loss 9.596185\n",
      "global_step 43925 , loss 13.147089\n",
      "global_step 44025 , loss 11.360027\n",
      "global_step 44125 , loss 11.194465\n",
      "INFO:tensorflow:global_step/sec: 394.02\n",
      "global_step 44225 , loss 11.142031\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  958.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  929.]]\n",
      " true labels train [ 961.  941. 1000.  216.  141.  867.   57.  316.   15.    1.]\n",
      " pred labels train [964.6101 929.5454 952.6238 211.3281 156.7973 858.3654  49.3336 336.5473\n",
      "  11.6967   0.9999]\n",
      " all vars norms [164.4536, 0.5350922, 77.380356, 14.276307, 19.078487, 0.9999243]\n",
      "global_step 44325 , loss 11.718632\n",
      "global_step 44425 , loss 11.402234\n",
      "global_step 44525 , loss 12.269325\n",
      "global_step 44625 , loss 13.580014\n",
      "global_step 44725 , loss 12.430563\n",
      "global_step 44825 , loss 11.036885\n",
      "global_step 44925 , loss 11.889153\n",
      "global_step 45025 , loss 12.452467\n",
      "global_step 45125 , loss 11.517405\n",
      "global_step 45225 , loss 12.245422\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    1.    0.    0.    0.   55.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    1.    0.    0.    0.  103.]]\n",
      " true labels train [ 47. 100. 961.  28.   1.   1. 849. 786.   1.  12.]\n",
      " pred labels train [4.7100e+01 8.7272e+01 9.2699e+02 2.4351e+01 6.7803e-01 9.9998e-01\n",
      " 8.7569e+02 7.7091e+02 9.9998e-01 1.1438e+01]\n",
      " all vars norms [165.24715, 0.5353248, 78.16771, 14.408341, 19.230684, 1.0000067]\n",
      "global_step 45325 , loss 13.279795\n",
      "global_step 45425 , loss 8.908216\n",
      "global_step 45525 , loss 11.404256\n",
      "global_step 45625 , loss 10.593366\n",
      "global_step 45725 , loss 10.257008\n",
      "global_step 45825 , loss 10.913423\n",
      "global_step 45925 , loss 11.697588\n",
      "global_step 46025 , loss 12.432701\n",
      "global_step 46125 , loss 11.650041\n",
      "global_step 46225 , loss 13.120739\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  753.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  182.]]\n",
      " true labels train [ 737.    1.    1.  290.    1.  292.   10. 1000.    1.    1.]\n",
      " pred labels train [7.4805e+02 4.7684e+00 1.0001e+00 2.7615e+02 1.0001e+00 3.3638e+02\n",
      " 7.4584e+00 1.0507e+03 9.8932e+00 1.0001e+00]\n",
      " all vars norms [165.9978, 0.5352474, 78.98952, 14.541431, 19.377274, 1.0000918]\n",
      "global_step 46325 , loss 11.372298\n",
      "global_step 46425 , loss 14.77225\n",
      "global_step 46525 , loss 11.586864\n",
      "global_step 46625 , loss 13.629338\n",
      "global_step 46725 , loss 12.572588\n",
      "global_step 46825 , loss 11.69385\n",
      "global_step 46925 , loss 9.380498\n",
      "global_step 47025 , loss 9.646889\n",
      "global_step 47125 , loss 13.813244\n",
      "global_step 47225 , loss 11.605497\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  844.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    1.   86.]]\n",
      " true labels train [  1.  85. 642.   1. 223.   1. 271. 100.   7. 194.]\n",
      " pred labels train [  1.      84.575  608.1741   1.     230.002    1.     279.1556  90.8279\n",
      "  10.6527 181.548 ]\n",
      " all vars norms [166.81892, 0.53522146, 79.728226, 14.6650305, 19.527401, 0.99991345]\n",
      "global_step 47325 , loss 13.860502\n",
      "global_step 47425 , loss 11.040369\n",
      "global_step 47525 , loss 9.864686\n",
      "global_step 47625 , loss 12.604098\n",
      "global_step 47725 , loss 11.573194\n",
      "global_step 47825 , loss 11.726625\n",
      "global_step 47925 , loss 12.434489\n",
      "global_step 48025 , loss 11.209574\n",
      "global_step 48125 , loss 11.395105\n",
      "global_step 48225 , loss 9.976746\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    1.    0.    0.    0.    0.   27.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    1.    0.    0.    0.    0.  305.]]\n",
      " true labels train [  3.   1.  12. 827.   1.   1. 550. 632.   1. 439.]\n",
      " pred labels train [  1.6236   1.0001  11.6661 854.4051   3.5256   3.6757 514.6697 620.8763\n",
      "   1.0001 449.7507]\n",
      " all vars norms [167.592, 0.5350138, 80.439735, 14.793995, 19.673176, 0.9998837]\n",
      "global_step 48325 , loss 10.388822\n",
      "global_step 48425 , loss 12.38283\n",
      "global_step 48525 , loss 10.133656\n",
      "global_step 48625 , loss 10.6455555\n",
      "global_step 48725 , loss 10.704374\n",
      "global_step 48825 , loss 12.54299\n",
      "global_step 48925 , loss 10.536928\n",
      "global_step 49025 , loss 12.201849\n",
      "global_step 49125 , loss 12.95145\n",
      "INFO:tensorflow:global_step/sec: 376.01\n",
      "global_step 49225 , loss 9.162299\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  438.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  921.]]\n",
      " true labels train [  10.    1.  274.    1. 1000.  518.   10.    9.   10.   10.]\n",
      " pred labels train [  8.1065   1.0002 287.8943  -4.7141 924.2599 512.8514   8.156   10.3515\n",
      "  11.0461   8.9751]\n",
      " all vars norms [168.31155, 0.5349256, 81.148834, 14.917614, 19.810146, 1.0002687]\n",
      "global_step 49325 , loss 9.451617\n",
      "global_step 49425 , loss 11.233496\n",
      "global_step 49525 , loss 12.449778\n",
      "global_step 49625 , loss 12.075184\n",
      "global_step 49725 , loss 10.788291\n",
      "global_step 49825 , loss 11.65254\n",
      "global_step 49925 , loss 11.605318\n",
      "global_step 50025 , loss 10.28184\n",
      "global_step 50125 , loss 13.107971\n",
      "global_step 50225 , loss 12.084984\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  108.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  514.]]\n",
      " true labels train [ 907.  242.   10.   71.  394.  848. 1000.   11.  765.    1.]\n",
      " pred labels train [8.8750e+02 1.2492e+00 1.2196e+01 8.1683e+01 3.8731e+02 8.3920e+02\n",
      " 1.0109e+03 1.2226e+01 7.5631e+02 9.9986e-01]\n",
      " all vars norms [169.06873, 0.5348331, 81.84239, 15.038777, 19.95214, 0.99996364]\n",
      "global_step 50325 , loss 9.941521\n",
      "global_step 50425 , loss 12.929439\n",
      "global_step 50525 , loss 10.904379\n",
      "global_step 50625 , loss 12.018867\n",
      "global_step 50725 , loss 9.498611\n",
      "global_step 50825 , loss 12.488802\n",
      "global_step 50925 , loss 11.301575\n",
      "global_step 51025 , loss 10.711735\n",
      "global_step 51125 , loss 12.301667\n",
      "global_step 51225 , loss 9.773107\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    1.    0.  514.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  633.]]\n",
      " true labels train [ 100. 1000.  617.  353.  687.   80.    1.  312.  427.  810.]\n",
      " pred labels train [1.2273e+02 1.0129e+03 6.4282e+02 3.5068e+02 6.4936e+02 7.4827e+01\n",
      " 9.9986e-01 3.1808e+02 4.9790e+02 7.7645e+02]\n",
      " all vars norms [169.71666, 0.5348295, 82.57723, 15.15394, 20.067673, 0.99984545]\n",
      "global_step 51325 , loss 12.477095\n",
      "global_step 51425 , loss 11.783595\n",
      "global_step 51525 , loss 10.130426\n",
      "global_step 51625 , loss 8.905394\n",
      "global_step 51725 , loss 11.055977\n",
      "global_step 51825 , loss 9.664722\n",
      "global_step 51925 , loss 10.429836\n",
      "global_step 52025 , loss 16.155643\n",
      "global_step 52125 , loss 11.390612\n",
      "global_step 52225 , loss 9.873838\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  448.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    1.    0.  597.]]\n",
      " true labels train [1000.  100.    1.    1.    1.  980.   10.    1.  630.    1.]\n",
      " pred labels train [9.7374e+02 9.7102e+01 1.0001e+00 1.0001e+00 6.4081e-01 9.6427e+02\n",
      " 1.2073e+01 8.4462e-01 6.1197e+02 1.2390e-01]\n",
      " all vars norms [170.49132, 0.53464216, 83.22884, 15.271017, 20.203491, 1.000135]\n",
      "global_step 52325 , loss 9.30055\n",
      "global_step 52425 , loss 10.920723\n",
      "global_step 52525 , loss 11.763451\n",
      "global_step 52625 , loss 8.954459\n",
      "global_step 52725 , loss 11.41006\n",
      "global_step 52825 , loss 13.100487\n",
      "global_step 52925 , loss 13.371246\n",
      "global_step 53025 , loss 11.734611\n",
      "global_step 53125 , loss 9.154828\n",
      "global_step 53225 , loss 12.814415\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  495.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  483.]]\n",
      " true labels train [   3.  492. 1000.    9.    1.  133. 1000.   14.    1.   11.]\n",
      " pred labels train [ 10.8768 478.4165 964.4542   8.9392   1.0002 172.6739 979.5834  24.2242\n",
      "   1.0002   9.5029]\n",
      " all vars norms [171.25894, 0.5345493, 83.89327, 15.387894, 20.337048, 1.0001053]\n",
      "global_step 53325 , loss 10.657318\n",
      "global_step 53425 , loss 10.244846\n",
      "global_step 53525 , loss 9.565172\n",
      "global_step 53625 , loss 10.401418\n",
      "global_step 53725 , loss 10.901298\n",
      "global_step 53825 , loss 9.621684\n",
      "global_step 53925 , loss 11.739389\n",
      "INFO:tensorflow:Saving checkpoints for 53995 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 54025 , loss 11.816496\n",
      "global_step 54125 , loss 11.974211\n",
      "INFO:tensorflow:global_step/sec: 386.799\n",
      "global_step 54225 , loss 10.338809\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  136.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  224.]]\n",
      " true labels train [152.   1.  67.   1. 258.   1. 165.  14. 576.  10.]\n",
      " pred labels train [131.8362   0.9999  72.0503   0.9999 250.1481   0.9999 152.2141  13.1362\n",
      " 569.361   10.3446]\n",
      " all vars norms [171.99556, 0.53459114, 84.57578, 15.49911, 20.478971, 0.99995285]\n",
      "global_step 54325 , loss 8.969262\n",
      "global_step 54425 , loss 10.329508\n",
      "global_step 54525 , loss 9.460451\n",
      "global_step 54625 , loss 9.828687\n",
      "global_step 54725 , loss 10.432274\n",
      "global_step 54825 , loss 10.876295\n",
      "global_step 54925 , loss 8.584151\n",
      "global_step 55025 , loss 11.352919\n",
      "global_step 55125 , loss 10.093027\n",
      "global_step 55225 , loss 12.034262\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  192.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    1.    0.    0.   19.]]\n",
      " true labels train [199.  88.   1. 687.   1. 847.  10.   1. 539.  10.]\n",
      " pred labels train [219.7685  70.6311   1.     672.015    1.     836.882   11.2154   1.\n",
      " 553.0094  10.7602]\n",
      " all vars norms [172.72623, 0.5346506, 85.20277, 15.60348, 20.602781, 1.0000201]\n",
      "global_step 55325 , loss 12.45862\n",
      "global_step 55425 , loss 16.64809\n",
      "global_step 55525 , loss 12.857401\n",
      "global_step 55625 , loss 12.462989\n",
      "global_step 55725 , loss 9.746807\n",
      "global_step 55825 , loss 8.600929\n",
      "global_step 55925 , loss 11.992758\n",
      "global_step 56025 , loss 10.764215\n",
      "global_step 56125 , loss 10.455406\n",
      "global_step 56225 , loss 11.360589\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    1.    0.    0.    1.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   81.]]\n",
      " true labels train [ 100.  930.  100.  208.   10. 1000.   10.  445.  173.   10.]\n",
      " pred labels train [  95.1437  945.6016   86.1752  189.2097   10.8634 1030.151     3.6718\n",
      "  439.9582  174.5748   10.2618]\n",
      " all vars norms [173.51753, 0.5347467, 85.80081, 15.7169285, 20.726364, 0.99984473]\n",
      "global_step 56325 , loss 9.959363\n",
      "global_step 56425 , loss 10.214\n",
      "global_step 56525 , loss 9.326283\n",
      "global_step 56625 , loss 9.338073\n",
      "global_step 56725 , loss 10.883646\n",
      "global_step 56825 , loss 11.305213\n",
      "global_step 56925 , loss 8.825755\n",
      "global_step 57025 , loss 10.40036\n",
      "global_step 57125 , loss 9.23115\n",
      "global_step 57225 , loss 9.264032\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  886.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  199.]]\n",
      " true labels train [890. 824.   1.   1. 945.   1.   1.   1. 585. 100.]\n",
      " pred labels train [878.9467 810.0081   1.5068   0.9999 950.14     7.638    0.9999   0.9999\n",
      " 601.4838 104.3574]\n",
      " all vars norms [174.23317, 0.5345941, 86.41453, 15.823064, 20.863842, 0.99992037]\n",
      "global_step 57325 , loss 10.607079\n",
      "global_step 57425 , loss 9.264468\n",
      "global_step 57525 , loss 12.038815\n",
      "global_step 57625 , loss 12.2896385\n",
      "global_step 57725 , loss 11.014482\n",
      "global_step 57825 , loss 10.946964\n",
      "global_step 57925 , loss 13.044558\n",
      "global_step 58025 , loss 11.734376\n",
      "global_step 58125 , loss 8.776325\n",
      "global_step 58225 , loss 11.072322\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  967.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  665.]]\n",
      " true labels train [1000.  353.   28.   10.  100.   43.    1.  710.  895.   44.]\n",
      " pred labels train [898.8905 331.5583  28.1931   9.357   79.6152  24.7114   1.7632 705.9016\n",
      " 856.402   49.1315]\n",
      " all vars norms [174.9836, 0.53475994, 87.06667, 15.927262, 20.995344, 1.0000347]\n",
      "global_step 58325 , loss 14.390181\n",
      "global_step 58425 , loss 10.610617\n",
      "global_step 58525 , loss 9.99682\n",
      "global_step 58625 , loss 9.680369\n",
      "global_step 58725 , loss 9.620307\n",
      "global_step 58825 , loss 11.059998\n",
      "global_step 58925 , loss 8.141141\n",
      "global_step 59025 , loss 12.602646\n",
      "global_step 59125 , loss 12.057694\n",
      "INFO:tensorflow:global_step/sec: 372.412\n",
      "global_step 59225 , loss 12.104391\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   42.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  636.]]\n",
      " true labels train [ 10. 617.   1. 559. 473.  10. 595.   1. 470.  10.]\n",
      " pred labels train [ 20.9939 630.8375   0.9999 555.5333 490.0631   8.2162 600.0586   1.1157\n",
      " 480.6206  10.3634]\n",
      " all vars norms [175.77586, 0.53472537, 87.64459, 16.031384, 21.151415, 0.9999393]\n",
      "global_step 59325 , loss 9.2476425\n",
      "global_step 59425 , loss 11.871593\n",
      "global_step 59525 , loss 10.040605\n",
      "global_step 59625 , loss 7.83044\n",
      "global_step 59725 , loss 9.504627\n",
      "global_step 59825 , loss 10.499832\n",
      "global_step 59925 , loss 10.626595\n",
      "global_step 60025 , loss 9.554228\n",
      "global_step 60125 , loss 13.586941\n",
      "global_step 60225 , loss 8.468767\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  404.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    1.]]\n",
      " true labels train [ 609. 1000.   10.  130.   56.   10.    1.  653.    1.    1.]\n",
      " pred labels train [6.1459e+02 7.9362e+02 8.0449e+00 8.4641e+01 4.3947e+01 9.0573e+00\n",
      " 1.0001e+00 6.5785e+02 2.5542e-01 1.0001e+00]\n",
      " all vars norms [176.45833, 0.5344972, 88.23031, 16.13742, 21.28288, 1.0000985]\n",
      "global_step 60325 , loss 10.08912\n",
      "global_step 60425 , loss 8.145227\n",
      "global_step 60525 , loss 8.659758\n",
      "global_step 60625 , loss 10.167288\n",
      "global_step 60725 , loss 9.33424\n",
      "global_step 60825 , loss 10.786707\n",
      "global_step 60925 , loss 10.297276\n",
      "global_step 61025 , loss 11.948111\n",
      "global_step 61125 , loss 11.021483\n",
      "global_step 61225 , loss 9.177135\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  340.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  463.]]\n",
      " true labels train [676.  10.   1. 397.   1.   1.  10.  83. 177.   1.]\n",
      " pred labels train [672.0143   6.0047   0.9999 394.2366   0.9999   0.9999   9.9779 104.5573\n",
      " 141.1638   0.9999]\n",
      " all vars norms [177.16269, 0.534495, 88.87353, 16.239235, 21.396433, 0.999895]\n",
      "global_step 61325 , loss 10.856274\n",
      "global_step 61425 , loss 10.909176\n",
      "global_step 61525 , loss 10.600869\n",
      "global_step 61625 , loss 8.485813\n",
      "global_step 61725 , loss 11.03697\n",
      "global_step 61825 , loss 9.560331\n",
      "global_step 61925 , loss 9.873017\n",
      "global_step 62025 , loss 11.657305\n",
      "global_step 62125 , loss 8.785844\n",
      "global_step 62225 , loss 9.2276\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  978.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    1.    0.    0.    0.    0.   91.]]\n",
      " true labels train [979.   1. 755. 961. 950. 832.  12.   1. 335. 322.]\n",
      " pred labels train [972.6506   4.887  739.8914 925.8929 961.2116 818.4661  10.332    1.\n",
      " 322.1361 361.6739]\n",
      " all vars norms [177.8084, 0.53437674, 89.52922, 16.349676, 21.526934, 0.9999824]\n",
      "global_step 62325 , loss 11.229957\n",
      "global_step 62425 , loss 8.29047\n",
      "global_step 62525 , loss 10.206165\n",
      "global_step 62625 , loss 12.68734\n",
      "global_step 62725 , loss 10.579737\n",
      "global_step 62825 , loss 10.917931\n",
      "global_step 62925 , loss 11.635178\n",
      "global_step 63025 , loss 11.98267\n",
      "global_step 63125 , loss 12.782763\n",
      "global_step 63225 , loss 8.470497\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  293.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  419.]]\n",
      " true labels train [ 283.   14.   10.  381.  203.  100.    7.   10.    8. 1000.]\n",
      " pred labels train [292.1978  11.818    6.3584 369.0287 203.8609 110.3686  17.8794  10.1897\n",
      "  11.3234 961.7764]\n",
      " all vars norms [178.58475, 0.53464437, 90.147766, 16.450956, 21.653028, 1.000225]\n",
      "global_step 63325 , loss 9.466314\n",
      "global_step 63425 , loss 9.09301\n",
      "global_step 63525 , loss 9.888956\n",
      "global_step 63625 , loss 9.632149\n",
      "global_step 63725 , loss 8.882611\n",
      "global_step 63825 , loss 9.243958\n",
      "global_step 63925 , loss 11.81461\n",
      "global_step 64025 , loss 9.441978\n",
      "global_step 64125 , loss 13.041979\n",
      "INFO:tensorflow:global_step/sec: 361.311\n",
      "global_step 64225 , loss 7.8951244\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  180.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  499.]]\n",
      " true labels train [   1.  477. 1000.  871.    1.  599.    1.  865.  329.  615.]\n",
      " pred labels train [9.9994e-01 4.6339e+02 1.0211e+03 8.7415e+02 3.2851e+00 5.9560e+02\n",
      " 9.9994e-01 8.8150e+02 3.1330e+02 6.2329e+02]\n",
      " all vars norms [179.25554, 0.5343964, 90.761536, 16.559015, 21.753567, 0.9998548]\n",
      "global_step 64325 , loss 8.930052\n",
      "global_step 64425 , loss 9.189679\n",
      "global_step 64525 , loss 10.526116\n",
      "global_step 64625 , loss 11.768141\n",
      "global_step 64725 , loss 10.30183\n",
      "global_step 64825 , loss 9.321133\n",
      "global_step 64925 , loss 7.7310505\n",
      "global_step 65025 , loss 8.777246\n",
      "global_step 65125 , loss 8.206743\n",
      "global_step 65225 , loss 13.834999\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  465.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  938.]]\n",
      " true labels train [  1.   1.  13. 271. 407.  93.  88.   1. 451.   1.]\n",
      " pred labels train [  1.1987   1.      10.8581 225.6414 421.4817 101.4652  78.0114   1.\n",
      " 470.1623   1.    ]\n",
      " all vars norms [179.96996, 0.5346167, 91.287, 16.66002, 21.844246, 1.000043]\n",
      "global_step 65325 , loss 9.556866\n",
      "global_step 65425 , loss 9.774879\n",
      "global_step 65525 , loss 8.307253\n",
      "global_step 65625 , loss 8.624882\n",
      "global_step 65725 , loss 9.197119\n",
      "global_step 65825 , loss 12.075044\n",
      "global_step 65925 , loss 9.629393\n",
      "global_step 66025 , loss 8.863226\n",
      "global_step 66125 , loss 9.5721855\n",
      "global_step 66225 , loss 9.974218\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  572.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  796.]]\n",
      " true labels train [ 574.    1.   66.  728. 1000.   12.    7.    1.    1.   11.]\n",
      " pred labels train [ 5.7641e+02  9.9989e-01  6.2890e+01  7.3134e+02  9.9220e+02  8.8226e+00\n",
      "  9.1931e+00 -3.5348e-01  1.4945e+00  1.0390e+01]\n",
      " all vars norms [180.7257, 0.5344887, 91.84294, 16.765038, 21.955467, 0.9997224]\n",
      "global_step 66325 , loss 8.773388\n",
      "global_step 66425 , loss 8.79484\n",
      "global_step 66525 , loss 9.632718\n",
      "global_step 66625 , loss 12.421782\n",
      "global_step 66725 , loss 7.4772787\n",
      "global_step 66825 , loss 9.37167\n",
      "global_step 66925 , loss 8.970619\n",
      "global_step 67025 , loss 10.319201\n",
      "global_step 67125 , loss 8.552074\n",
      "global_step 67225 , loss 11.654324\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  838.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  222.]]\n",
      " true labels train [ 192.    1. 1000.    1.   10.    8.  194.    1.  894.  890.]\n",
      " pred labels train [201.0388   1.0002 893.8433   1.0002  11.5457  11.4005 213.17     1.0002\n",
      " 889.4311 890.959 ]\n",
      " all vars norms [181.42233, 0.5343276, 92.3966, 16.868559, 22.04925, 1.0001608]\n",
      "global_step 67325 , loss 8.73153\n",
      "global_step 67425 , loss 8.89929\n",
      "global_step 67525 , loss 9.872627\n",
      "global_step 67625 , loss 8.302727\n",
      "global_step 67725 , loss 10.789724\n",
      "global_step 67825 , loss 8.394622\n",
      "global_step 67925 , loss 10.266797\n",
      "global_step 68025 , loss 8.653474\n",
      "global_step 68125 , loss 9.660658\n",
      "global_step 68225 , loss 11.141426\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  558.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  232.]]\n",
      " true labels train [   1.  778.   10. 1000.  736.  661.   21.    9.   10. 1000.]\n",
      " pred labels train [   1.8933  787.3295   10.8321  995.5723  753.8992  661.6071   22.5944\n",
      "    5.6426    2.2046 1058.1141]\n",
      " all vars norms [182.19858, 0.5345397, 93.04698, 16.969303, 22.160374, 1.000064]\n",
      "global_step 68325 , loss 10.200364\n",
      "global_step 68425 , loss 9.897495\n",
      "global_step 68525 , loss 9.120404\n",
      "global_step 68625 , loss 8.892212\n",
      "global_step 68725 , loss 8.785583\n",
      "global_step 68825 , loss 9.315056\n",
      "global_step 68925 , loss 10.285505\n",
      "global_step 69025 , loss 10.3877535\n",
      "global_step 69125 , loss 10.491299\n",
      "INFO:tensorflow:global_step/sec: 342.554\n",
      "global_step 69225 , loss 8.835144\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  120.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  193.]]\n",
      " true labels train [871. 199. 969.   1.  10. 680.  39.  83. 606. 550.]\n",
      " pred labels train [ 888.2001  199.2749 1000.675   -14.8967    6.8272  685.0068   31.7538\n",
      "   82.7121  616.5464  577.0383]\n",
      " all vars norms [182.93808, 0.5343471, 93.62318, 17.06264, 22.260609, 0.999923]\n",
      "global_step 69325 , loss 10.457577\n",
      "global_step 69425 , loss 10.107203\n",
      "global_step 69525 , loss 9.847509\n",
      "global_step 69625 , loss 9.990669\n",
      "global_step 69725 , loss 9.780478\n",
      "global_step 69825 , loss 8.136042\n",
      "global_step 69925 , loss 9.898985\n",
      "global_step 70025 , loss 8.358401\n",
      "global_step 70125 , loss 10.170189\n",
      "global_step 70225 , loss 11.490386\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    1.   34.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    1.    0.  105.]]\n",
      " true labels train [  33.    1. 1000.   85.  343.    9.   97.    7. 1000.  454.]\n",
      " pred labels train [  32.2366    9.751   958.9059   85.6405  354.0959   13.0036   88.1723\n",
      "    9.0584 1037.6174  499.7926]\n",
      " all vars norms [183.60416, 0.53461, 94.15138, 17.166832, 22.365679, 0.9998936]\n",
      "global_step 70325 , loss 10.244141\n",
      "global_step 70425 , loss 9.450952\n",
      "global_step 70525 , loss 7.994639\n",
      "global_step 70625 , loss 8.96183\n",
      "global_step 70725 , loss 7.787309\n",
      "global_step 70825 , loss 10.738924\n",
      "global_step 70925 , loss 11.633088\n",
      "global_step 71025 , loss 10.012455\n",
      "global_step 71125 , loss 9.490992\n",
      "global_step 71225 , loss 10.655138\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  580.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  981.]]\n",
      " true labels train [   8.    1.    4.    1.  878.    1.    1.  701.  923. 1000.]\n",
      " pred labels train [ 10.2389   1.      -4.4335   1.     881.4166   1.      38.0015 709.4089\n",
      " 947.4346 983.9237]\n",
      " all vars norms [184.3339, 0.5348276, 94.68008, 17.26462, 22.472723, 1.0000476]\n",
      "global_step 71325 , loss 11.138824\n",
      "global_step 71425 , loss 7.905154\n",
      "global_step 71525 , loss 8.828234\n",
      "global_step 71625 , loss 8.440035\n",
      "global_step 71725 , loss 10.361463\n",
      "global_step 71825 , loss 10.513205\n",
      "global_step 71925 , loss 10.541712\n",
      "global_step 72025 , loss 8.1630535\n",
      "global_step 72125 , loss 11.308041\n",
      "global_step 72225 , loss 10.296257\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  294.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  329.]]\n",
      " true labels train [ 729.    1.    1.   50. 1000.  848.  283.  100.  623.  950.]\n",
      " pred labels train [7.1918e+02 9.9992e-01 9.9992e-01 5.3988e+01 1.0030e+03 8.5626e+02\n",
      " 2.9916e+02 8.1699e+01 6.3032e+02 9.5149e+02]\n",
      " all vars norms [185.01294, 0.53446627, 95.23866, 17.366972, 22.570751, 1.000098]\n",
      "global_step 72325 , loss 8.591529\n",
      "global_step 72425 , loss 9.542678\n",
      "global_step 72525 , loss 8.873558\n",
      "global_step 72625 , loss 9.102282\n",
      "global_step 72725 , loss 9.904952\n",
      "global_step 72825 , loss 10.695009\n",
      "global_step 72925 , loss 11.974766\n",
      "global_step 73025 , loss 8.953146\n",
      "global_step 73125 , loss 10.609944\n",
      "global_step 73225 , loss 7.487861\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  173.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  664.]]\n",
      " true labels train [192.  10.  39.   1.  11. 661.   1. 930. 376.  60.]\n",
      " pred labels train [ 2.1530e+02  9.4014e+00  4.0972e+01 -8.3065e-01  1.0684e+01  6.5777e+02\n",
      "  1.0001e+00  8.9253e+02  3.8341e+02  6.5883e+01]\n",
      " all vars norms [185.75752, 0.53456765, 95.81865, 17.463171, 22.65678, 1.0002147]\n",
      "global_step 73325 , loss 8.686802\n",
      "global_step 73425 , loss 10.008661\n",
      "global_step 73525 , loss 9.072785\n",
      "global_step 73625 , loss 8.874435\n",
      "global_step 73725 , loss 8.003248\n",
      "global_step 73825 , loss 11.452931\n",
      "global_step 73925 , loss 8.468337\n",
      "global_step 74025 , loss 10.69928\n",
      "global_step 74125 , loss 9.002454\n",
      "INFO:tensorflow:global_step/sec: 370.966\n",
      "global_step 74225 , loss 8.700456\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  824.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  967.]]\n",
      " true labels train [1000. 1000.    1.  216.  100.   10.   89.  115.   10.  389.]\n",
      " pred labels train [992.595  985.7066   1.     215.2575  99.7357   9.7579  84.5556 130.9712\n",
      "  10.6275 407.9551]\n",
      " all vars norms [186.4747, 0.53467065, 96.3381, 17.568647, 22.75831, 1.0000187]\n",
      "global_step 74325 , loss 9.866561\n",
      "global_step 74425 , loss 12.758972\n",
      "global_step 74525 , loss 10.369799\n",
      "global_step 74625 , loss 8.46007\n",
      "global_step 74725 , loss 9.361765\n",
      "global_step 74825 , loss 14.622211\n",
      "global_step 74925 , loss 10.337276\n",
      "global_step 75025 , loss 8.701498\n",
      "global_step 75125 , loss 8.117442\n",
      "global_step 75225 , loss 9.230778\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  738.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    1.    0.  788.]]\n",
      " true labels train [ 736.  100.   17.    1.  585.   28.   10.  562. 1000.  233.]\n",
      " pred labels train [ 736.5901  107.8655   15.4716    1.8381  598.2139   21.6964   10.8124\n",
      "  565.3851 1021.8586  228.6596]\n",
      " all vars norms [187.1435, 0.5346044, 96.865364, 17.665276, 22.843931, 1.0000298]\n",
      "global_step 75325 , loss 8.636362\n",
      "global_step 75425 , loss 9.100359\n",
      "global_step 75525 , loss 8.304625\n",
      "INFO:tensorflow:Saving checkpoints for 75617 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 75625 , loss 7.455634\n",
      "global_step 75725 , loss 9.053389\n",
      "global_step 75825 , loss 8.699579\n",
      "global_step 75925 , loss 9.723554\n",
      "global_step 76025 , loss 9.934978\n",
      "global_step 76125 , loss 8.826392\n",
      "global_step 76225 , loss 10.174306\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   17.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    1.    0.    0.    0.   56.]]\n",
      " true labels train [  14.   46.    1.  599.  271.   10. 1000.  507.  848.   13.]\n",
      " pred labels train [ 11.2204  55.155    2.3009 593.1672 269.7309   4.946  994.0254 496.0952\n",
      " 853.7937  25.7793]\n",
      " all vars norms [187.80794, 0.53434443, 97.406944, 17.761827, 22.926487, 1.0001546]\n",
      "global_step 76325 , loss 9.689319\n",
      "global_step 76425 , loss 10.317068\n",
      "global_step 76525 , loss 7.9518857\n",
      "global_step 76625 , loss 12.863484\n",
      "global_step 76725 , loss 9.674734\n",
      "global_step 76825 , loss 9.406256\n",
      "global_step 76925 , loss 9.158264\n",
      "global_step 77025 , loss 10.022959\n",
      "global_step 77125 , loss 8.565064\n",
      "global_step 77225 , loss 10.590906\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  218.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  259.]]\n",
      " true labels train [  1.   1. 896. 467. 209.  10.  93. 615. 152. 824.]\n",
      " pred labels train [  1.0001  -6.6071 913.797  487.1759 264.0886  11.346   78.8459 638.36\n",
      " 133.6281 830.2471]\n",
      " all vars norms [188.4166, 0.53451234, 97.860466, 17.850077, 23.007906, 1.0001072]\n",
      "global_step 77325 , loss 9.204326\n",
      "global_step 77425 , loss 11.1314125\n",
      "global_step 77525 , loss 10.47455\n",
      "global_step 77625 , loss 9.401648\n",
      "global_step 77725 , loss 7.949707\n",
      "global_step 77825 , loss 9.12468\n",
      "global_step 77925 , loss 8.976146\n",
      "global_step 78025 , loss 9.108776\n",
      "global_step 78125 , loss 9.855789\n",
      "global_step 78225 , loss 11.718336\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  663.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  664.]]\n",
      " true labels train [362.  10. 184. 100. 206. 100. 100.   1. 173.   1.]\n",
      " pred labels train [360.0203   9.8534 181.1186  95.5605 209.8409  88.9251 104.241   -1.793\n",
      " 170.3076   0.9999]\n",
      " all vars norms [189.1525, 0.534522, 98.3435, 17.953026, 23.080662, 0.99989474]\n",
      "global_step 78325 , loss 7.8272724\n",
      "global_step 78425 , loss 10.345089\n",
      "global_step 78525 , loss 7.902876\n",
      "global_step 78625 , loss 11.584036\n",
      "global_step 78725 , loss 6.8685274\n",
      "global_step 78825 , loss 10.308236\n",
      "global_step 78925 , loss 8.244347\n",
      "global_step 79025 , loss 9.104548\n",
      "global_step 79125 , loss 8.954506\n",
      "INFO:tensorflow:global_step/sec: 338.126\n",
      "global_step 79225 , loss 9.377012\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  756.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   31.]]\n",
      " true labels train [   1.    1.    1.   59.  483.    1.    1.  574. 1000.  562.]\n",
      " pred labels train [2.6022e+00 5.1031e-01 9.9983e-01 6.4396e+01 4.9203e+02 9.9983e-01\n",
      " 1.0949e+00 5.8611e+02 1.0198e+03 5.8579e+02]\n",
      " all vars norms [189.83356, 0.53449196, 98.83664, 18.03567, 23.165218, 0.9998577]\n",
      "global_step 79325 , loss 8.730615\n",
      "global_step 79425 , loss 8.034847\n",
      "global_step 79525 , loss 9.8267975\n",
      "global_step 79625 , loss 7.524886\n",
      "global_step 79725 , loss 10.59853\n",
      "global_step 79825 , loss 9.444056\n",
      "global_step 79925 , loss 8.484282\n",
      "global_step 80025 , loss 8.681398\n",
      "global_step 80125 , loss 9.779741\n",
      "global_step 80225 , loss 8.571672\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    1.    0.    0.  131.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    1.    0.    0.  519.]]\n",
      " true labels train [ 100.    1.   10.  559.  124.   11.  100.   10.    9. 1000.]\n",
      " pred labels train [1.2147e+02 1.0001e+00 9.2440e+00 5.5918e+02 1.5241e+02 1.1394e+01\n",
      " 9.8301e+01 1.0294e+01 9.0286e+00 1.0154e+03]\n",
      " all vars norms [190.50467, 0.534643, 99.31512, 18.136967, 23.263542, 0.99997246]\n",
      "global_step 80325 , loss 9.000212\n",
      "global_step 80425 , loss 12.265081\n",
      "global_step 80525 , loss 7.951929\n",
      "global_step 80625 , loss 6.824209\n",
      "global_step 80725 , loss 8.0971985\n",
      "global_step 80825 , loss 8.914497\n",
      "global_step 80925 , loss 8.418442\n",
      "global_step 81025 , loss 9.76945\n",
      "global_step 81125 , loss 8.690006\n",
      "global_step 81225 , loss 8.958092\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   55.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  380.]]\n",
      " true labels train [ 81.   1. 335.   7.  83.  10. 100.   1.   1. 100.]\n",
      " pred labels train [ 58.4467   1.0001 338.0529  11.9722  93.658   10.7428  87.5063   1.0001\n",
      "   4.0313  95.2364]\n",
      " all vars norms [191.23605, 0.5344586, 99.812355, 18.223318, 23.3662, 1.0000898]\n",
      "global_step 81325 , loss 9.056196\n",
      "global_step 81425 , loss 9.509596\n",
      "global_step 81525 , loss 9.911139\n",
      "global_step 81625 , loss 8.866114\n",
      "global_step 81725 , loss 10.492973\n",
      "global_step 81825 , loss 6.7535996\n",
      "global_step 81925 , loss 8.330343\n",
      "global_step 82025 , loss 9.101891\n",
      "global_step 82125 , loss 8.662352\n",
      "global_step 82225 , loss 8.416344\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  611.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  980.]]\n",
      " true labels train [376.  17. 177.  13. 595. 995. 518.   1. 805.  13.]\n",
      " pred labels train [382.8883  17.9512 176.0214  11.899  581.3431 790.6736 514.4496   1.0001\n",
      " 791.1573  12.2312]\n",
      " all vars norms [191.87964, 0.5345758, 100.255806, 18.317375, 23.44795, 1.0001351]\n",
      "global_step 82325 , loss 9.414923\n",
      "global_step 82425 , loss 10.795506\n",
      "global_step 82525 , loss 9.976367\n",
      "global_step 82625 , loss 8.26704\n",
      "global_step 82725 , loss 9.845246\n",
      "global_step 82825 , loss 7.096734\n",
      "global_step 82925 , loss 9.7659445\n",
      "global_step 83025 , loss 7.163887\n",
      "global_step 83125 , loss 8.633598\n",
      "global_step 83225 , loss 10.59874\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  996.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  532.]]\n",
      " true labels train [  10.    8.    1.   10. 1000.    1.    1.    1.  246.    3.]\n",
      " pred labels train [ 10.7513  11.1894   0.9998   9.1936 999.8135   2.7434   0.9998   0.9998\n",
      " 220.6665   2.5631]\n",
      " all vars norms [192.62683, 0.53486234, 100.78784, 18.40626, 23.565445, 0.99978966]\n",
      "global_step 83325 , loss 10.86879\n",
      "global_step 83425 , loss 8.624443\n",
      "global_step 83525 , loss 10.681148\n",
      "global_step 83625 , loss 9.486908\n",
      "global_step 83725 , loss 9.10229\n",
      "global_step 83825 , loss 7.1423273\n",
      "global_step 83925 , loss 8.333304\n",
      "global_step 84025 , loss 7.9875984\n",
      "global_step 84125 , loss 8.806765\n",
      "INFO:tensorflow:global_step/sec: 352.847\n",
      "global_step 84225 , loss 10.199141\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  987.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    1.    0.    0.   80.]]\n",
      " true labels train [  30.   21. 1000.  731.   12.    1.  653.  680.   67.    2.]\n",
      " pred labels train [ 42.7963  14.7513 988.5925 749.5745  12.3718   0.9998 646.1247 680.5021\n",
      "  60.8598   0.9998]\n",
      " all vars norms [193.28018, 0.5345534, 101.20983, 18.50317, 23.664732, 0.999796]\n",
      "global_step 84325 , loss 9.92341\n",
      "global_step 84425 , loss 11.153879\n",
      "global_step 84525 , loss 8.442607\n",
      "global_step 84625 , loss 8.43375\n",
      "global_step 84725 , loss 8.694419\n",
      "global_step 84825 , loss 9.086958\n",
      "global_step 84925 , loss 9.134369\n",
      "global_step 85025 , loss 8.923841\n",
      "global_step 85125 , loss 10.059822\n",
      "global_step 85225 , loss 8.838518\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  685.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  926.]]\n",
      " true labels train [  10.   14.  890.    1.  904. 1000.   10.  583.    1.  467.]\n",
      " pred labels train [1.0896e+01 1.2687e+01 9.0287e+02 9.9976e-01 8.9860e+02 1.0247e+03\n",
      " 6.1822e+00 5.8485e+02 9.9976e-01 4.5508e+02]\n",
      " all vars norms [193.94061, 0.53453475, 101.66278, 18.597897, 23.753155, 0.9997533]\n",
      "global_step 85325 , loss 9.469446\n",
      "global_step 85425 , loss 10.027238\n",
      "global_step 85525 , loss 10.51352\n",
      "global_step 85625 , loss 8.198802\n",
      "global_step 85725 , loss 6.845522\n",
      "global_step 85825 , loss 9.555079\n",
      "global_step 85925 , loss 7.7752438\n",
      "global_step 86025 , loss 8.860104\n",
      "global_step 86125 , loss 11.175768\n",
      "global_step 86225 , loss 9.793592\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  551.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  670.]]\n",
      " true labels train [  1.   7. 446. 411. 154. 196. 835.   1.  59.   8.]\n",
      " pred labels train [  2.178   12.0501 459.6393 426.2423 166.9512 176.597  835.4443   0.9999\n",
      "  39.7955   8.8689]\n",
      " all vars norms [194.6202, 0.53464997, 102.156906, 18.686237, 23.854227, 0.99998325]\n",
      "global_step 86325 , loss 9.991423\n",
      "global_step 86425 , loss 8.399117\n",
      "global_step 86525 , loss 6.9180417\n",
      "global_step 86625 , loss 7.0581517\n",
      "global_step 86725 , loss 10.149237\n",
      "global_step 86825 , loss 8.596685\n",
      "global_step 86925 , loss 7.500278\n",
      "global_step 87025 , loss 9.45335\n",
      "global_step 87125 , loss 8.743092\n",
      "global_step 87225 , loss 7.997392\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    1.    0.    0.    4.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  925.]]\n",
      " true labels train [ 97.  79. 100.   1.   1.   1.  70.   1.  10.   8.]\n",
      " pred labels train [ 79.7292  73.2363 102.4897   0.9999   0.9999   0.9999  75.1027   1.0781\n",
      "  10.9204  11.0439]\n",
      " all vars norms [195.2666, 0.53457457, 102.58494, 18.770958, 23.961725, 0.99988294]\n",
      "global_step 87325 , loss 9.133499\n",
      "global_step 87425 , loss 7.733794\n",
      "global_step 87525 , loss 8.680037\n",
      "global_step 87625 , loss 7.993817\n",
      "global_step 87725 , loss 9.916977\n",
      "global_step 87825 , loss 7.3192472\n",
      "global_step 87925 , loss 9.132006\n",
      "global_step 88025 , loss 7.76437\n",
      "global_step 88125 , loss 8.687799\n",
      "global_step 88225 , loss 6.9132977\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  189.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  569.]]\n",
      " true labels train [835. 567. 539. 173. 627.  20.   1.  63.   1. 849.]\n",
      " pred labels train [832.1996 570.2053 535.1959 200.1053 632.5803   8.6763   1.      64.3113\n",
      "   1.6507 858.462 ]\n",
      " all vars norms [195.94151, 0.5346137, 103.0724, 18.863724, 24.05771, 1.0000035]\n",
      "global_step 88325 , loss 7.5409565\n",
      "global_step 88425 , loss 7.517167\n",
      "global_step 88525 , loss 8.091879\n",
      "global_step 88625 , loss 9.554212\n",
      "global_step 88725 , loss 9.099882\n",
      "global_step 88825 , loss 7.4631863\n",
      "global_step 88925 , loss 10.902492\n",
      "global_step 89025 , loss 9.518866\n",
      "global_step 89125 , loss 9.462608\n",
      "INFO:tensorflow:global_step/sec: 365.864\n",
      "global_step 89225 , loss 9.084056\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  496.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  160.]]\n",
      " true labels train [503. 155. 282.   1. 299.   1.   1. 204. 627. 473.]\n",
      " pred labels train [496.9433 160.3656 298.3528  -1.3816 290.082    1.0002   1.0002 214.2161\n",
      " 618.7954 475.0829]\n",
      " all vars norms [196.49556, 0.5347287, 103.53024, 18.954758, 24.138988, 1.0002897]\n",
      "global_step 89325 , loss 7.36487\n",
      "global_step 89425 , loss 6.9244165\n",
      "global_step 89525 , loss 8.075505\n",
      "global_step 89625 , loss 10.15373\n",
      "global_step 89725 , loss 11.439795\n",
      "global_step 89825 , loss 10.342586\n",
      "global_step 89925 , loss 8.171509\n",
      "global_step 90025 , loss 9.661476\n",
      "global_step 90125 , loss 8.499079\n",
      "global_step 90225 , loss 8.183754\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  475.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  437.]]\n",
      " true labels train [ 100.    1.  687.   79.   44.    1.  165.   83.  100. 1000.]\n",
      " pred labels train [ 96.1341   2.3952 673.8696  79.0162  30.254    1.0003 169.4434  80.5023\n",
      " 107.5668 960.8045]\n",
      " all vars norms [197.124, 0.534464, 103.94729, 19.04902, 24.22498, 1.000312]\n",
      "global_step 90325 , loss 10.098768\n",
      "global_step 90425 , loss 7.992094\n",
      "global_step 90525 , loss 8.570496\n",
      "global_step 90625 , loss 13.583796\n",
      "global_step 90725 , loss 8.201341\n",
      "global_step 90825 , loss 10.967281\n",
      "global_step 90925 , loss 8.323824\n",
      "global_step 91025 , loss 11.267914\n",
      "global_step 91125 , loss 8.249831\n",
      "global_step 91225 , loss 8.530046\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  603.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    1.    0.    0.    4.]]\n",
      " true labels train [611.  97.   1. 636.   1. 308. 826. 100. 130. 471.]\n",
      " pred labels train [608.5939 101.0871   1.5132 637.8618   1.     311.6358 819.983   96.6413\n",
      " 121.5695 464.562 ]\n",
      " all vars norms [197.7207, 0.5342548, 104.41312, 19.132801, 24.30227, 0.99997836]\n",
      "global_step 91325 , loss 8.02088\n",
      "global_step 91425 , loss 9.989119\n",
      "global_step 91525 , loss 10.043486\n",
      "global_step 91625 , loss 8.889299\n",
      "global_step 91725 , loss 8.5857315\n",
      "global_step 91825 , loss 6.753572\n",
      "global_step 91925 , loss 7.4064393\n",
      "global_step 92025 , loss 7.387684\n",
      "global_step 92125 , loss 9.518414\n",
      "global_step 92225 , loss 10.265644\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  345.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  520.]]\n",
      " true labels train [  1. 491.   8.   1. 580.   1.  93.  10. 737. 100.]\n",
      " pred labels train [  1.0004 485.0188   8.4903   1.0004 553.389    1.0004  81.593    9.8506\n",
      " 748.9919 104.4638]\n",
      " all vars norms [198.36421, 0.53478396, 104.84826, 19.218712, 24.406569, 1.000311]\n",
      "global_step 92325 , loss 8.156502\n",
      "global_step 92425 , loss 8.03641\n",
      "global_step 92525 , loss 7.7709327\n",
      "global_step 92625 , loss 9.932685\n",
      "global_step 92725 , loss 9.793194\n",
      "global_step 92825 , loss 10.940519\n",
      "global_step 92925 , loss 9.877338\n",
      "global_step 93025 , loss 8.835457\n",
      "global_step 93125 , loss 8.509289\n",
      "global_step 93225 , loss 9.469156\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  920.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  102.]]\n",
      " true labels train [926.   8.   1.  12. 950.  10.   1. 100.   1.   8.]\n",
      " pred labels train [926.7928   9.2462   1.0408  12.8213 961.571   10.1824  19.1546  98.1111\n",
      "   0.9998  10.9355]\n",
      " all vars norms [198.95117, 0.5346074, 105.32748, 19.311483, 24.493551, 0.9998776]\n",
      "global_step 93325 , loss 10.232544\n",
      "global_step 93425 , loss 6.979\n",
      "global_step 93525 , loss 8.224678\n",
      "global_step 93625 , loss 9.068075\n",
      "global_step 93725 , loss 9.819987\n",
      "global_step 93825 , loss 9.38101\n",
      "global_step 93925 , loss 8.376345\n",
      "global_step 94025 , loss 7.785067\n",
      "global_step 94125 , loss 6.834599\n",
      "INFO:tensorflow:global_step/sec: 350.781\n",
      "global_step 94225 , loss 6.667488\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    1.    0.    0.    0.    5.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  807.]]\n",
      " true labels train [  95.    1.    7.  325. 1000.  246.    2.  426.    1.  100.]\n",
      " pred labels train [8.3688e+01 9.9951e-01 8.7878e+00 3.2030e+02 1.0183e+03 2.4916e+02\n",
      " 7.7528e+01 4.3478e+02 9.9951e-01 1.0161e+02]\n",
      " all vars norms [199.48944, 0.53441465, 105.736336, 19.402695, 24.589975, 0.99952054]\n",
      "global_step 94325 , loss 8.152853\n",
      "global_step 94425 , loss 9.772718\n",
      "global_step 94525 , loss 9.048996\n",
      "global_step 94625 , loss 11.403391\n",
      "global_step 94725 , loss 8.9872675\n",
      "global_step 94825 , loss 11.591422\n",
      "global_step 94925 , loss 8.513732\n",
      "global_step 95025 , loss 8.102982\n",
      "global_step 95125 , loss 14.285112\n",
      "global_step 95225 , loss 9.776093\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  652.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  286.]]\n",
      " true labels train [ 354.  728.  999.  832.   10.  371.  688.   10.  728. 1000.]\n",
      " pred labels train [ 349.3279  721.4592  879.749   813.1062    9.9272  381.9614  664.3068\n",
      "   10.1272  739.4863 1014.182 ]\n",
      " all vars norms [200.14275, 0.5347539, 106.135994, 19.487507, 24.688028, 1.0001843]\n",
      "global_step 95325 , loss 9.3451\n",
      "global_step 95425 , loss 7.979416\n",
      "global_step 95525 , loss 6.8020945\n",
      "global_step 95625 , loss 8.230219\n",
      "global_step 95725 , loss 10.501142\n",
      "global_step 95825 , loss 7.3924394\n",
      "global_step 95925 , loss 7.2573786\n",
      "global_step 96025 , loss 8.988978\n",
      "global_step 96125 , loss 8.600769\n",
      "global_step 96225 , loss 8.257469\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  635.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    1.    0.    0.  103.]]\n",
      " true labels train [  1.   1. 525.  10.   1.  33. 100. 453.   1.   1.]\n",
      " pred labels train [  1.       9.7894 518.5023   7.1276   1.      30.1983 116.2329 452.9359\n",
      "   2.9129   1.    ]\n",
      " all vars norms [200.69188, 0.5344201, 106.56842, 19.575838, 24.780455, 0.9999606]\n",
      "global_step 96325 , loss 10.048334\n",
      "global_step 96425 , loss 6.343544\n",
      "global_step 96525 , loss 7.4164715\n",
      "global_step 96625 , loss 7.9659925\n",
      "global_step 96725 , loss 11.902544\n",
      "global_step 96825 , loss 7.981173\n",
      "INFO:tensorflow:Saving checkpoints for 96849 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 96925 , loss 7.4395313\n",
      "global_step 97025 , loss 9.311186\n",
      "global_step 97125 , loss 7.66512\n",
      "global_step 97225 , loss 8.407165\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  579.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  188.]]\n",
      " true labels train [  1. 197. 555.   1. 737. 484. 100. 426.   1. 922.]\n",
      " pred labels train [ 9.9968e-01  2.1043e+02  5.5283e+02 -1.1703e+01  7.5239e+02  4.5090e+02\n",
      "  1.0112e+02  4.0489e+02 -4.1356e-01  9.2823e+02]\n",
      " all vars norms [201.22499, 0.5343543, 106.97426, 19.658491, 24.858843, 0.999603]\n",
      "global_step 97325 , loss 10.319315\n",
      "global_step 97425 , loss 10.041072\n",
      "global_step 97525 , loss 7.7923317\n",
      "global_step 97625 , loss 9.805842\n",
      "global_step 97725 , loss 9.533775\n",
      "global_step 97825 , loss 7.457443\n",
      "global_step 97925 , loss 9.376391\n",
      "global_step 98025 , loss 7.7852483\n",
      "global_step 98125 , loss 8.3678875\n",
      "global_step 98225 , loss 8.740585\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  837.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  911.]]\n",
      " true labels train [ 822.    1.    1.  100.    1.    9. 1000.   10.    1.   23.]\n",
      " pred labels train [8.1158e+02 1.0000e+00 4.5947e+00 1.1082e+02 1.0000e+00 8.3616e+00\n",
      " 1.0095e+03 9.7679e+00 4.2709e+01 1.0191e+01]\n",
      " all vars norms [201.79166, 0.5346602, 107.36057, 19.744287, 24.94058, 1.0000716]\n",
      "global_step 98325 , loss 7.359781\n",
      "global_step 98425 , loss 10.315319\n",
      "global_step 98525 , loss 9.014366\n",
      "global_step 98625 , loss 12.221508\n",
      "global_step 98725 , loss 9.078314\n",
      "global_step 98825 , loss 8.654366\n",
      "global_step 98925 , loss 9.308489\n",
      "global_step 99025 , loss 9.440429\n",
      "global_step 99125 , loss 7.9215174\n",
      "INFO:tensorflow:global_step/sec: 365.584\n",
      "global_step 99225 , loss 7.390682\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  180.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  279.]]\n",
      " true labels train [  1.  10.  15. 100. 984.   8.   1.   1.  10. 477.]\n",
      " pred labels train [  0.9999  10.6795  10.1865  98.8501 977.6222   9.6075   0.9999   0.9999\n",
      "   9.9659 509.8817]\n",
      " all vars norms [202.40164, 0.53461635, 107.75852, 19.823885, 25.038969, 0.99980116]\n",
      "global_step 99325 , loss 7.9035325\n",
      "global_step 99425 , loss 10.529287\n",
      "global_step 99525 , loss 7.5264874\n",
      "global_step 99625 , loss 8.419784\n",
      "global_step 99725 , loss 8.696402\n",
      "global_step 99825 , loss 10.137103\n",
      "global_step 99925 , loss 8.594771\n",
      "global_step 100025 , loss 8.427307\n",
      "global_step 100125 , loss 7.7721043\n",
      "global_step 100225 , loss 8.310989\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   24.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   33.]]\n",
      " true labels train [ 38.  10.   1.  42.   1.  10. 895.  10.  15. 162.]\n",
      " pred labels train [ 48.4653   9.61     2.9986  35.2917   1.0002   9.9125 914.1044   7.5491\n",
      "  13.6746 156.3761]\n",
      " all vars norms [202.95761, 0.5347822, 108.15479, 19.914623, 25.137024, 1.000205]\n",
      "global_step 100325 , loss 8.644068\n",
      "global_step 100425 , loss 8.225759\n",
      "global_step 100525 , loss 11.848945\n",
      "global_step 100625 , loss 9.991598\n",
      "global_step 100725 , loss 10.765572\n",
      "global_step 100825 , loss 10.833404\n",
      "global_step 100925 , loss 8.119089\n",
      "global_step 101025 , loss 10.754221\n",
      "global_step 101125 , loss 9.477184\n",
      "global_step 101225 , loss 8.959999\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    1.  291.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  177.]]\n",
      " true labels train [  1. 176.  11. 979. 990.   1.   1.   1. 100. 218.]\n",
      " pred labels train [  1.0801 177.3804  11.827  968.8447 988.964    1.0001   1.0001   1.0001\n",
      "  95.6352 226.843 ]\n",
      " all vars norms [203.48975, 0.534828, 108.572525, 20.001999, 25.227354, 1.0000393]\n",
      "global_step 101325 , loss 8.55187\n",
      "global_step 101425 , loss 7.6996202\n",
      "global_step 101525 , loss 7.4296117\n",
      "global_step 101625 , loss 10.567297\n",
      "global_step 101725 , loss 9.465107\n",
      "global_step 101825 , loss 9.739872\n",
      "global_step 101925 , loss 9.822161\n",
      "global_step 102025 , loss 9.3357525\n",
      "global_step 102125 , loss 6.1334867\n",
      "global_step 102225 , loss 6.9459414\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   91.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  169.]]\n",
      " true labels train [  1.  10. 573. 316.   1.   1.  11.   1.   1. 100.]\n",
      " pred labels train [  2.3763  10.2306 568.5381 322.6049   0.9999   0.9999  10.8661   0.8833\n",
      "   2.2524 104.8321]\n",
      " all vars norms [204.01468, 0.53486955, 108.96015, 20.084854, 25.32142, 0.99991363]\n",
      "global_step 102325 , loss 6.9459267\n",
      "global_step 102425 , loss 11.9558\n",
      "global_step 102525 , loss 8.536522\n",
      "global_step 102625 , loss 9.885324\n",
      "global_step 102725 , loss 9.206465\n",
      "global_step 102825 , loss 9.104054\n",
      "global_step 102925 , loss 8.303126\n",
      "global_step 103025 , loss 8.939769\n",
      "global_step 103125 , loss 9.538951\n",
      "global_step 103225 , loss 7.4268255\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  171.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    1.    0.    0.   46.]]\n",
      " true labels train [  10.   56.  134.   56.   10.  100.   10.  473. 1000. 1000.]\n",
      " pred labels train [  12.3784   49.8851  144.2855   55.0179   10.616    93.4835   10.037\n",
      "  473.2294  995.6564 1025.6533]\n",
      " all vars norms [204.60225, 0.5348247, 109.36167, 20.164886, 25.422379, 0.99997777]\n",
      "global_step 103325 , loss 9.597334\n",
      "global_step 103425 , loss 7.8211575\n",
      "global_step 103525 , loss 7.655177\n",
      "global_step 103625 , loss 8.718822\n",
      "global_step 103725 , loss 7.48182\n",
      "global_step 103825 , loss 6.922305\n",
      "global_step 103925 , loss 7.67204\n",
      "global_step 104025 , loss 7.810754\n",
      "global_step 104125 , loss 8.263152\n",
      "INFO:tensorflow:global_step/sec: 386.87\n",
      "global_step 104225 , loss 8.154245\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  205.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  947.]]\n",
      " true labels train [ 207.   50.  355. 1000.   78.   85.   68.    1.   10.  122.]\n",
      " pred labels train [2.1006e+02 6.0383e+01 3.6167e+02 9.9562e+02 8.4014e+01 8.4283e+01\n",
      " 6.5830e+01 2.5218e-01 9.8016e+00 1.1710e+02]\n",
      " all vars norms [205.0816, 0.5348294, 109.74329, 20.253803, 25.503016, 1.0000525]\n",
      "global_step 104325 , loss 7.533247\n",
      "global_step 104425 , loss 9.483942\n",
      "global_step 104525 , loss 9.870556\n",
      "global_step 104625 , loss 9.264809\n",
      "global_step 104725 , loss 7.599705\n",
      "global_step 104825 , loss 10.241686\n",
      "global_step 104925 , loss 12.358968\n",
      "global_step 105025 , loss 9.27264\n",
      "global_step 105125 , loss 6.528396\n",
      "global_step 105225 , loss 7.1755137\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   44.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  471.]]\n",
      " true labels train [ 53. 521.  10. 100.  10. 519.   1.  12. 192.   1.]\n",
      " pred labels train [ 59.2234 506.0035  10.1592 103.8484   9.8167 566.2187   0.9999   9.0244\n",
      " 173.2899   0.9999]\n",
      " all vars norms [205.6147, 0.53509814, 110.11883, 20.332829, 25.577927, 0.9999369]\n",
      "global_step 105325 , loss 10.91088\n",
      "global_step 105425 , loss 6.9568815\n",
      "global_step 105525 , loss 6.1244483\n",
      "global_step 105625 , loss 6.0469284\n",
      "global_step 105725 , loss 8.39838\n",
      "global_step 105825 , loss 9.991417\n",
      "global_step 105925 , loss 11.569842\n",
      "global_step 106025 , loss 9.945707\n",
      "global_step 106125 , loss 9.874398\n",
      "global_step 106225 , loss 7.902989\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  126.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  616.]]\n",
      " true labels train [134.  10.  10.   1.   1. 894.  10. 154.  10. 204.]\n",
      " pred labels train [158.0296   4.0098  11.9521   0.9999  -3.7582 882.3679  10.6824 170.7032\n",
      "  10.5995 221.6484]\n",
      " all vars norms [206.16415, 0.53520864, 110.500435, 20.413982, 25.648857, 0.99993]\n",
      "global_step 106325 , loss 7.032093\n",
      "global_step 106425 , loss 9.828102\n",
      "global_step 106525 , loss 9.911602\n",
      "global_step 106625 , loss 8.731308\n",
      "global_step 106725 , loss 6.752575\n",
      "global_step 106825 , loss 8.411879\n",
      "global_step 106925 , loss 8.468927\n",
      "global_step 107025 , loss 7.1120467\n",
      "global_step 107125 , loss 6.829788\n",
      "global_step 107225 , loss 7.91245\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  161.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  443.]]\n",
      " true labels train [100.   1. 792.   1. 732.   1. 250.   1. 710. 845.]\n",
      " pred labels train [ 93.5646  19.474  801.4404   1.     740.7803   1.     246.0823   1.\n",
      " 713.4602 851.7183]\n",
      " all vars norms [206.68127, 0.53528637, 110.88126, 20.50007, 25.739063, 0.9999613]\n",
      "global_step 107325 , loss 8.288372\n",
      "global_step 107425 , loss 7.851228\n",
      "global_step 107525 , loss 9.818593\n",
      "global_step 107625 , loss 8.039384\n",
      "global_step 107725 , loss 10.558706\n",
      "global_step 107825 , loss 9.1335335\n",
      "global_step 107925 , loss 9.042589\n",
      "global_step 108025 , loss 9.395969\n",
      "global_step 108125 , loss 8.3359375\n",
      "global_step 108225 , loss 9.336765\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  909.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  274.]]\n",
      " true labels train [1000.    1.  808.  960.  417.   14.    1.    1.    1.   19.]\n",
      " pred labels train [9.9683e+02 1.0001e+00 8.0814e+02 9.5144e+02 4.3089e+02 1.2015e+01\n",
      " 1.0001e+00 2.2964e-01 1.0001e+00 1.6304e+01]\n",
      " all vars norms [207.20953, 0.5351085, 111.258, 20.573019, 25.802979, 1.0000697]\n",
      "global_step 108325 , loss 6.9046702\n",
      "global_step 108425 , loss 7.8528347\n",
      "global_step 108525 , loss 8.100088\n",
      "global_step 108625 , loss 8.4945965\n",
      "global_step 108725 , loss 8.288744\n",
      "global_step 108825 , loss 7.1864686\n",
      "global_step 108925 , loss 9.040173\n",
      "global_step 109025 , loss 8.848189\n",
      "global_step 109125 , loss 7.088757\n",
      "INFO:tensorflow:global_step/sec: 388.943\n",
      "global_step 109225 , loss 6.7806735\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  110.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  434.]]\n",
      " true labels train [890.   7.   1.  10.   1. 100.  10. 152.  12.   1.]\n",
      " pred labels train [888.0417   8.5065   1.       9.2378   1.6924 102.6498  10.1179 132.9222\n",
      "  10.5827   1.    ]\n",
      " all vars norms [207.668, 0.53531027, 111.653755, 20.64978, 25.881615, 1.0000784]\n",
      "global_step 109325 , loss 8.721429\n",
      "global_step 109425 , loss 9.058515\n",
      "global_step 109525 , loss 7.3617077\n",
      "global_step 109625 , loss 7.482024\n",
      "global_step 109725 , loss 6.9738655\n",
      "global_step 109825 , loss 9.428551\n",
      "global_step 109925 , loss 8.865851\n",
      "global_step 110025 , loss 8.17928\n",
      "global_step 110125 , loss 6.7363434\n",
      "global_step 110225 , loss 6.788355\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  894.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    1.    0.    0.    0.    0.   27.]]\n",
      " true labels train [882.   2.   1.   1.   1.  14. 398.  10. 545. 355.]\n",
      " pred labels train [808.1319   1.8406   5.8672   0.9998   0.9998  11.9824 395.95     9.3779\n",
      " 532.4415 360.7184]\n",
      " all vars norms [208.18787, 0.53534263, 112.0177, 20.7344, 25.947565, 0.9998987]\n",
      "global_step 110325 , loss 7.755\n",
      "global_step 110425 , loss 7.515111\n",
      "global_step 110525 , loss 8.894108\n",
      "global_step 110625 , loss 8.7756\n",
      "global_step 110725 , loss 7.684719\n",
      "global_step 110825 , loss 7.4621854\n",
      "global_step 110925 , loss 8.180792\n",
      "global_step 111025 , loss 6.7149754\n",
      "global_step 111125 , loss 10.266825\n",
      "global_step 111225 , loss 10.018855\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    1.    0.    0.    0.  471.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    1.  365.]]\n",
      " true labels train [  1.   1.   1.  10.  93. 195.   9. 343.   1.   1.]\n",
      " pred labels train [  6.4124   3.4344   1.       9.9729  97.4819 202.2997   9.9638 339.3503\n",
      "   1.       1.8586]\n",
      " all vars norms [208.65936, 0.5352487, 112.383675, 20.812721, 26.019161, 1.0001693]\n",
      "global_step 111325 , loss 8.101842\n",
      "global_step 111425 , loss 7.3866816\n",
      "global_step 111525 , loss 8.998066\n",
      "global_step 111625 , loss 8.93623\n",
      "global_step 111725 , loss 9.964821\n",
      "global_step 111825 , loss 8.891602\n",
      "global_step 111925 , loss 8.687006\n",
      "global_step 112025 , loss 6.6893473\n",
      "global_step 112125 , loss 5.4072475\n",
      "global_step 112225 , loss 11.702798\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  935.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    1.   71.]]\n",
      " true labels train [  10.   78.  497.  570.    5.  890.  736.   10. 1000.  182.]\n",
      " pred labels train [ 11.4221  71.5807 514.9104 549.5183   0.9998 898.8163 740.8842  12.0715\n",
      " 975.3067 169.6952]\n",
      " all vars norms [209.20407, 0.53549576, 112.74065, 20.892912, 26.092815, 0.99980265]\n",
      "global_step 112325 , loss 8.363165\n",
      "global_step 112425 , loss 7.744922\n",
      "global_step 112525 , loss 7.9665537\n",
      "global_step 112625 , loss 9.101304\n",
      "global_step 112725 , loss 8.103735\n",
      "global_step 112825 , loss 7.199585\n",
      "global_step 112925 , loss 6.4583645\n",
      "global_step 113025 , loss 6.221653\n",
      "global_step 113125 , loss 8.806707\n",
      "global_step 113225 , loss 6.94312\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  811.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  143.]]\n",
      " true labels train [  1.  10. 108. 100. 558. 956.  29. 521.  10.  46.]\n",
      " pred labels train [  1.      10.1362 103.8066 101.598  563.1984 954.9944  38.197  524.9122\n",
      "   8.996   46.822 ]\n",
      " all vars norms [209.73338, 0.5353239, 113.08763, 20.962572, 26.163118, 0.999995]\n",
      "global_step 113325 , loss 7.088869\n",
      "global_step 113425 , loss 8.480488\n",
      "global_step 113525 , loss 8.141941\n",
      "global_step 113625 , loss 8.245375\n",
      "global_step 113725 , loss 7.41568\n",
      "global_step 113825 , loss 7.458887\n",
      "global_step 113925 , loss 6.4998307\n",
      "global_step 114025 , loss 8.971045\n",
      "global_step 114125 , loss 7.731616\n",
      "INFO:tensorflow:global_step/sec: 390.274\n",
      "global_step 114225 , loss 7.994932\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   14.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  798.]]\n",
      " true labels train [989. 795. 725.   1.   1.  97.  12. 848.   1.   2.]\n",
      " pred labels train [976.0528 763.6166 716.7235   0.9999   0.9999 102.1485  11.4087 862.8631\n",
      "   0.9999  27.6389]\n",
      " all vars norms [210.24324, 0.53532463, 113.47596, 21.040451, 26.228642, 0.99999154]\n",
      "global_step 114325 , loss 8.640163\n",
      "global_step 114425 , loss 7.7309523\n",
      "global_step 114525 , loss 8.896889\n",
      "global_step 114625 , loss 6.1750727\n",
      "global_step 114725 , loss 6.2912216\n",
      "global_step 114825 , loss 9.94082\n",
      "global_step 114925 , loss 10.007751\n",
      "global_step 115025 , loss 10.479179\n",
      "global_step 115125 , loss 7.947572\n",
      "global_step 115225 , loss 7.5740204\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    1.    0.    0.    0.    0.   13.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  900.]]\n",
      " true labels train [ 10. 118. 233. 676.  12.  12. 445. 535.  10. 229.]\n",
      " pred labels train [  1.9617 119.9797 273.2693 667.6     12.0314  13.1367 457.7412 525.3743\n",
      "  10.5027 220.1673]\n",
      " all vars norms [210.75693, 0.5356205, 113.82385, 21.113586, 26.30092, 0.9997572]\n",
      "global_step 115325 , loss 8.787561\n",
      "global_step 115425 , loss 7.510483\n",
      "global_step 115525 , loss 8.023689\n",
      "global_step 115625 , loss 8.987608\n",
      "global_step 115725 , loss 8.319694\n",
      "global_step 115825 , loss 7.4418945\n",
      "global_step 115925 , loss 7.9989767\n",
      "global_step 116025 , loss 11.746876\n",
      "global_step 116125 , loss 7.6727304\n",
      "global_step 116225 , loss 7.948629\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    1.    0.    0.    0.  222.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  173.]]\n",
      " true labels train [100. 192. 165. 246.   1.  43. 347. 905. 543.   1.]\n",
      " pred labels train [ 93.4258 178.6575 169.3432 496.4571  -0.9572  48.7678 339.8889 912.2607\n",
      " 542.0693   3.3409]\n",
      " all vars norms [211.27596, 0.53554183, 114.16222, 21.190298, 26.360228, 1.0003088]\n",
      "global_step 116325 , loss 7.7875576\n",
      "global_step 116425 , loss 8.53088\n",
      "global_step 116525 , loss 11.5104885\n",
      "global_step 116625 , loss 6.1158357\n",
      "global_step 116725 , loss 7.047416\n",
      "global_step 116825 , loss 8.556757\n",
      "global_step 116925 , loss 7.1076975\n",
      "global_step 117025 , loss 8.320755\n",
      "global_step 117125 , loss 7.279736\n",
      "global_step 117225 , loss 9.103521\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  526.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  647.]]\n",
      " true labels train [  1. 646.   1. 676. 351. 376.  10. 623. 329. 950.]\n",
      " pred labels train [  0.9998 637.2892   0.9998 676.3375 353.7801 360.0879   7.1893 613.5682\n",
      " 326.4159 950.5115]\n",
      " all vars norms [211.81331, 0.5354765, 114.493416, 21.261055, 26.426882, 0.9998079]\n",
      "global_step 117325 , loss 9.368122\n",
      "global_step 117425 , loss 6.9177155\n",
      "global_step 117525 , loss 6.653914\n",
      "global_step 117625 , loss 10.352688\n",
      "global_step 117725 , loss 6.617841\n",
      "global_step 117825 , loss 9.556667\n",
      "global_step 117925 , loss 9.130545\n",
      "global_step 118025 , loss 11.358564\n",
      "global_step 118125 , loss 7.638089\n",
      "global_step 118225 , loss 7.6682463\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    1.    0.    0.  163.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  109.]]\n",
      " true labels train [100. 110.  16.  13. 343. 785.   1. 934.   9. 661.]\n",
      " pred labels train [ 78.1845 108.5431   9.2573  10.9451 342.1545 728.3093   1.2976 922.4703\n",
      "   9.5555 670.1594]\n",
      " all vars norms [212.29384, 0.53553534, 114.842766, 21.32761, 26.492283, 0.99959517]\n",
      "global_step 118325 , loss 7.5128927\n",
      "global_step 118425 , loss 9.31753\n",
      "global_step 118525 , loss 8.019623\n",
      "global_step 118625 , loss 8.366107\n",
      "global_step 118725 , loss 6.7987723\n",
      "global_step 118825 , loss 5.8952904\n",
      "global_step 118925 , loss 6.9066925\n",
      "global_step 119025 , loss 10.137627\n",
      "global_step 119125 , loss 6.849437\n",
      "INFO:tensorflow:global_step/sec: 384.502\n",
      "global_step 119225 , loss 8.920129\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  733.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  663.]]\n",
      " true labels train [  1. 362.   1.  12.   1.  15.  10.   1. 423.  13.]\n",
      " pred labels train [  0.9999 347.1636   0.9999  10.0736  16.9026   9.8397  15.1694   0.9999\n",
      " 440.0445   5.0894]\n",
      " all vars norms [212.85435, 0.53574085, 115.17573, 21.39575, 26.554178, 0.99982893]\n",
      "global_step 119325 , loss 6.5592384\n",
      "global_step 119425 , loss 5.8935122\n",
      "global_step 119525 , loss 8.129546\n",
      "global_step 119625 , loss 8.789394\n",
      "global_step 119725 , loss 8.642544\n",
      "global_step 119825 , loss 6.877861\n",
      "INFO:tensorflow:Saving checkpoints for 119882 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 119925 , loss 6.8009753\n",
      "global_step 120025 , loss 6.752632\n",
      "global_step 120125 , loss 7.0092373\n",
      "global_step 120225 , loss 9.854174\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  812.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  673.]]\n",
      " true labels train [ 10.   1. 329.  10.   1. 100.  10. 135. 960.  18.]\n",
      " pred labels train [ 10.5188   0.9998 327.4897  12.4242   0.9998 102.0173  10.5824 123.4716\n",
      " 973.0424  12.0675]\n",
      " all vars norms [213.34407, 0.53540206, 115.52987, 21.475002, 26.626888, 0.9997384]\n",
      "global_step 120325 , loss 8.104933\n",
      "global_step 120425 , loss 6.519916\n",
      "global_step 120525 , loss 7.488116\n",
      "global_step 120625 , loss 8.515942\n",
      "global_step 120725 , loss 7.421555\n",
      "global_step 120825 , loss 8.536604\n",
      "global_step 120925 , loss 7.755651\n",
      "global_step 121025 , loss 6.471178\n",
      "global_step 121125 , loss 8.359285\n",
      "global_step 121225 , loss 8.750412\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  907.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  166.]]\n",
      " true labels train [ 14.   1.  10.   1. 100. 832.  15.  30.   1. 310.]\n",
      " pred labels train [ 13.8719   1.      10.4884   1.     104.3748 829.13    13.2697  29.6112\n",
      "   1.     303.2122]\n",
      " all vars norms [213.82431, 0.53535646, 115.87505, 21.545298, 26.685307, 1.0000143]\n",
      "global_step 121325 , loss 7.956175\n",
      "global_step 121425 , loss 8.219216\n",
      "global_step 121525 , loss 8.1521435\n",
      "global_step 121625 , loss 7.0413837\n",
      "global_step 121725 , loss 9.322349\n",
      "global_step 121825 , loss 8.152172\n",
      "global_step 121925 , loss 7.82658\n",
      "global_step 122025 , loss 7.0409174\n",
      "global_step 122125 , loss 9.194808\n",
      "global_step 122225 , loss 8.909334\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    1.    5.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    1.  313.]]\n",
      " true labels train [  7.   1.   3.  56. 470. 459.  12. 624.   1.  14.]\n",
      " pred labels train [  2.6873   1.0504   5.2208  55.9303 468.5773 448.0856  12.3224 622.5322\n",
      "   0.7796   9.65  ]\n",
      " all vars norms [214.33995, 0.5356244, 116.2311, 21.606386, 26.76423, 1.0001365]\n",
      "global_step 122325 , loss 9.869467\n",
      "global_step 122425 , loss 7.550392\n",
      "global_step 122525 , loss 10.193448\n",
      "global_step 122625 , loss 9.907845\n",
      "global_step 122725 , loss 6.571974\n",
      "global_step 122825 , loss 6.6583843\n",
      "global_step 122925 , loss 9.307042\n",
      "global_step 123025 , loss 7.844489\n",
      "global_step 123125 , loss 7.6315002\n",
      "global_step 123225 , loss 7.805315\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  554.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  807.]]\n",
      " true labels train [547.  17. 756.   1. 701.  38.   1.   1.   1.   1.]\n",
      " pred labels train [559.4702  13.9296 769.0789   1.0001 706.3176  26.9807   1.3978   1.0001\n",
      "   3.4358  -2.6595]\n",
      " all vars norms [214.82568, 0.53551435, 116.56606, 21.684185, 26.816515, 1.0000802]\n",
      "global_step 123325 , loss 9.845543\n",
      "global_step 123425 , loss 7.244354\n",
      "global_step 123525 , loss 8.410465\n",
      "global_step 123625 , loss 8.081091\n",
      "global_step 123725 , loss 7.596587\n",
      "global_step 123825 , loss 8.910229\n",
      "global_step 123925 , loss 8.357412\n",
      "global_step 124025 , loss 8.05835\n",
      "global_step 124125 , loss 10.465118\n",
      "INFO:tensorflow:global_step/sec: 370.196\n",
      "global_step 124225 , loss 8.054033\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    1.   10.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  768.]]\n",
      " true labels train [ 13. 746.  92.  95. 536. 895.   1. 343.   8.  10.]\n",
      " pred labels train [  3.422  746.178   82.3126  46.8505 538.2986 891.6088   1.9882 262.5869\n",
      "  10.4584  10.1575]\n",
      " all vars norms [215.26935, 0.53552496, 116.896675, 21.752325, 26.877028, 0.9999012]\n",
      "global_step 124325 , loss 9.839407\n",
      "global_step 124425 , loss 8.188736\n",
      "global_step 124525 , loss 12.041335\n",
      "global_step 124625 , loss 7.84719\n",
      "global_step 124725 , loss 7.062292\n",
      "global_step 124825 , loss 7.0446014\n",
      "global_step 124925 , loss 7.698775\n",
      "global_step 125025 , loss 7.4799867\n",
      "global_step 125125 , loss 10.603289\n",
      "global_step 125225 , loss 7.921673\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    1.    0.    0.    0.    0.  303.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  825.]]\n",
      " true labels train [   1.    1. 1000.  956.  335.    1.   10.    3.    1.    1.]\n",
      " pred labels train [  3.2987   1.     990.7422 945.5399 353.4717   1.      10.4171   1.\n",
      "   3.0414   1.    ]\n",
      " all vars norms [215.81187, 0.5351283, 117.2493, 21.821213, 26.94106, 1.0000303]\n",
      "global_step 125325 , loss 8.094314\n",
      "global_step 125425 , loss 7.4080467\n",
      "global_step 125525 , loss 8.921134\n",
      "global_step 125625 , loss 8.635668\n",
      "global_step 125725 , loss 9.790904\n",
      "global_step 125825 , loss 9.492165\n",
      "global_step 125925 , loss 8.018826\n",
      "global_step 126025 , loss 10.122706\n",
      "global_step 126125 , loss 9.596882\n",
      "global_step 126225 , loss 9.300564\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    1.    0.  179.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    1.    6.]]\n",
      " true labels train [  1.   9.  10.   2. 135.   1.  19.   1.   1.  10.]\n",
      " pred labels train [  0.7143   7.6245   6.9173 336.5693 149.4081   1.0003  16.6625   1.0003\n",
      "   1.0003   9.37  ]\n",
      " all vars norms [216.26039, 0.53543943, 117.57573, 21.89378, 26.97962, 1.0002643]\n",
      "global_step 126325 , loss 7.360597\n",
      "global_step 126425 , loss 7.294222\n",
      "global_step 126525 , loss 7.661954\n",
      "global_step 126625 , loss 9.899641\n",
      "global_step 126725 , loss 7.8640213\n",
      "global_step 126825 , loss 6.963892\n",
      "global_step 126925 , loss 7.402045\n",
      "global_step 127025 , loss 5.606361\n",
      "global_step 127125 , loss 6.728688\n",
      "global_step 127225 , loss 7.8510685\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  392.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    1.    0.    0.    0.    0.  656.]]\n",
      " true labels train [   1.    1.    1. 1000.    9.    1.    1.  335.  479.  950.]\n",
      " pred labels train [9.9991e-01 9.9991e-01 9.9991e-01 1.0163e+03 1.0711e+01 9.9991e-01\n",
      " 9.9991e-01 3.3317e+02 5.1456e+02 9.6208e+02]\n",
      " all vars norms [216.77486, 0.5356608, 117.89213, 21.96031, 27.040268, 0.9997669]\n",
      "global_step 127325 , loss 6.673091\n",
      "global_step 127425 , loss 7.2176323\n",
      "global_step 127525 , loss 7.857937\n",
      "global_step 127625 , loss 8.586729\n",
      "global_step 127725 , loss 9.496452\n",
      "global_step 127825 , loss 6.847504\n",
      "global_step 127925 , loss 9.037111\n",
      "global_step 128025 , loss 8.192813\n",
      "global_step 128125 , loss 9.263891\n",
      "global_step 128225 , loss 8.279612\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  841.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    1.    0.    0.    0.  265.]]\n",
      " true labels train [ 178.    1.  844.   10.  100. 1000.  421.    1.    1.   60.]\n",
      " pred labels train [1.9080e+02 9.9999e-01 8.4973e+02 1.0374e+01 7.7406e+01 1.0000e+03\n",
      " 3.9416e+02 9.9999e-01 9.9999e-01 7.9460e+01]\n",
      " all vars norms [217.24004, 0.5356827, 118.25031, 22.033438, 27.113882, 0.9999122]\n",
      "global_step 128325 , loss 8.287502\n",
      "global_step 128425 , loss 6.745254\n",
      "global_step 128525 , loss 8.26576\n",
      "global_step 128625 , loss 8.210577\n",
      "global_step 128725 , loss 8.628315\n",
      "global_step 128825 , loss 7.212199\n",
      "global_step 128925 , loss 6.450697\n",
      "global_step 129025 , loss 7.9741054\n",
      "global_step 129125 , loss 9.062957\n",
      "INFO:tensorflow:global_step/sec: 378.998\n",
      "global_step 129225 , loss 8.4891205\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  219.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    1.    0.    0.    0.    0.  303.]]\n",
      " true labels train [ 791.    1.  100.  134.    1. 1000.    1.  464.   10.  485.]\n",
      " pred labels train [7.8003e+02 1.0000e+00 9.1398e+01 1.3786e+02 1.0000e+00 1.0288e+03\n",
      " 4.3543e+00 4.6578e+02 1.0414e+01 5.0175e+02]\n",
      " all vars norms [217.73009, 0.53561723, 118.557106, 22.092125, 27.16898, 1.0000185]\n",
      "global_step 129325 , loss 6.9131575\n",
      "global_step 129425 , loss 9.000217\n",
      "global_step 129525 , loss 7.8550367\n",
      "global_step 129625 , loss 7.608548\n",
      "global_step 129725 , loss 5.7466164\n",
      "global_step 129825 , loss 7.3206234\n",
      "global_step 129925 , loss 10.302027\n",
      "global_step 130025 , loss 6.479237\n",
      "global_step 130125 , loss 6.487938\n",
      "global_step 130225 , loss 6.4594984\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  970.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    1.    0.    0.    0.    0.    6.]]\n",
      " true labels train [980.   3.  10. 556.   1. 547.  10. 642. 636. 376.]\n",
      " pred labels train [9.9044e+02 9.9990e-01 9.9395e+00 5.7356e+02 6.0834e-01 5.5686e+02\n",
      " 1.0908e+00 6.4691e+02 6.3237e+02 3.8865e+02]\n",
      " all vars norms [218.24399, 0.53557664, 118.86933, 22.153254, 27.219564, 0.99997246]\n",
      "global_step 130325 , loss 8.151113\n",
      "global_step 130425 , loss 8.209125\n",
      "global_step 130525 , loss 8.196023\n",
      "global_step 130625 , loss 12.0148945\n",
      "global_step 130725 , loss 7.9053445\n",
      "global_step 130825 , loss 8.046234\n",
      "global_step 130925 , loss 7.403294\n",
      "global_step 131025 , loss 6.960655\n",
      "global_step 131125 , loss 8.286972\n",
      "global_step 131225 , loss 5.8760414\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   82.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   97.]]\n",
      " true labels train [  10.   97.  804.  708.  939. 1000.  785.  485.  100.    1.]\n",
      " pred labels train [ 10.9643  92.4108 812.699  728.2411 940.9092 972.1161 786.2139 486.6519\n",
      "  90.8562   1.0002]\n",
      " all vars norms [218.7889, 0.5356715, 119.24458, 22.214167, 27.278725, 1.000207]\n",
      "global_step 131325 , loss 11.852446\n",
      "global_step 131425 , loss 8.2814865\n",
      "global_step 131525 , loss 7.472219\n",
      "global_step 131625 , loss 6.86514\n",
      "global_step 131725 , loss 7.7400265\n",
      "global_step 131825 , loss 6.8944526\n",
      "global_step 131925 , loss 8.155465\n",
      "global_step 132025 , loss 8.575052\n",
      "global_step 132125 , loss 9.374435\n",
      "global_step 132225 , loss 6.9555016\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    1.  651.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  830.]]\n",
      " true labels train [ 100.  199.    1.    1.    1.   10.    5.   15. 1000.    1.]\n",
      " pred labels train [101.6505 198.5      1.0004   1.0004   1.0004   9.9059  15.7011  26.1983\n",
      " 977.7588   1.0004]\n",
      " all vars norms [219.30043, 0.5357214, 119.60807, 22.271164, 27.347446, 1.00028]\n",
      "global_step 132325 , loss 8.418617\n",
      "global_step 132425 , loss 9.2992935\n",
      "global_step 132525 , loss 8.935544\n",
      "global_step 132625 , loss 8.301559\n",
      "global_step 132725 , loss 9.398969\n",
      "global_step 132825 , loss 9.643822\n",
      "global_step 132925 , loss 6.0325723\n",
      "global_step 133025 , loss 7.3232126\n",
      "global_step 133125 , loss 9.251381\n",
      "global_step 133225 , loss 7.785188\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  365.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  748.]]\n",
      " true labels train [  1.   1.  10. 100.   1.   1.  39.   1.  14. 161.]\n",
      " pred labels train [  1.6545   0.9997   3.2351 102.6584   3.2008  -3.4848  49.4703   2.6477\n",
      "  12.0527 192.9307]\n",
      " all vars norms [219.82838, 0.53546315, 119.917946, 22.33787, 27.415424, 0.9997087]\n",
      "global_step 133325 , loss 7.268638\n",
      "global_step 133425 , loss 7.9472504\n",
      "global_step 133525 , loss 5.612563\n",
      "global_step 133625 , loss 8.246885\n",
      "global_step 133725 , loss 7.7988815\n",
      "global_step 133825 , loss 7.492564\n",
      "global_step 133925 , loss 8.6686945\n",
      "global_step 134025 , loss 6.0593967\n",
      "global_step 134125 , loss 8.389494\n",
      "INFO:tensorflow:global_step/sec: 397.215\n",
      "global_step 134225 , loss 7.246245\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  766.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  172.]]\n",
      " true labels train [  1. 845.   1.  10.  10.   1.  10.   1. 961. 100.]\n",
      " pred labels train [  1.     851.5458   1.       9.5567   9.4101   1.      10.5213   1.\n",
      " 962.1343 102.7939]\n",
      " all vars norms [220.24379, 0.53595823, 120.26088, 22.394896, 27.463747, 0.99997336]\n",
      "global_step 134325 , loss 7.814457\n",
      "global_step 134425 , loss 7.1225777\n",
      "global_step 134525 , loss 8.06481\n",
      "global_step 134625 , loss 7.7259574\n",
      "global_step 134725 , loss 7.8708735\n",
      "global_step 134825 , loss 8.351074\n",
      "global_step 134925 , loss 9.101303\n",
      "global_step 135025 , loss 8.406858\n",
      "global_step 135125 , loss 6.599868\n",
      "global_step 135225 , loss 7.603319\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  506.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  885.]]\n",
      " true labels train [ 185.  899.    1. 1000.   18.    9.   39.  616.  705.  829.]\n",
      " pred labels train [2.9888e+00 8.7564e+02 9.9990e-01 1.0110e+03 9.8141e+00 4.5925e+00\n",
      " 3.7945e+01 6.2586e+02 7.0858e+02 8.4263e+02]\n",
      " all vars norms [220.75002, 0.5357561, 120.52625, 22.458797, 27.507359, 0.9997835]\n",
      "global_step 135325 , loss 7.6802845\n",
      "global_step 135425 , loss 5.1636972\n",
      "global_step 135525 , loss 7.5292006\n",
      "global_step 135625 , loss 7.956812\n",
      "global_step 135725 , loss 7.815048\n",
      "global_step 135825 , loss 6.755167\n",
      "global_step 135925 , loss 8.387678\n",
      "global_step 136025 , loss 9.495546\n",
      "global_step 136125 , loss 7.70242\n",
      "global_step 136225 , loss 8.270712\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    1.    0.    0.    0.  964.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  397.]]\n",
      " true labels train [  1. 384.  13. 939.   1.  19. 284. 676. 175. 492.]\n",
      " pred labels train [  1.0002 412.3169  11.0283 938.1382   1.4607  18.5086 293.7945 662.6264\n",
      " 153.2097 500.3315]\n",
      " all vars norms [221.23485, 0.5356675, 120.83663, 22.51789, 27.553242, 1.0000495]\n",
      "global_step 136325 , loss 7.591394\n",
      "global_step 136425 , loss 6.8123055\n",
      "global_step 136525 , loss 8.16184\n",
      "global_step 136625 , loss 8.325951\n",
      "global_step 136725 , loss 11.137004\n",
      "global_step 136825 , loss 6.9618063\n",
      "global_step 136925 , loss 8.067025\n",
      "global_step 137025 , loss 8.025312\n",
      "global_step 137125 , loss 8.496983\n",
      "global_step 137225 , loss 8.614632\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  580.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    1.    4.]]\n",
      " true labels train [  8.   1. 858.   9. 732.   1.  15.  83. 896.  71.]\n",
      " pred labels train [  9.7704  -5.8231 852.947    1.0151 723.4466   1.0002  10.4334  92.6114\n",
      " 899.466   66.3449]\n",
      " all vars norms [221.70703, 0.53592175, 121.12948, 22.573868, 27.605118, 1.0002198]\n",
      "global_step 137325 , loss 7.049634\n",
      "global_step 137425 , loss 7.111603\n",
      "global_step 137525 , loss 5.925685\n",
      "global_step 137625 , loss 7.9919996\n",
      "global_step 137725 , loss 9.765617\n",
      "global_step 137825 , loss 8.32337\n",
      "global_step 137925 , loss 7.2298136\n",
      "global_step 138025 , loss 10.89676\n",
      "global_step 138125 , loss 7.1617556\n",
      "global_step 138225 , loss 7.096862\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    1.    0.    0.    0.   78.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  990.]]\n",
      " true labels train [ 26.  13. 447. 623. 208.   1. 855. 871.   1.   1.]\n",
      " pred labels train [2.5707e+01 1.4192e+01 4.5486e+02 6.5650e+02 1.9899e+02 6.6075e-01\n",
      " 8.2883e+02 8.8085e+02 1.1310e+00 9.9985e-01]\n",
      " all vars norms [222.20741, 0.5358587, 121.411354, 22.636683, 27.656292, 1.0000136]\n",
      "global_step 138325 , loss 8.133838\n",
      "global_step 138425 , loss 7.782484\n",
      "global_step 138525 , loss 7.030732\n",
      "global_step 138625 , loss 7.0871468\n",
      "global_step 138725 , loss 8.344514\n",
      "global_step 138825 , loss 6.69951\n",
      "global_step 138925 , loss 10.141836\n",
      "global_step 139025 , loss 8.245504\n",
      "global_step 139125 , loss 6.7596016\n",
      "INFO:tensorflow:global_step/sec: 393.829\n",
      "global_step 139225 , loss 9.529268\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  140.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  549.]]\n",
      " true labels train [865. 550. 511. 528. 978.   1. 100.   1.  10. 835.]\n",
      " pred labels train [878.2151 557.8046 506.331  522.4777 970.8657   0.9996  96.1279   0.9996\n",
      "   9.8543 851.4769]\n",
      " all vars norms [222.64392, 0.5356005, 121.720604, 22.704483, 27.698784, 0.9996429]\n",
      "global_step 139325 , loss 9.370637\n",
      "global_step 139425 , loss 8.094631\n",
      "global_step 139525 , loss 9.627615\n",
      "global_step 139625 , loss 7.5863624\n",
      "global_step 139725 , loss 9.629243\n",
      "global_step 139825 , loss 8.0655155\n",
      "global_step 139925 , loss 7.1336985\n",
      "global_step 140025 , loss 7.7080355\n",
      "global_step 140125 , loss 8.493483\n",
      "global_step 140225 , loss 8.338835\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   70.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  729.]]\n",
      " true labels train [  10.    1.  100. 1000.   10.   10.  389.    2.    1.    9.]\n",
      " pred labels train [8.5176e+00 1.0001e+00 9.4547e+01 1.0020e+03 5.7927e+00 3.8043e+00\n",
      " 3.9514e+02 1.4980e+00 3.8019e+02 5.6777e+00]\n",
      " all vars norms [223.07971, 0.53600544, 122.02148, 22.771988, 27.750458, 1.0000271]\n",
      "global_step 140325 , loss 7.4544973\n",
      "global_step 140425 , loss 7.350677\n",
      "global_step 140525 , loss 8.2550535\n",
      "global_step 140625 , loss 6.1865854\n",
      "global_step 140725 , loss 11.773745\n",
      "global_step 140825 , loss 7.487174\n",
      "global_step 140925 , loss 6.587142\n",
      "global_step 141025 , loss 6.0309696\n",
      "global_step 141125 , loss 8.507211\n",
      "global_step 141225 , loss 7.109167\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  199.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  611.]]\n",
      " true labels train [804. 376. 556. 292.  31. 490.   1. 525.   1. 100.]\n",
      " pred labels train [703.905  409.3331 568.3286 306.3961  23.7517 492.9012   0.9999 544.6787\n",
      "   1.393  102.2865]\n",
      " all vars norms [223.52823, 0.5358085, 122.330025, 22.830082, 27.800465, 0.9999319]\n",
      "global_step 141325 , loss 10.43202\n",
      "global_step 141425 , loss 7.77505\n",
      "global_step 141525 , loss 7.227959\n",
      "global_step 141625 , loss 7.0739465\n",
      "global_step 141725 , loss 7.35465\n",
      "global_step 141825 , loss 6.398701\n",
      "global_step 141925 , loss 10.403493\n",
      "global_step 142025 , loss 8.15902\n",
      "global_step 142125 , loss 7.5574007\n",
      "global_step 142225 , loss 6.8101287\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   70.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  908.]]\n",
      " true labels train [ 10.  10.   1.  11.  81. 629. 315.   1. 979.   1.]\n",
      " pred labels train [ 10.3963  11.367    1.0001   8.767   79.187  630.5323 340.5436   1.0001\n",
      " 988.6451   1.0001]\n",
      " all vars norms [224.0259, 0.5356695, 122.628044, 22.882648, 27.845911, 1.0000285]\n",
      "global_step 142325 , loss 9.381154\n",
      "global_step 142425 , loss 7.371692\n",
      "global_step 142525 , loss 7.5361047\n",
      "INFO:tensorflow:Saving checkpoints for 142561 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 142625 , loss 7.977481\n",
      "global_step 142725 , loss 7.011382\n",
      "global_step 142825 , loss 10.558673\n",
      "global_step 142925 , loss 7.3486753\n",
      "global_step 143025 , loss 6.3804708\n",
      "global_step 143125 , loss 8.396189\n",
      "global_step 143225 , loss 6.985178\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    1.    0.    0.    0.   46.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    1.    0.    0.    0.   96.]]\n",
      " true labels train [ 56.   1.  16. 246. 165. 100. 413.  51. 496.  50.]\n",
      " pred labels train [ 65.7001  10.9443   9.0545 249.6    148.5237  99.6065 410.7102  52.3809\n",
      " 502.9889  61.682 ]\n",
      " all vars norms [224.47282, 0.53589433, 122.96104, 22.943922, 27.897104, 1.0000359]\n",
      "global_step 143325 , loss 9.636245\n",
      "global_step 143425 , loss 7.052451\n",
      "global_step 143525 , loss 7.4135385\n",
      "global_step 143625 , loss 10.028906\n",
      "global_step 143725 , loss 7.7707634\n",
      "global_step 143825 , loss 7.264425\n",
      "global_step 143925 , loss 7.6567097\n",
      "global_step 144025 , loss 7.451212\n",
      "global_step 144125 , loss 9.686715\n",
      "INFO:tensorflow:global_step/sec: 336.912\n",
      "global_step 144225 , loss 8.06785\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  902.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  512.]]\n",
      " true labels train [105.   1.  10.  85.  14. 895. 701.  11. 301.   1.]\n",
      " pred labels train [129.7022   0.9999  10.5277  83.758   10.8286 919.2935 704.3559  11.5424\n",
      " 306.1129   0.9999]\n",
      " all vars norms [224.97641, 0.53580064, 123.25995, 22.999374, 27.949894, 0.9999556]\n",
      "global_step 144325 , loss 7.106221\n",
      "global_step 144425 , loss 8.251805\n",
      "global_step 144525 , loss 7.5585084\n",
      "global_step 144625 , loss 8.198259\n",
      "global_step 144725 , loss 6.657916\n",
      "global_step 144825 , loss 7.950141\n",
      "global_step 144925 , loss 7.864621\n",
      "global_step 145025 , loss 7.158882\n",
      "global_step 145125 , loss 7.5331593\n",
      "global_step 145225 , loss 8.27627\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  807.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  341.]]\n",
      " true labels train [   1.    1.    1.   67. 1000.  914.  559.  195.  100.    1.]\n",
      " pred labels train [  1.0003   1.0003   1.0003  59.7487 988.4191 925.1851 568.142  207.964\n",
      " 107.5149   1.933 ]\n",
      " all vars norms [225.44571, 0.53600925, 123.58812, 23.057102, 28.00542, 1.0003682]\n",
      "global_step 145325 , loss 6.081174\n",
      "global_step 145425 , loss 9.581762\n",
      "global_step 145525 , loss 8.119663\n",
      "global_step 145625 , loss 6.849166\n",
      "global_step 145725 , loss 7.0876393\n",
      "global_step 145825 , loss 7.9162254\n",
      "global_step 145925 , loss 9.229185\n",
      "global_step 146025 , loss 7.4677324\n",
      "global_step 146125 , loss 7.443639\n",
      "global_step 146225 , loss 11.099096\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   22.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  726.]]\n",
      " true labels train [  75.  312. 1000.    1.   10.   13.    1.    2.   21.    1.]\n",
      " pred labels train [ 6.6760e+01  3.5606e+02  1.0024e+03  1.0000e+00  1.0180e+01  1.0289e+01\n",
      "  1.0000e+00 -6.9168e+00  1.4844e+01  1.0000e+00]\n",
      " all vars norms [225.90247, 0.5357867, 123.9065, 23.11789, 28.057905, 0.999985]\n",
      "global_step 146325 , loss 6.570621\n",
      "global_step 146425 , loss 7.5515594\n",
      "global_step 146525 , loss 8.173973\n",
      "global_step 146625 , loss 6.8700256\n",
      "global_step 146725 , loss 6.822891\n",
      "global_step 146825 , loss 7.4196334\n",
      "global_step 146925 , loss 7.9739966\n",
      "global_step 147025 , loss 9.026946\n",
      "global_step 147125 , loss 5.8104744\n",
      "global_step 147225 , loss 6.2735662\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   10.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  940.]]\n",
      " true labels train [ 25.   1. 100.   1. 136.  10. 420.  13. 477. 725.]\n",
      " pred labels train [ 24.5962   1.0002  93.2365   1.0002 166.8785   3.0069 412.7843  11.9453\n",
      " 483.2628 729.4388]\n",
      " all vars norms [226.38889, 0.53606325, 124.248985, 23.163435, 28.111118, 1.0001372]\n",
      "global_step 147325 , loss 6.339176\n",
      "global_step 147425 , loss 7.145175\n",
      "global_step 147525 , loss 7.0872245\n",
      "global_step 147625 , loss 7.2952943\n",
      "global_step 147725 , loss 7.7087917\n",
      "global_step 147825 , loss 6.5306425\n",
      "global_step 147925 , loss 8.700531\n",
      "global_step 148025 , loss 7.369399\n",
      "global_step 148125 , loss 6.622947\n",
      "global_step 148225 , loss 5.9007015\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  979.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  525.]]\n",
      " true labels train [ 33. 982.  10.  14. 858. 863.   1.  10. 615.   1.]\n",
      " pred labels train [ 41.4431 974.3745   9.2687  13.2013 867.0805 882.1365   1.0005   9.1688\n",
      " 622.517    1.0005]\n",
      " all vars norms [226.84023, 0.5361072, 124.54953, 23.221052, 28.165766, 1.0005012]\n",
      "global_step 148325 , loss 9.1492405\n",
      "global_step 148425 , loss 9.232396\n",
      "global_step 148525 , loss 6.879842\n",
      "global_step 148625 , loss 10.64751\n",
      "global_step 148725 , loss 8.497705\n",
      "global_step 148825 , loss 7.8164477\n",
      "global_step 148925 , loss 6.278916\n",
      "global_step 149025 , loss 8.603432\n",
      "global_step 149125 , loss 7.4111547\n",
      "INFO:tensorflow:global_step/sec: 312.88\n",
      "global_step 149225 , loss 7.3194184\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   87.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  593.]]\n",
      " true labels train [ 920.  404.  717.    9.  204. 1000.    1.    1.    1.  712.]\n",
      " pred labels train [9.1106e+02 4.0085e+02 6.9650e+02 1.2026e+01 2.1925e+02 1.0181e+03\n",
      " 1.0000e+00 1.0000e+00 1.0000e+00 7.0610e+02]\n",
      " all vars norms [227.29314, 0.5358752, 124.85775, 23.284235, 28.22705, 1.000091]\n",
      "global_step 149325 , loss 8.869823\n",
      "global_step 149425 , loss 7.2608595\n",
      "global_step 149525 , loss 6.4403343\n",
      "global_step 149625 , loss 6.5219436\n",
      "global_step 149725 , loss 6.668417\n",
      "global_step 149825 , loss 6.98993\n",
      "global_step 149925 , loss 10.14798\n",
      "global_step 150025 , loss 6.247992\n",
      "global_step 150125 , loss 6.737481\n",
      "global_step 150225 , loss 6.907029\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    1.  957.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  110.]]\n",
      " true labels train [ 100.  890.   11.  981.    1.  580. 1000.  100.    1.  100.]\n",
      " pred labels train [ 96.422  895.7241  10.8005 981.6392   1.     571.8209 990.3495 102.5091\n",
      "   2.626  104.3328]\n",
      " all vars norms [227.83301, 0.53607726, 125.125465, 23.331446, 28.267384, 0.99987954]\n",
      "global_step 150325 , loss 9.632114\n",
      "global_step 150425 , loss 6.391005\n",
      "global_step 150525 , loss 6.8273616\n",
      "global_step 150625 , loss 8.430428\n",
      "global_step 150725 , loss 5.9742756\n",
      "global_step 150825 , loss 8.740639\n",
      "global_step 150925 , loss 6.9189653\n",
      "global_step 151025 , loss 9.750751\n",
      "global_step 151125 , loss 6.6769114\n",
      "global_step 151225 , loss 6.865227\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   14.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  191.]]\n",
      " true labels train [  1. 830. 965.   1.   1.  13. 933.  83.  13. 894.]\n",
      " pred labels train [  1.0001 823.9258 956.3535  42.7468   1.0001  12.3175 944.7561  87.1063\n",
      "  10.6318 896.8765]\n",
      " all vars norms [228.32454, 0.53622496, 125.38881, 23.38509, 28.285044, 1.0000772]\n",
      "global_step 151325 , loss 6.7309685\n",
      "global_step 151425 , loss 6.1891003\n",
      "global_step 151525 , loss 5.9311724\n",
      "global_step 151625 , loss 12.802208\n",
      "global_step 151725 , loss 6.9028883\n",
      "global_step 151825 , loss 8.431238\n",
      "global_step 151925 , loss 6.9446816\n",
      "global_step 152025 , loss 5.90776\n",
      "global_step 152125 , loss 10.729341\n",
      "global_step 152225 , loss 6.9678016\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  248.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  372.]]\n",
      " true labels train [ 257.   13.   67. 1000.   10.  914.  518.    1.    5.   10.]\n",
      " pred labels train [246.2949  11.5652  63.7247 960.3336   9.6545 904.2107 513.5079   0.9997\n",
      "   1.4284   9.1285]\n",
      " all vars norms [228.76143, 0.53619, 125.65574, 23.444672, 28.318806, 0.99973047]\n",
      "global_step 152325 , loss 7.5625944\n",
      "global_step 152425 , loss 7.5152254\n",
      "global_step 152525 , loss 7.575615\n",
      "global_step 152625 , loss 9.256063\n",
      "global_step 152725 , loss 6.548624\n",
      "global_step 152825 , loss 6.2103453\n",
      "global_step 152925 , loss 6.729248\n",
      "global_step 153025 , loss 6.5898046\n",
      "global_step 153125 , loss 8.650315\n",
      "global_step 153225 , loss 8.265446\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    1.  857.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  915.]]\n",
      " true labels train [100. 102.   1.  10. 786. 857.   1. 335.   1. 202.]\n",
      " pred labels train [ 90.2014  84.7523   1.0001   8.9909 797.4366 875.8428   1.0001 322.7424\n",
      "  -2.7676 189.9545]\n",
      " all vars norms [229.31206, 0.5362905, 125.938416, 23.484463, 28.36035, 1.0002593]\n",
      "global_step 153325 , loss 7.4023685\n",
      "global_step 153425 , loss 9.675358\n",
      "global_step 153525 , loss 8.450531\n",
      "global_step 153625 , loss 7.8837337\n",
      "global_step 153725 , loss 8.203688\n",
      "global_step 153825 , loss 6.1237316\n",
      "global_step 153925 , loss 8.169029\n",
      "global_step 154025 , loss 8.444414\n",
      "global_step 154125 , loss 6.7539005\n",
      "INFO:tensorflow:global_step/sec: 314.751\n",
      "global_step 154225 , loss 6.801502\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    1.   70.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  653.]]\n",
      " true labels train [  70.    1.    1.  762.    1.    1.   10. 1000. 1000.   13.]\n",
      " pred labels train [ 75.6646   1.       1.     776.8964   1.1985  -3.9219  11.5566 943.2643\n",
      " 954.8526  10.251 ]\n",
      " all vars norms [229.80867, 0.5360806, 126.22458, 23.54499, 28.400322, 0.99998087]\n",
      "global_step 154325 , loss 7.7502365\n",
      "global_step 154425 , loss 9.630394\n",
      "global_step 154525 , loss 8.458746\n",
      "global_step 154625 , loss 7.161914\n",
      "global_step 154725 , loss 7.4578547\n",
      "global_step 154825 , loss 7.2043886\n",
      "global_step 154925 , loss 6.985744\n",
      "global_step 155025 , loss 6.837579\n",
      "global_step 155125 , loss 7.351017\n",
      "global_step 155225 , loss 8.302858\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  507.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  211.]]\n",
      " true labels train [ 185. 1000.    1.  100.   43.  520.   14.    1.    1.   77.]\n",
      " pred labels train [  5.1448 987.2098   4.4938  80.3158  33.9893 521.118   14.2122   0.9999\n",
      "   0.9999  75.9382]\n",
      " all vars norms [230.27426, 0.5361309, 126.531906, 23.609518, 28.443008, 1.0000199]\n",
      "global_step 155325 , loss 6.1710615\n",
      "global_step 155425 , loss 8.167347\n",
      "global_step 155525 , loss 7.1402407\n",
      "global_step 155625 , loss 7.2447233\n",
      "global_step 155725 , loss 6.5832825\n",
      "global_step 155825 , loss 7.3265915\n",
      "global_step 155925 , loss 10.825437\n",
      "global_step 156025 , loss 5.6723766\n",
      "global_step 156125 , loss 7.1856604\n",
      "global_step 156225 , loss 6.674711\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    1.  672.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    1.    0.   45.]]\n",
      " true labels train [100.  44. 485. 576.  76.  26.   1.  10. 185.  10.]\n",
      " pred labels train [102.7275  40.7546 466.4487 581.0832  78.3146  20.8847   1.6915   9.8018\n",
      " 194.0922  10.2259]\n",
      " all vars norms [230.75813, 0.53622675, 126.83071, 23.66723, 28.496769, 0.99948347]\n",
      "global_step 156325 , loss 8.085041\n",
      "global_step 156425 , loss 6.3327265\n",
      "global_step 156525 , loss 6.667651\n",
      "global_step 156625 , loss 6.677698\n",
      "global_step 156725 , loss 7.197836\n",
      "global_step 156825 , loss 6.304639\n",
      "global_step 156925 , loss 8.607472\n",
      "global_step 157025 , loss 10.8071785\n",
      "global_step 157125 , loss 7.5410743\n",
      "global_step 157225 , loss 8.848724\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  888.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   50.]]\n",
      " true labels train [   1.  951.  964.  585.  100.    1.   12.   95.  939. 1000.]\n",
      " pred labels train [  1.0001 952.1796 941.7828 577.0117 105.5653   2.9097  10.0521  96.9149\n",
      " 930.0192 992.1494]\n",
      " all vars norms [231.25159, 0.5360111, 127.11468, 23.712477, 28.552443, 1.0001876]\n",
      "global_step 157325 , loss 6.8684907\n",
      "global_step 157425 , loss 6.578886\n",
      "global_step 157525 , loss 14.503281\n",
      "global_step 157625 , loss 7.520817\n",
      "global_step 157725 , loss 6.825275\n",
      "global_step 157825 , loss 6.534403\n",
      "global_step 157925 , loss 7.7114534\n",
      "global_step 158025 , loss 7.913096\n",
      "global_step 158125 , loss 7.1223965\n",
      "global_step 158225 , loss 6.7813177\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    1.    0.    0.    0.  899.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  792.]]\n",
      " true labels train [  1.  10. 410.   1. 134.   1. 867.   5.  76. 258.]\n",
      " pred labels train [  1.0003   9.8421 428.6223   1.0003 136.2999   1.0003 872.8692   1.7898\n",
      "  85.6251 273.8562]\n",
      " all vars norms [231.79454, 0.5362886, 127.4007, 23.771383, 28.611578, 1.0002434]\n",
      "global_step 158325 , loss 7.131898\n",
      "global_step 158425 , loss 6.2757063\n",
      "global_step 158525 , loss 8.443253\n",
      "global_step 158625 , loss 7.070819\n",
      "global_step 158725 , loss 5.5948277\n",
      "global_step 158825 , loss 7.6091495\n",
      "global_step 158925 , loss 7.9070168\n",
      "global_step 159025 , loss 8.559098\n",
      "global_step 159125 , loss 8.7735195\n",
      "INFO:tensorflow:global_step/sec: 357.686\n",
      "global_step 159225 , loss 6.594017\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  833.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  157.]]\n",
      " true labels train [ 10. 860.  43.   1.   1. 328.   1. 100.   1. 473.]\n",
      " pred labels train [  9.9284 848.7996  44.9302   1.       1.     322.666    1.     101.5889\n",
      "  -4.6957 474.9947]\n",
      " all vars norms [232.25514, 0.5362316, 127.64707, 23.827566, 28.647505, 0.999953]\n",
      "global_step 159325 , loss 7.1998076\n",
      "global_step 159425 , loss 6.2210083\n",
      "global_step 159525 , loss 8.320274\n",
      "global_step 159625 , loss 8.109275\n",
      "global_step 159725 , loss 7.74595\n",
      "global_step 159825 , loss 6.927063\n",
      "global_step 159925 , loss 7.5239964\n",
      "global_step 160025 , loss 7.7747536\n",
      "global_step 160125 , loss 7.975029\n",
      "global_step 160225 , loss 6.705965\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    1.  641.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  248.]]\n",
      " true labels train [ 100.    1.  710.  280.   14.    1.    2.  100.   10. 1000.]\n",
      " pred labels train [ 99.0415   1.     719.7122 291.9029  11.2623   1.      15.0267 103.3533\n",
      "   9.3068 987.5454]\n",
      " all vars norms [232.6739, 0.5362336, 127.95211, 23.885254, 28.683508, 0.99992764]\n",
      "global_step 160325 , loss 10.828594\n",
      "global_step 160425 , loss 7.1925306\n",
      "global_step 160525 , loss 6.800237\n",
      "global_step 160625 , loss 7.6130204\n",
      "global_step 160725 , loss 7.7833843\n",
      "global_step 160825 , loss 6.731044\n",
      "global_step 160925 , loss 11.703988\n",
      "global_step 161025 , loss 8.487694\n",
      "global_step 161125 , loss 7.494275\n",
      "global_step 161225 , loss 6.6492634\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  406.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  958.]]\n",
      " true labels train [ 617.  956.  539.    1.   91.    1.    1.   10.  979. 1000.]\n",
      " pred labels train [613.3823 957.1536 543.1506   1.      91.5546   1.1674   1.      10.0418\n",
      " 979.2472 999.5858]\n",
      " all vars norms [233.10992, 0.53615165, 128.22336, 23.942587, 28.735985, 1.0000985]\n",
      "global_step 161325 , loss 7.4177637\n",
      "global_step 161425 , loss 9.089167\n",
      "global_step 161525 , loss 7.5548315\n",
      "global_step 161625 , loss 5.6852293\n",
      "global_step 161725 , loss 10.0968275\n",
      "global_step 161825 , loss 7.7041073\n",
      "global_step 161925 , loss 8.383378\n",
      "global_step 162025 , loss 7.0246305\n",
      "global_step 162125 , loss 10.072123\n",
      "global_step 162225 , loss 8.500634\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  229.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    1.    0.   86.]]\n",
      " true labels train [   1.   85.    1. 1000.   10.    1.   85.    1.  100.  876.]\n",
      " pred labels train [4.9656e+01 8.1812e+01 1.0000e+00 1.0117e+03 1.0407e+01 1.0000e+00\n",
      " 8.1287e+01 1.0000e+00 9.8489e+01 8.8256e+02]\n",
      " all vars norms [233.55006, 0.53638315, 128.47968, 23.990654, 28.752106, 1.0000135]\n",
      "global_step 162325 , loss 7.4748573\n",
      "global_step 162425 , loss 9.018078\n",
      "INFO:tensorflow:Saving checkpoints for 162483 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 162525 , loss 8.319479\n",
      "global_step 162625 , loss 7.8719225\n",
      "global_step 162725 , loss 7.3083076\n",
      "global_step 162825 , loss 6.3013186\n",
      "global_step 162925 , loss 8.70487\n",
      "global_step 163025 , loss 5.537799\n",
      "global_step 163125 , loss 5.91948\n",
      "global_step 163225 , loss 8.749428\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  585.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  967.]]\n",
      " true labels train [  10. 1000.  804.   97.  714.  847.    1.   14.    1.  329.]\n",
      " pred labels train [  0.9999 995.0611 790.6616 100.6339 715.4715 855.0811   0.9999  12.8594\n",
      "   2.107  340.9354]\n",
      " all vars norms [234.0144, 0.5363669, 128.7461, 24.045212, 28.793127, 0.9998756]\n",
      "global_step 163325 , loss 9.341141\n",
      "global_step 163425 , loss 7.655616\n",
      "global_step 163525 , loss 7.539673\n",
      "global_step 163625 , loss 6.151727\n",
      "global_step 163725 , loss 6.8055277\n",
      "global_step 163825 , loss 8.077435\n",
      "global_step 163925 , loss 7.8599625\n",
      "global_step 164025 , loss 11.365424\n",
      "global_step 164125 , loss 8.420684\n",
      "INFO:tensorflow:global_step/sec: 350.925\n",
      "global_step 164225 , loss 7.450349\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  498.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  164.]]\n",
      " true labels train [  1.   9.  17.  59.  80.  10.  10. 866.  18. 511.]\n",
      " pred labels train [  1.5512   8.7485  10.6923  52.7064  81.66     9.8973   9.9115 867.7776\n",
      "  14.901  506.1785]\n",
      " all vars norms [234.57028, 0.5361755, 129.03659, 24.096552, 28.83554, 1.0001185]\n",
      "global_step 164325 , loss 7.647658\n",
      "global_step 164425 , loss 7.9424896\n",
      "global_step 164525 , loss 6.620315\n",
      "global_step 164625 , loss 5.685136\n",
      "global_step 164725 , loss 7.3294826\n",
      "global_step 164825 , loss 8.118149\n",
      "global_step 164925 , loss 11.58141\n",
      "global_step 165025 , loss 6.450655\n",
      "global_step 165125 , loss 8.086305\n",
      "global_step 165225 , loss 7.8613124\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   30.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  494.]]\n",
      " true labels train [   1.  477. 1000.   14.   11.   10.  896.  100.   10.   52.]\n",
      " pred labels train [  1.3258 493.0318 998.9895  12.3995  11.444   10.1932 921.7916 106.9846\n",
      "   1.1542  39.119 ]\n",
      " all vars norms [235.03087, 0.5363666, 129.32431, 24.155432, 28.895576, 1.0000136]\n",
      "global_step 165325 , loss 7.0835457\n",
      "global_step 165425 , loss 6.269069\n",
      "global_step 165525 , loss 7.515421\n",
      "global_step 165625 , loss 7.0326824\n",
      "global_step 165725 , loss 5.534363\n",
      "global_step 165825 , loss 5.997881\n",
      "global_step 165925 , loss 6.937368\n",
      "global_step 166025 , loss 6.827025\n",
      "global_step 166125 , loss 7.925129\n",
      "global_step 166225 , loss 8.0482025\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    1.    0.    0.    0.    0.    3.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   78.]]\n",
      " true labels train [  2. 923. 100.   1.   1.   1. 485.  10.  10. 335.]\n",
      " pred labels train [  1.5527 927.7665  94.5225   1.7779   1.0537   1.     493.1397  11.0896\n",
      "  10.7533 329.3877]\n",
      " all vars norms [235.50386, 0.53645533, 129.59985, 24.215576, 28.927738, 1.0000006]\n",
      "global_step 166325 , loss 6.300425\n",
      "global_step 166425 , loss 7.9745464\n",
      "global_step 166525 , loss 6.563482\n",
      "global_step 166625 , loss 8.219605\n",
      "global_step 166725 , loss 10.230425\n",
      "global_step 166825 , loss 9.130879\n",
      "global_step 166925 , loss 7.445756\n",
      "global_step 167025 , loss 7.3646564\n",
      "global_step 167125 , loss 7.07594\n",
      "global_step 167225 , loss 5.8000298\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  432.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    1.  561.]]\n",
      " true labels train [426. 100. 584.   1.  56. 559. 115.   1.   1.  10.]\n",
      " pred labels train [439.1732 101.8726 551.0041   3.4749  55.3927 555.1799 107.9503  -0.5615\n",
      "   1.       9.1549]\n",
      " all vars norms [235.96857, 0.536173, 129.88118, 24.26418, 28.990377, 1.0000362]\n",
      "global_step 167325 , loss 5.7119823\n",
      "global_step 167425 , loss 8.415725\n",
      "global_step 167525 , loss 6.568126\n",
      "global_step 167625 , loss 7.3769865\n",
      "global_step 167725 , loss 6.7299347\n",
      "global_step 167825 , loss 8.668266\n",
      "global_step 167925 , loss 7.6707582\n",
      "global_step 168025 , loss 7.5838823\n",
      "global_step 168125 , loss 9.679195\n",
      "global_step 168225 , loss 7.651991\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  270.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  520.]]\n",
      " true labels train [724. 491.   1. 351. 343. 100. 249. 950. 246. 216.]\n",
      " pred labels train [715.9174 481.6051   1.     366.6886 362.7163 100.7741 235.9331 927.1519\n",
      " 244.5896 225.0636]\n",
      " all vars norms [236.39752, 0.5363332, 130.12369, 24.319067, 29.036182, 0.9999635]\n",
      "global_step 168325 , loss 5.579425\n",
      "global_step 168425 , loss 9.996681\n",
      "global_step 168525 , loss 7.6606793\n",
      "global_step 168625 , loss 7.5241785\n",
      "global_step 168725 , loss 6.271823\n",
      "global_step 168825 , loss 7.4215093\n",
      "global_step 168925 , loss 6.0631866\n",
      "global_step 169025 , loss 5.8303413\n",
      "global_step 169125 , loss 7.729583\n",
      "INFO:tensorflow:global_step/sec: 327.324\n",
      "global_step 169225 , loss 7.076463\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   96.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  660.]]\n",
      " true labels train [  12.  359.    1.  199.  642.  639.    1.    1. 1000. 1000.]\n",
      " pred labels train [  9.8247 405.5863   4.2872 199.6669 652.6441 642.2275   0.9999  -5.082\n",
      " 991.8393 999.2838]\n",
      " all vars norms [236.83464, 0.5366122, 130.40358, 24.37856, 29.075935, 0.99994206]\n",
      "global_step 169325 , loss 6.7850075\n",
      "global_step 169425 , loss 6.8550243\n",
      "global_step 169525 , loss 8.280336\n",
      "global_step 169625 , loss 5.8977184\n",
      "global_step 169725 , loss 6.5842824\n",
      "global_step 169825 , loss 6.606179\n",
      "global_step 169925 , loss 8.729288\n",
      "global_step 170025 , loss 6.7157617\n",
      "global_step 170125 , loss 6.7915587\n",
      "global_step 170225 , loss 9.296108\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    1.    0.    0.    0.  177.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  365.]]\n",
      " true labels train [100.   1. 105. 319.   1.   1. 184.   1.  10. 768.]\n",
      " pred labels train [ 80.0375   1.788  122.8664 333.8713   1.       1.     187.0226  -6.6554\n",
      "   9.6497 953.2428]\n",
      " all vars norms [237.24547, 0.536411, 130.65898, 24.433743, 29.119267, 1.0000831]\n",
      "global_step 170325 , loss 8.999605\n",
      "global_step 170425 , loss 5.918107\n",
      "global_step 170525 , loss 7.0865836\n",
      "global_step 170625 , loss 6.3884325\n",
      "global_step 170725 , loss 6.994711\n",
      "global_step 170825 , loss 6.554346\n",
      "global_step 170925 , loss 7.1427593\n",
      "global_step 171025 , loss 7.2899\n",
      "global_step 171125 , loss 6.5448723\n",
      "global_step 171225 , loss 7.1013584\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  109.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    1.    0.    0.    0.  946.]]\n",
      " true labels train [110.   1.   1.  82. 728. 477.  16.   1. 175.   1.]\n",
      " pred labels train [114.2179   0.9999   0.9999  49.6123 737.9689 480.9573  17.2195   0.9999\n",
      " 180.6166   0.9999]\n",
      " all vars norms [237.82263, 0.5360915, 130.94919, 24.486246, 29.14857, 1.0000813]\n",
      "global_step 171325 , loss 6.5808716\n",
      "global_step 171425 , loss 6.3598037\n",
      "global_step 171525 , loss 7.515433\n",
      "global_step 171625 , loss 7.303722\n",
      "global_step 171725 , loss 6.8484945\n",
      "global_step 171825 , loss 7.4127603\n",
      "global_step 171925 , loss 8.711878\n",
      "global_step 172025 , loss 7.532225\n",
      "global_step 172125 , loss 8.030438\n",
      "global_step 172225 , loss 6.928116\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  733.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  169.]]\n",
      " true labels train [ 733.  849.    1.  718.    1. 1000.  670.   12.    1.    1.]\n",
      " pred labels train [7.3688e+02 8.6401e+02 1.0001e+00 7.2994e+02 1.0001e+00 1.0056e+03\n",
      " 6.5148e+02 1.1625e+01 1.0001e+00 1.0001e+00]\n",
      " all vars norms [238.40485, 0.53619784, 131.23093, 24.530035, 29.194103, 1.0001782]\n",
      "global_step 172325 , loss 9.653154\n",
      "global_step 172425 , loss 8.364384\n",
      "global_step 172525 , loss 6.508719\n",
      "global_step 172625 , loss 9.120314\n",
      "global_step 172725 , loss 9.618103\n",
      "global_step 172825 , loss 8.847746\n",
      "global_step 172925 , loss 7.7778816\n",
      "global_step 173025 , loss 6.9465995\n",
      "global_step 173125 , loss 6.1175327\n",
      "global_step 173225 , loss 7.9017906\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  533.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  496.]]\n",
      " true labels train [481. 503.   1. 603.  10.  10.   7. 100.   1.  10.]\n",
      " pred labels train [483.3399 502.1819  18.4821 597.8513   9.6119   9.4127   9.1616 103.468\n",
      "   4.7274  10.5417]\n",
      " all vars norms [238.81535, 0.53630817, 131.5029, 24.58087, 29.235817, 1.0001465]\n",
      "global_step 173325 , loss 6.906718\n",
      "global_step 173425 , loss 6.585992\n",
      "global_step 173525 , loss 9.098485\n",
      "global_step 173625 , loss 7.1172957\n",
      "global_step 173725 , loss 5.442996\n",
      "global_step 173825 , loss 6.656743\n",
      "global_step 173925 , loss 8.673813\n",
      "global_step 174025 , loss 7.882678\n",
      "global_step 174125 , loss 6.714611\n",
      "INFO:tensorflow:global_step/sec: 363.077\n",
      "global_step 174225 , loss 8.960233\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  173.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   97.]]\n",
      " true labels train [ 177.   97.   10.    1.  518. 1000.  100.   10.   75.   10.]\n",
      " pred labels train [1.8695e+02 9.9003e+01 9.9110e+00 9.9991e-01 5.2239e+02 1.0126e+03\n",
      " 1.1209e+02 1.0673e+01 7.6736e+01 9.6282e+00]\n",
      " all vars norms [239.27988, 0.53652954, 131.77534, 24.642231, 29.280603, 0.9999423]\n",
      "global_step 174325 , loss 8.205382\n",
      "global_step 174425 , loss 6.178439\n",
      "global_step 174525 , loss 7.96453\n",
      "global_step 174625 , loss 6.4051857\n",
      "global_step 174725 , loss 7.4002824\n",
      "global_step 174825 , loss 6.6944227\n",
      "global_step 174925 , loss 7.8984547\n",
      "global_step 175025 , loss 6.8931766\n",
      "global_step 175125 , loss 5.860344\n",
      "global_step 175225 , loss 7.272941\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  879.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   53.]]\n",
      " true labels train [858. 951.   1. 878.  10. 479. 825.  13. 701.   1.]\n",
      " pred labels train [875.1857 940.2989   1.0002 862.4226  10.2283 480.1725 811.0504  23.4976\n",
      " 707.1782   1.0002]\n",
      " all vars norms [239.69579, 0.5363136, 132.03874, 24.690876, 29.306244, 1.0001618]\n",
      "global_step 175325 , loss 6.7847395\n",
      "global_step 175425 , loss 7.286743\n",
      "global_step 175525 , loss 8.089321\n",
      "global_step 175625 , loss 6.6201005\n",
      "global_step 175725 , loss 6.29708\n",
      "global_step 175825 , loss 5.8771896\n",
      "global_step 175925 , loss 6.1718693\n",
      "global_step 176025 , loss 5.966058\n",
      "global_step 176125 , loss 8.544519\n",
      "global_step 176225 , loss 9.252745\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  109.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    1.    0.   64.]]\n",
      " true labels train [110.  63.  76. 220.   9.   8. 979. 556. 100. 446.]\n",
      " pred labels train [124.5647  58.1292  73.6305 226.6835  12.1219  11.6054 986.1591 551.3046\n",
      " 107.0758 435.557 ]\n",
      " all vars norms [240.13254, 0.5367717, 132.30237, 24.749338, 29.336065, 0.9996174]\n",
      "global_step 176325 , loss 6.7153826\n",
      "global_step 176425 , loss 9.732478\n",
      "global_step 176525 , loss 6.576993\n",
      "global_step 176625 , loss 7.3384724\n",
      "global_step 176725 , loss 7.6644917\n",
      "global_step 176825 , loss 5.8536997\n",
      "global_step 176925 , loss 7.239168\n",
      "global_step 177025 , loss 7.909837\n",
      "global_step 177125 , loss 8.2516165\n",
      "global_step 177225 , loss 8.270605\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  366.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  109.]]\n",
      " true labels train [653. 110.   1.   1. 865. 653.  28.  10.   1. 100.]\n",
      " pred labels train [653.4914 109.1095   1.0001   1.0001 860.3463 643.439   24.4518  12.9807\n",
      "   2.5022  94.2511]\n",
      " all vars norms [240.67165, 0.5365603, 132.5516, 24.78477, 29.396301, 0.9998313]\n",
      "global_step 177325 , loss 7.7588186\n",
      "global_step 177425 , loss 6.4616218\n",
      "global_step 177525 , loss 6.729397\n",
      "global_step 177625 , loss 7.2792993\n",
      "global_step 177725 , loss 8.085057\n",
      "global_step 177825 , loss 6.8401184\n",
      "global_step 177925 , loss 9.734064\n",
      "global_step 178025 , loss 7.703562\n",
      "global_step 178125 , loss 6.4248257\n",
      "global_step 178225 , loss 8.247539\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  841.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  890.]]\n",
      " true labels train [ 178.  126.    1. 1000.  849.  376.   10.  100.    1.   21.]\n",
      " pred labels train [1.9376e+02 1.4869e+02 9.9999e-01 1.0184e+03 8.4802e+02 3.8317e+02\n",
      " 1.0199e+01 1.0072e+02 9.9999e-01 1.3842e+01]\n",
      " all vars norms [241.14514, 0.5367893, 132.83804, 24.834543, 29.442978, 0.9999829]\n",
      "global_step 178325 , loss 7.7855268\n",
      "global_step 178425 , loss 6.5819798\n",
      "global_step 178525 , loss 5.8841066\n",
      "global_step 178625 , loss 7.4529104\n",
      "global_step 178725 , loss 5.585047\n",
      "global_step 178825 , loss 7.072953\n",
      "global_step 178925 , loss 7.3153114\n",
      "global_step 179025 , loss 6.444241\n",
      "global_step 179125 , loss 5.714407\n",
      "INFO:tensorflow:global_step/sec: 363.849\n",
      "global_step 179225 , loss 6.4941874\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    1.    0.    4.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   39.]]\n",
      " true labels train [ 13. 979.   1. 980. 808.   1.   1. 567. 314.   1.]\n",
      " pred labels train [  7.4761 992.3648   2.9213 958.2487 793.5391   1.       1.     569.1927\n",
      " 303.496    1.7449]\n",
      " all vars norms [241.56717, 0.53634745, 133.09, 24.8916, 29.469662, 1.0000123]\n",
      "global_step 179325 , loss 6.761626\n",
      "global_step 179425 , loss 8.78789\n",
      "global_step 179525 , loss 6.707075\n",
      "global_step 179625 , loss 6.0956903\n",
      "global_step 179725 , loss 5.61442\n",
      "global_step 179825 , loss 8.245668\n",
      "global_step 179925 , loss 5.643739\n",
      "global_step 180025 , loss 7.594601\n",
      "global_step 180125 , loss 6.2131033\n",
      "global_step 180225 , loss 6.498328\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    1.    0.   45.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  904.]]\n",
      " true labels train [ 44. 127.   1. 420. 110.  26.   1.  31.   1.   9.]\n",
      " pred labels train [ 35.6686 110.7083   1.0002 417.6085  89.2822  43.7632   1.0002  38.1919\n",
      "   1.0002  10.0553]\n",
      " all vars norms [242.02359, 0.5365049, 133.34546, 24.942163, 29.487026, 1.0002398]\n",
      "global_step 180325 , loss 6.4988365\n",
      "global_step 180425 , loss 10.573861\n",
      "global_step 180525 , loss 5.727091\n",
      "global_step 180625 , loss 6.7446404\n",
      "global_step 180725 , loss 8.838996\n",
      "global_step 180825 , loss 8.79911\n",
      "global_step 180925 , loss 5.755898\n",
      "global_step 181025 , loss 7.5878563\n",
      "global_step 181125 , loss 7.0552077\n",
      "global_step 181225 , loss 7.6637883\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  203.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  827.]]\n",
      " true labels train [ 816.    1.   10.   10.  135.  601.  232.  864. 1000.   10.]\n",
      " pred labels train [813.3911   1.       9.8021   7.8772 138.6616 609.1225 262.7253 860.6901\n",
      " 999.1835   6.0875]\n",
      " all vars norms [242.45874, 0.536968, 133.61218, 24.994762, 29.537933, 0.99994934]\n",
      "global_step 181325 , loss 7.1030664\n",
      "global_step 181425 , loss 8.521095\n",
      "global_step 181525 , loss 7.607821\n",
      "global_step 181625 , loss 7.3173375\n",
      "global_step 181725 , loss 7.705722\n",
      "global_step 181825 , loss 8.378616\n",
      "global_step 181925 , loss 6.694097\n",
      "global_step 182025 , loss 7.6747313\n",
      "global_step 182125 , loss 7.1424384\n",
      "global_step 182225 , loss 5.726816\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  544.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  588.]]\n",
      " true labels train [ 550.    8.  173.  315.    9.  736.   10.    1.  950. 1000.]\n",
      " pred labels train [5.3079e+02 9.3858e+00 1.7542e+02 2.9721e+02 1.0514e+01 7.4147e+02\n",
      " 1.1409e+01 9.9998e-01 9.4618e+02 1.0008e+03]\n",
      " all vars norms [242.97475, 0.5363319, 133.90268, 25.044819, 29.593, 1.0000184]\n",
      "global_step 182325 , loss 7.1311684\n",
      "global_step 182425 , loss 5.641861\n",
      "global_step 182525 , loss 7.962999\n",
      "global_step 182625 , loss 7.7954464\n",
      "global_step 182725 , loss 7.4842567\n",
      "global_step 182825 , loss 6.409761\n",
      "global_step 182925 , loss 6.2379045\n",
      "global_step 183025 , loss 9.07974\n",
      "global_step 183125 , loss 7.108426\n",
      "global_step 183225 , loss 7.5987515\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  210.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  486.]]\n",
      " true labels train [233.  82.  16. 894.   1.  38.   1. 688.  10.  10.]\n",
      " pred labels train [247.2672 140.4191  10.9735 923.3917  24.1568  47.5669   2.0162 664.9659\n",
      "  11.0035   9.7572]\n",
      " all vars norms [243.37152, 0.5366198, 134.15779, 25.101046, 29.607586, 0.9998753]\n",
      "global_step 183325 , loss 7.3991528\n",
      "global_step 183425 , loss 7.267867\n",
      "global_step 183525 , loss 5.913727\n",
      "global_step 183625 , loss 6.8125396\n",
      "global_step 183725 , loss 6.6464834\n",
      "INFO:tensorflow:Saving checkpoints for 183742 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 183825 , loss 7.016825\n",
      "global_step 183925 , loss 6.8087807\n",
      "global_step 184025 , loss 10.48381\n",
      "global_step 184125 , loss 7.535632\n",
      "INFO:tensorflow:global_step/sec: 368.401\n",
      "global_step 184225 , loss 6.513634\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   22.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  959.]]\n",
      " true labels train [ 75.  10.   8. 199.   1. 100.  10. 292.  10.  39.]\n",
      " pred labels train [ 74.9607  10.836    8.3766 191.1011   1.      89.6667   9.8328 278.1868\n",
      "  10.8921  42.1456]\n",
      " all vars norms [243.82953, 0.53682274, 134.41302, 25.145576, 29.645996, 1.0000448]\n",
      "global_step 184325 , loss 7.725195\n",
      "global_step 184425 , loss 6.803626\n",
      "global_step 184525 , loss 6.2223997\n",
      "global_step 184625 , loss 6.864019\n",
      "global_step 184725 , loss 6.1816816\n",
      "global_step 184825 , loss 7.554888\n",
      "global_step 184925 , loss 6.342635\n",
      "global_step 185025 , loss 6.255615\n",
      "global_step 185125 , loss 6.2927628\n",
      "global_step 185225 , loss 6.8093843\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  253.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  495.]]\n",
      " true labels train [ 16.   8. 343.   1.  10.   1. 100. 322.   1.   1.]\n",
      " pred labels train [ 1.0102e+01  8.6570e+00  3.4752e+02  9.9997e-01  9.5428e+00 -2.1496e-01\n",
      "  1.0403e+02  3.1802e+02  7.9798e+00  9.9997e-01]\n",
      " all vars norms [244.23, 0.5363959, 134.6852, 25.196545, 29.674896, 0.9999657]\n",
      "global_step 185325 , loss 7.623843\n",
      "global_step 185425 , loss 7.758948\n",
      "global_step 185525 , loss 8.868191\n",
      "global_step 185625 , loss 5.8916464\n",
      "global_step 185725 , loss 7.7620277\n",
      "global_step 185825 , loss 7.120487\n",
      "global_step 185925 , loss 8.377061\n",
      "global_step 186025 , loss 7.4533467\n",
      "global_step 186125 , loss 7.9378576\n",
      "global_step 186225 , loss 5.654476\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  962.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  670.]]\n",
      " true labels train [ 10.   7.  10. 687.   1.  10.  10. 410. 815.   7.]\n",
      " pred labels train [ 10.7962  10.4023  10.0176 691.4496   1.      10.3871  10.7365 417.429\n",
      " 810.2221   2.2166]\n",
      " all vars norms [244.67442, 0.5365727, 134.94498, 25.241734, 29.721966, 0.99993604]\n",
      "global_step 186325 , loss 6.1758037\n",
      "global_step 186425 , loss 5.5049105\n",
      "global_step 186525 , loss 7.2961717\n",
      "global_step 186625 , loss 6.2882843\n",
      "global_step 186725 , loss 5.7250147\n",
      "global_step 186825 , loss 7.502291\n",
      "global_step 186925 , loss 8.128628\n",
      "global_step 187025 , loss 6.900134\n",
      "global_step 187125 , loss 6.995943\n",
      "global_step 187225 , loss 7.536566\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  300.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  824.]]\n",
      " true labels train [   1. 1000.    9.   13.  220.    1.  714.  100. 1000.   12.]\n",
      " pred labels train [  0.9996 990.9701  11.7483  11.0856 214.0431   0.9996 701.9215  80.3928\n",
      " 997.7637  11.2713]\n",
      " all vars norms [245.12372, 0.536802, 135.17209, 25.287996, 29.739094, 0.9995684]\n",
      "global_step 187325 , loss 7.4110994\n",
      "global_step 187425 , loss 7.343887\n",
      "global_step 187525 , loss 7.536925\n",
      "global_step 187625 , loss 6.6167006\n",
      "global_step 187725 , loss 6.4661946\n",
      "global_step 187825 , loss 8.05191\n",
      "global_step 187925 , loss 6.40611\n",
      "global_step 188025 , loss 6.7397275\n",
      "global_step 188125 , loss 6.4205484\n",
      "global_step 188225 , loss 6.02147\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   25.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  985.]]\n",
      " true labels train [ 26.  30. 100. 882.  10.  68.  53. 624. 315.   1.]\n",
      " pred labels train [ 13.5735  32.2532  95.6445 881.3224   9.9     68.6857  52.0216 607.6244\n",
      " 311.808    1.    ]\n",
      " all vars norms [245.59824, 0.5365277, 135.41165, 25.334862, 29.769352, 1.0000608]\n",
      "global_step 188325 , loss 6.153651\n",
      "global_step 188425 , loss 7.3187885\n",
      "global_step 188525 , loss 6.9765844\n",
      "global_step 188625 , loss 6.5692134\n",
      "global_step 188725 , loss 7.716582\n",
      "global_step 188825 , loss 14.239734\n",
      "global_step 188925 , loss 5.714322\n",
      "global_step 189025 , loss 8.218667\n",
      "global_step 189125 , loss 7.0716686\n",
      "INFO:tensorflow:global_step/sec: 350.948\n",
      "global_step 189225 , loss 7.368004\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    1.  291.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  475.]]\n",
      " true labels train [  1. 100.  75. 322. 653. 250.  10.   1. 847. 100.]\n",
      " pred labels train [  2.5573  98.3951  85.6776 420.7493 625.3278 257.1906   3.0498   1.\n",
      " 849.1124 100.0241]\n",
      " all vars norms [246.05444, 0.53674984, 135.67036, 25.379921, 29.795166, 0.99993026]\n",
      "global_step 189325 , loss 6.6236677\n",
      "global_step 189425 , loss 6.3084702\n",
      "global_step 189525 , loss 6.7628465\n",
      "global_step 189625 , loss 6.757357\n",
      "global_step 189725 , loss 9.351915\n",
      "global_step 189825 , loss 7.0751405\n",
      "global_step 189925 , loss 6.325894\n",
      "global_step 190025 , loss 7.388021\n",
      "global_step 190125 , loss 7.063721\n",
      "global_step 190225 , loss 6.141612\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  972.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  713.]]\n",
      " true labels train [100. 280. 315.   1. 632. 623. 217.   1. 815.   1.]\n",
      " pred labels train [100.4907 293.5254 304.8347   2.3013 622.5697 618.5861 230.6677   1.\n",
      " 802.4695   1.    ]\n",
      " all vars norms [246.55116, 0.53648716, 135.92316, 25.435333, 29.82323, 0.9998811]\n",
      "global_step 190325 , loss 6.4885273\n",
      "global_step 190425 , loss 6.7987967\n",
      "global_step 190525 , loss 7.2953777\n",
      "global_step 190625 , loss 7.8835907\n",
      "global_step 190725 , loss 7.8016834\n",
      "global_step 190825 , loss 9.268148\n",
      "global_step 190925 , loss 6.6849127\n",
      "global_step 191025 , loss 6.4543343\n",
      "global_step 191125 , loss 6.1003404\n",
      "global_step 191225 , loss 7.485392\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    1.  291.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  905.]]\n",
      " true labels train [  1. 118. 100.   1. 881.  12.   1. 873.  10.   1.]\n",
      " pred labels train [-7.0911e-01  1.0937e+02  9.7218e+01  1.0001e+00  8.8298e+02  1.2625e+01\n",
      "  1.0001e+00  8.6862e+02  1.0133e+01  1.0001e+00]\n",
      " all vars norms [246.98892, 0.53671926, 136.17181, 25.485203, 29.829836, 1.0001568]\n",
      "global_step 191325 , loss 7.9455843\n",
      "global_step 191425 , loss 5.0830684\n",
      "global_step 191525 , loss 6.0948\n",
      "global_step 191625 , loss 8.315861\n",
      "global_step 191725 , loss 6.3298016\n",
      "global_step 191825 , loss 5.301116\n",
      "global_step 191925 , loss 7.2304707\n",
      "global_step 192025 , loss 6.5962543\n",
      "global_step 192125 , loss 6.49566\n",
      "global_step 192225 , loss 5.251589\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  695.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  641.]]\n",
      " true labels train [ 302.  381.   31. 1000.   11.  274.    1.    1.  680.  725.]\n",
      " pred labels train [299.0956 395.2309  48.1574 990.0024  13.9977 274.0996   0.9999   0.9999\n",
      " 680.4463 740.1843]\n",
      " all vars norms [247.44403, 0.5365914, 136.41797, 25.533504, 29.856245, 0.9999807]\n",
      "global_step 192325 , loss 7.8604393\n",
      "global_step 192425 , loss 9.214151\n",
      "global_step 192525 , loss 7.0184507\n",
      "global_step 192625 , loss 6.4923563\n",
      "global_step 192725 , loss 6.7221212\n",
      "global_step 192825 , loss 6.2666597\n",
      "global_step 192925 , loss 6.46279\n",
      "global_step 193025 , loss 6.505604\n",
      "global_step 193125 , loss 8.384338\n",
      "global_step 193225 , loss 5.390876\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  487.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  695.]]\n",
      " true labels train [ 10. 302.   1.  10.   1.   1.   1.  86.   1.  38.]\n",
      " pred labels train [ 10.3328 267.409    0.9998  10.1651   0.9998   0.9998   0.9998  87.0222\n",
      "   0.9998  43.4649]\n",
      " all vars norms [247.90825, 0.53657496, 136.67374, 25.590408, 29.903992, 0.99989057]\n",
      "global_step 193325 , loss 6.5225735\n",
      "global_step 193425 , loss 7.0369997\n",
      "global_step 193525 , loss 7.1663866\n",
      "global_step 193625 , loss 7.2377844\n",
      "global_step 193725 , loss 5.5444317\n",
      "global_step 193825 , loss 5.6613603\n",
      "global_step 193925 , loss 7.593835\n",
      "global_step 194025 , loss 6.6515427\n",
      "global_step 194125 , loss 6.315922\n",
      "INFO:tensorflow:global_step/sec: 361.325\n",
      "global_step 194225 , loss 5.9406633\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    1.  669.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  408.]]\n",
      " true labels train [100.   1. 584.  10. 760.   9. 301.   1.  60.   1.]\n",
      " pred labels train [100.6801   1.0002 572.9583   9.574  758.4036  10.5154 273.3977  14.1025\n",
      "  61.9156   1.7275]\n",
      " all vars norms [248.28163, 0.53674537, 136.9222, 25.640469, 29.933733, 1.0001122]\n",
      "global_step 194325 , loss 7.013397\n",
      "global_step 194425 , loss 6.7868285\n",
      "global_step 194525 , loss 9.000418\n",
      "global_step 194625 , loss 7.69277\n",
      "global_step 194725 , loss 6.7496395\n",
      "global_step 194825 , loss 7.038891\n",
      "global_step 194925 , loss 7.5031815\n",
      "global_step 195025 , loss 8.4213\n",
      "global_step 195125 , loss 5.9331236\n",
      "global_step 195225 , loss 8.232969\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  113.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  863.]]\n",
      " true labels train [896.  15. 525.  10. 380. 516. 283.  10. 401. 100.]\n",
      " pred labels train [884.3947  12.7235 524.7207   9.6331 392.0171 498.2999 279.1942   9.9648\n",
      " 393.3154 100.2074]\n",
      " all vars norms [248.75285, 0.5366898, 137.20392, 25.691612, 29.978748, 0.99987227]\n",
      "global_step 195325 , loss 6.1375537\n",
      "global_step 195425 , loss 6.8228683\n",
      "global_step 195525 , loss 7.5520296\n",
      "global_step 195625 , loss 6.069156\n",
      "global_step 195725 , loss 6.53051\n",
      "global_step 195825 , loss 6.2175593\n",
      "global_step 195925 , loss 6.909749\n",
      "global_step 196025 , loss 5.862477\n",
      "global_step 196125 , loss 8.153051\n",
      "global_step 196225 , loss 7.6394634\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  196.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  821.]]\n",
      " true labels train [ 10.   1. 865.   1. 485. 462. 561.   1.   1.   1.]\n",
      " pred labels train [  9.8761   0.9998 872.8792   0.9998 486.9536 466.1375 550.5117   0.9998\n",
      "   0.9998   0.9998]\n",
      " all vars norms [249.15517, 0.5365972, 137.44206, 25.747744, 30.001177, 0.9998597]\n",
      "global_step 196325 , loss 8.762626\n",
      "global_step 196425 , loss 6.729125\n",
      "global_step 196525 , loss 6.4895196\n",
      "global_step 196625 , loss 6.567026\n",
      "global_step 196725 , loss 6.3121862\n",
      "global_step 196825 , loss 6.216219\n",
      "global_step 196925 , loss 5.8620105\n",
      "global_step 197025 , loss 6.7426376\n",
      "global_step 197125 , loss 6.7980895\n",
      "global_step 197225 , loss 6.9007406\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  623.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    1.  291.]]\n",
      " true labels train [ 100.    1.   10.    9.  192.  364. 1000.    1.    1.    1.]\n",
      " pred labels train [7.2338e+01 5.5530e-01 9.6452e+00 8.7156e+00 1.8061e+02 3.4552e+02\n",
      " 8.4843e+02 1.0001e+00 1.0001e+00 1.0001e+00]\n",
      " all vars norms [249.60698, 0.5365366, 137.72798, 25.802933, 30.027773, 1.0000987]\n",
      "global_step 197325 , loss 5.790452\n",
      "global_step 197425 , loss 5.3431606\n",
      "global_step 197525 , loss 8.5723505\n",
      "global_step 197625 , loss 9.422945\n",
      "global_step 197725 , loss 5.8217025\n",
      "global_step 197825 , loss 5.9377065\n",
      "global_step 197925 , loss 6.67249\n",
      "global_step 198025 , loss 6.946249\n",
      "global_step 198125 , loss 6.5475345\n",
      "global_step 198225 , loss 7.9149647\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    1.    0.    0.    0.    0.   12.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    1.    0.   71.]]\n",
      " true labels train [   1.   68. 1000.  938.   10.  446.    1.  470.    1.  608.]\n",
      " pred labels train [  1.8971  68.5873 980.993  941.1371   9.6241 446.4676   1.0002 478.4144\n",
      "   1.0002 593.4446]\n",
      " all vars norms [250.09563, 0.536743, 137.9691, 25.851624, 30.064589, 1.0001792]\n",
      "global_step 198325 , loss 7.1491327\n",
      "global_step 198425 , loss 6.9315033\n",
      "global_step 198525 , loss 6.016732\n",
      "global_step 198625 , loss 10.307735\n",
      "global_step 198725 , loss 5.2124033\n",
      "global_step 198825 , loss 8.112672\n",
      "global_step 198925 , loss 7.2406974\n",
      "global_step 199025 , loss 6.489275\n",
      "global_step 199125 , loss 5.8780327\n",
      "INFO:tensorflow:global_step/sec: 369.442\n",
      "global_step 199225 , loss 7.9857635\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  777.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  592.]]\n",
      " true labels train [1000.    1.  632.   85.   68.   14.  193.    9.  873.  782.]\n",
      " pred labels train [940.9767   0.9997 631.556   83.7505  73.0214  11.6413 199.0787   9.1394\n",
      " 883.3568 777.9494]\n",
      " all vars norms [250.49884, 0.5368529, 138.23305, 25.906595, 30.105955, 0.99975336]\n",
      "global_step 199325 , loss 6.52962\n",
      "global_step 199425 , loss 6.5295525\n",
      "global_step 199525 , loss 5.6646447\n",
      "global_step 199625 , loss 8.433082\n",
      "global_step 199725 , loss 7.984377\n",
      "global_step 199825 , loss 7.4251966\n",
      "global_step 199925 , loss 6.127577\n",
      "global_step 200025 , loss 8.204571\n",
      "global_step 200125 , loss 6.7913346\n",
      "global_step 200225 , loss 6.3566303\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  494.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  800.]]\n",
      " true labels train [525. 216.   8.   1.   1.  16.  10.  10.   1.  14.]\n",
      " pred labels train [5.2490e+02 2.1606e+02 1.0074e+01 1.0001e+00 1.0001e+00 1.0730e+01\n",
      " 1.1902e-01 9.6881e+00 1.0001e+00 1.4444e+01]\n",
      " all vars norms [251.00208, 0.53658956, 138.51997, 25.95765, 30.15026, 1.0001898]\n",
      "global_step 200325 , loss 7.1953917\n",
      "global_step 200425 , loss 7.6423025\n",
      "global_step 200525 , loss 7.1810074\n",
      "global_step 200625 , loss 6.2447357\n",
      "global_step 200725 , loss 8.465166\n",
      "global_step 200825 , loss 6.015438\n",
      "global_step 200925 , loss 5.8571744\n",
      "global_step 201025 , loss 6.601937\n",
      "global_step 201125 , loss 7.0004134\n",
      "global_step 201225 , loss 5.6860695\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  765.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  773.]]\n",
      " true labels train [  1. 239.  28.  10. 141.  10.  10. 881. 642.   1.]\n",
      " pred labels train [  1.0001 286.2604  24.148    9.9907 131.3374  10.0451   8.7102 885.5308\n",
      " 632.0972   1.0001]\n",
      " all vars norms [251.40483, 0.5368485, 138.81161, 26.012203, 30.174244, 1.0001477]\n",
      "global_step 201325 , loss 6.1329627\n",
      "global_step 201425 , loss 6.1321673\n",
      "global_step 201525 , loss 7.298471\n",
      "global_step 201625 , loss 6.684532\n",
      "global_step 201725 , loss 7.1672745\n",
      "global_step 201825 , loss 6.7883577\n",
      "global_step 201925 , loss 7.086554\n",
      "global_step 202025 , loss 8.1849\n",
      "global_step 202125 , loss 6.0630364\n",
      "global_step 202225 , loss 5.34068\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  784.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  634.]]\n",
      " true labels train [  10.  389.  857.  233. 1000.    1.  100.  762.  785.   60.]\n",
      " pred labels train [  12.746   385.983   864.3851  214.5782 1015.4172   22.6668  100.289\n",
      "  763.8347  790.3506   58.0546]\n",
      " all vars norms [251.8706, 0.5368887, 139.0689, 26.05789, 30.2038, 0.999778]\n",
      "global_step 202325 , loss 6.6274424\n",
      "global_step 202425 , loss 7.354049\n",
      "global_step 202525 , loss 7.2324314\n",
      "global_step 202625 , loss 5.9297566\n",
      "global_step 202725 , loss 7.282352\n",
      "global_step 202825 , loss 7.0677795\n",
      "global_step 202925 , loss 6.685912\n",
      "global_step 203025 , loss 6.859668\n",
      "global_step 203125 , loss 5.551823\n",
      "global_step 203225 , loss 5.9641013\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  169.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  671.]]\n",
      " true labels train [   1.  336. 1000.   10.  249.    1.   12.   26.    1. 1000.]\n",
      " pred labels train [1.0002e+00 3.3497e+02 1.0147e+03 1.0112e+01 2.3594e+02 1.0002e+00\n",
      " 1.0328e+01 1.8735e+01 1.0002e+00 1.0266e+03]\n",
      " all vars norms [252.37761, 0.5369543, 139.33644, 26.110704, 30.24004, 1.0002081]\n",
      "global_step 203325 , loss 7.375601\n",
      "global_step 203425 , loss 7.209114\n",
      "global_step 203525 , loss 7.1245418\n",
      "global_step 203625 , loss 6.033582\n",
      "global_step 203725 , loss 6.694068\n",
      "global_step 203825 , loss 5.9636483\n",
      "global_step 203925 , loss 6.145988\n",
      "global_step 204025 , loss 9.011822\n",
      "global_step 204125 , loss 6.3252983\n",
      "INFO:tensorflow:global_step/sec: 379.241\n",
      "global_step 204225 , loss 6.5478873\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  970.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  401.]]\n",
      " true labels train [983.  10. 808. 961. 445.   1. 100. 100.   1. 315.]\n",
      " pred labels train [984.5248   9.8788 810.4394 966.307  457.7894  16.8012  99.098   97.4749\n",
      "   1.     317.6839]\n",
      " all vars norms [252.82855, 0.53708774, 139.60045, 26.16581, 30.288658, 0.99997175]\n",
      "global_step 204325 , loss 7.044468\n",
      "global_step 204425 , loss 7.557008\n",
      "global_step 204525 , loss 5.9078684\n",
      "global_step 204625 , loss 9.193672\n",
      "global_step 204725 , loss 7.3284655\n",
      "global_step 204825 , loss 7.3277874\n",
      "global_step 204925 , loss 10.184984\n",
      "global_step 205025 , loss 7.38414\n",
      "global_step 205125 , loss 9.796471\n",
      "global_step 205225 , loss 5.4760385\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   85.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  233.]]\n",
      " true labels train [  1. 785.  44.   1. 335.  10. 632. 740. 485.   1.]\n",
      " pred labels train [  0.9999 757.5283  40.1736   3.5318 356.7702   9.9332 638.6703 740.282\n",
      " 473.5669   0.9999]\n",
      " all vars norms [253.30122, 0.5369278, 139.87575, 26.2107, 30.312025, 1.000053]\n",
      "global_step 205325 , loss 6.3501487\n",
      "global_step 205425 , loss 6.1554184\n",
      "global_step 205525 , loss 6.97593\n",
      "global_step 205625 , loss 8.142872\n",
      "INFO:tensorflow:Saving checkpoints for 205630 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 205725 , loss 7.552979\n",
      "global_step 205825 , loss 8.262341\n",
      "global_step 205925 , loss 5.9468155\n",
      "global_step 206025 , loss 7.0255437\n",
      "global_step 206125 , loss 7.341133\n",
      "global_step 206225 , loss 7.138953\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    1.    0.    0.    0.    0.   95.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   91.]]\n",
      " true labels train [  2. 914.   1.  12.   7.   1. 412.   1. 714. 926.]\n",
      " pred labels train [1.4613e+00 9.1054e+02 8.6233e-01 1.1399e+01 8.8327e+00 9.9974e-01\n",
      " 4.2578e+02 9.9974e-01 7.1710e+02 9.2321e+02]\n",
      " all vars norms [253.7071, 0.5369205, 140.1388, 26.261808, 30.33685, 0.9998615]\n",
      "global_step 206325 , loss 5.5911703\n",
      "global_step 206425 , loss 5.9841633\n",
      "global_step 206525 , loss 6.4680347\n",
      "global_step 206625 , loss 7.1814637\n",
      "global_step 206725 , loss 5.9306583\n",
      "global_step 206825 , loss 7.7185974\n",
      "global_step 206925 , loss 5.435215\n",
      "global_step 207025 , loss 6.2381473\n",
      "global_step 207125 , loss 6.909113\n",
      "global_step 207225 , loss 6.931671\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    1.    0.    0.    0.  616.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  769.]]\n",
      " true labels train [  1. 761. 650. 119. 185.   1.  10.   1. 961.  10.]\n",
      " pred labels train [  1.0933 766.6226 640.2925 114.8418 184.6869  -1.4783  10.1081   1.\n",
      " 992.5752   9.7561]\n",
      " all vars norms [254.14458, 0.5368012, 140.39801, 26.326288, 30.368034, 1.0001279]\n",
      "global_step 207325 , loss 9.798321\n",
      "global_step 207425 , loss 8.15646\n",
      "global_step 207525 , loss 7.280203\n",
      "global_step 207625 , loss 9.979359\n",
      "global_step 207725 , loss 7.673788\n",
      "global_step 207825 , loss 7.808752\n",
      "global_step 207925 , loss 6.2770977\n",
      "global_step 208025 , loss 5.6262074\n",
      "global_step 208125 , loss 5.974889\n",
      "global_step 208225 , loss 6.583576\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  174.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  645.]]\n",
      " true labels train [  1. 364. 217. 748.   2.  10.  21. 873.   1.   1.]\n",
      " pred labels train [  1.     376.3749 229.3456 748.9279   2.986   11.2664  16.5126 866.0251\n",
      "   1.       1.    ]\n",
      " all vars norms [254.57803, 0.53669125, 140.65971, 26.37338, 30.404423, 0.99995774]\n",
      "global_step 208325 , loss 8.135745\n",
      "global_step 208425 , loss 7.938444\n",
      "global_step 208525 , loss 8.260834\n",
      "global_step 208625 , loss 9.163088\n",
      "global_step 208725 , loss 9.62666\n",
      "global_step 208825 , loss 6.785798\n",
      "global_step 208925 , loss 10.553923\n",
      "global_step 209025 , loss 5.727634\n",
      "global_step 209125 , loss 6.6704855\n",
      "INFO:tensorflow:global_step/sec: 364.953\n",
      "global_step 209225 , loss 5.147249\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  465.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  588.]]\n",
      " true labels train [   1.  426.  878.  136. 1000.    1.  871.  335.  222.  576.]\n",
      " pred labels train [  1.7195 423.2275 857.8591 138.7449 985.233    1.5939 887.068  327.6753\n",
      " 232.3754 583.9804]\n",
      " all vars norms [255.01132, 0.5371749, 140.95416, 26.425425, 30.429855, 0.99992603]\n",
      "global_step 209325 , loss 5.446033\n",
      "global_step 209425 , loss 6.575261\n",
      "global_step 209525 , loss 7.962055\n",
      "global_step 209625 , loss 9.4740095\n",
      "global_step 209725 , loss 7.624894\n",
      "global_step 209825 , loss 6.3316803\n",
      "global_step 209925 , loss 6.8092184\n",
      "global_step 210025 , loss 5.2316523\n",
      "global_step 210125 , loss 6.4577546\n",
      "global_step 210225 , loss 5.5701966\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    1.    0.    0.    0.    0.  656.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    1.    0.    0.    0.   89.]]\n",
      " true labels train [  1.  11.  38.  58.   1. 980. 100.   7. 676. 100.]\n",
      " pred labels train [  1.      15.7353  37.651   52.7498   1.     982.0317  99.7257  11.8315\n",
      " 669.524   93.0906]\n",
      " all vars norms [255.43784, 0.53695387, 141.21509, 26.477217, 30.46145, 0.99999964]\n",
      "global_step 210325 , loss 6.8710117\n",
      "global_step 210425 , loss 8.837179\n",
      "global_step 210525 , loss 7.1476455\n",
      "global_step 210625 , loss 7.647127\n",
      "global_step 210725 , loss 6.1725836\n",
      "global_step 210825 , loss 6.813592\n",
      "global_step 210925 , loss 7.1353517\n",
      "global_step 211025 , loss 6.6689615\n",
      "global_step 211125 , loss 5.671468\n",
      "global_step 211225 , loss 6.4257336\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  932.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  513.]]\n",
      " true labels train [ 942.   10.  624.    7. 1000.  624.    8.  411. 1000.  995.]\n",
      " pred labels train [898.4608   9.6831 625.7861  12.2269 978.5683 620.1625  10.6052 404.8412\n",
      " 978.2504 979.9373]\n",
      " all vars norms [255.80663, 0.53677726, 141.45195, 26.525564, 30.477974, 1.000004]\n",
      "global_step 211325 , loss 7.8471956\n",
      "global_step 211425 , loss 8.40675\n",
      "global_step 211525 , loss 6.1958137\n",
      "global_step 211625 , loss 7.4808416\n",
      "global_step 211725 , loss 7.560533\n",
      "global_step 211825 , loss 8.861615\n",
      "global_step 211925 , loss 9.17758\n",
      "global_step 212025 , loss 7.386434\n",
      "global_step 212125 , loss 6.0085735\n",
      "global_step 212225 , loss 6.444112\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  455.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  908.]]\n",
      " true labels train [449.  10.  60. 162.   1.  44. 177.  15.  10.   1.]\n",
      " pred labels train [448.9031   8.8548  47.0984 154.6235   1.      40.892  167.1389  12.3746\n",
      "   8.5697   1.    ]\n",
      " all vars norms [256.25986, 0.53723085, 141.76813, 26.57505, 30.516811, 0.99999887]\n",
      "global_step 212325 , loss 7.5987506\n",
      "global_step 212425 , loss 5.9958076\n",
      "global_step 212525 , loss 7.1204596\n",
      "global_step 212625 , loss 9.16194\n",
      "global_step 212725 , loss 7.0856977\n",
      "global_step 212825 , loss 7.451241\n",
      "global_step 212925 , loss 7.025873\n",
      "global_step 213025 , loss 7.4787803\n",
      "global_step 213125 , loss 6.2635756\n",
      "global_step 213225 , loss 5.392249\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  755.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  274.]]\n",
      " true labels train [   1.    1.  630.  823.  470.   10.    1.   10. 1000.   10.]\n",
      " pred labels train [  1.0004   1.0004 623.0657 799.5667 470.4718  10.3717   1.0004  10.2183\n",
      " 980.3516   8.9419]\n",
      " all vars norms [256.65448, 0.5370155, 142.01476, 26.627419, 30.535645, 1.000425]\n",
      "global_step 213325 , loss 7.4377\n",
      "global_step 213425 , loss 9.560971\n",
      "global_step 213525 , loss 6.9588194\n",
      "global_step 213625 , loss 6.264512\n",
      "global_step 213725 , loss 5.399214\n",
      "global_step 213825 , loss 6.4077377\n",
      "global_step 213925 , loss 6.796379\n",
      "global_step 214025 , loss 8.743266\n",
      "global_step 214125 , loss 7.96814\n",
      "INFO:tensorflow:global_step/sec: 344.414\n",
      "global_step 214225 , loss 6.046073\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    1.    0.    0.   98.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  634.]]\n",
      " true labels train [   1.  389.   10.  573.    1.  514.    1. 1000.   10.    1.]\n",
      " pred labels train [-3.7238e-01  3.9769e+02  9.2858e+00  5.6969e+02  1.0002e+00  5.4469e+02\n",
      "  1.0002e+00  1.0042e+03  1.2361e+01  1.0002e+00]\n",
      " all vars norms [257.1575, 0.5374681, 142.26859, 26.665707, 30.582285, 1.0001572]\n",
      "global_step 214325 , loss 7.0042076\n",
      "global_step 214425 , loss 8.837836\n",
      "global_step 214525 , loss 5.9614305\n",
      "global_step 214625 , loss 7.3044915\n",
      "global_step 214725 , loss 4.84678\n",
      "global_step 214825 , loss 6.1524076\n",
      "global_step 214925 , loss 7.048684\n",
      "global_step 215025 , loss 6.066939\n",
      "global_step 215125 , loss 6.9186425\n",
      "global_step 215225 , loss 6.3041363\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   45.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  157.]]\n",
      " true labels train [ 10. 855.  10.   2.   1. 934. 312.   8.  44.  11.]\n",
      " pred labels train [  9.7534 856.826   10.3951   7.3955   1.0002 939.947  430.9087  13.1724\n",
      "  40.0308  12.7633]\n",
      " all vars norms [257.57535, 0.5370254, 142.53035, 26.722725, 30.620113, 1.0002676]\n",
      "global_step 215325 , loss 9.074236\n",
      "global_step 215425 , loss 6.545771\n",
      "global_step 215525 , loss 10.337622\n",
      "global_step 215625 , loss 8.0358925\n",
      "global_step 215725 , loss 7.368474\n",
      "global_step 215825 , loss 9.440251\n",
      "global_step 215925 , loss 8.491367\n",
      "global_step 216025 , loss 8.238085\n",
      "global_step 216125 , loss 7.665861\n",
      "global_step 216225 , loss 6.2269087\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  597.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   55.]]\n",
      " true labels train [  1.  81. 853.  10. 207.   1. 823. 100.  33.   1.]\n",
      " pred labels train [  0.9998  78.4234 864.0067   8.301  197.7885   0.9998 801.1927 104.1693\n",
      "  38.151    3.4855]\n",
      " all vars norms [258.0, 0.5369772, 142.7417, 26.77709, 30.647871, 0.9997938]\n",
      "global_step 216325 , loss 7.671618\n",
      "global_step 216425 , loss 5.0029097\n",
      "global_step 216525 , loss 6.5830383\n",
      "global_step 216625 , loss 6.5199757\n",
      "global_step 216725 , loss 6.024988\n",
      "global_step 216825 , loss 7.4190636\n",
      "global_step 216925 , loss 7.701364\n",
      "global_step 217025 , loss 5.5788946\n",
      "global_step 217125 , loss 5.884061\n",
      "global_step 217225 , loss 6.639736\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  643.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  568.]]\n",
      " true labels train [362. 451. 786.   1.  10. 100.   9. 467. 204.   1.]\n",
      " pred labels train [372.8394 462.7361 778.0432   1.      10.3021  98.3724  12.665  497.7403\n",
      " 212.7827   1.    ]\n",
      " all vars norms [258.3862, 0.53712356, 143.00684, 26.829714, 30.66433, 0.9998893]\n",
      "global_step 217325 , loss 7.494197\n",
      "global_step 217425 , loss 7.71975\n",
      "global_step 217525 , loss 5.988834\n",
      "global_step 217625 , loss 7.370792\n",
      "global_step 217725 , loss 6.588613\n",
      "global_step 217825 , loss 6.2128\n",
      "global_step 217925 , loss 6.2636595\n",
      "global_step 218025 , loss 6.301177\n",
      "global_step 218125 , loss 7.679763\n",
      "global_step 218225 , loss 6.8539486\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   36.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  692.]]\n",
      " true labels train [ 10. 696. 560.   2.  10.  31.   1.  10. 536. 364.]\n",
      " pred labels train [  9.4507 679.2615 563.4879  11.2701  10.565   31.8776   1.0001  10.0796\n",
      " 540.3917 372.3618]\n",
      " all vars norms [258.92416, 0.53728825, 143.26288, 26.879381, 30.711761, 1.0002075]\n",
      "global_step 218325 , loss 5.8233137\n",
      "global_step 218425 , loss 5.779705\n",
      "global_step 218525 , loss 6.2999344\n",
      "global_step 218625 , loss 7.926871\n",
      "global_step 218725 , loss 7.5817394\n",
      "global_step 218825 , loss 5.442045\n",
      "global_step 218925 , loss 5.3859663\n",
      "global_step 219025 , loss 6.2766857\n",
      "global_step 219125 , loss 7.827516\n",
      "INFO:tensorflow:global_step/sec: 369.523\n",
      "global_step 219225 , loss 7.1783204\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  299.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    1.    0.  967.]]\n",
      " true labels train [ 301.  100.    9.  835.  477. 1000.  585.   10.    1.    5.]\n",
      " pred labels train [2.6309e+02 9.2054e+01 1.1112e+01 8.2206e+02 5.0232e+02 1.0145e+03\n",
      " 5.8168e+02 9.5701e+00 1.0001e+00 1.8964e+00]\n",
      " all vars norms [259.33426, 0.53716105, 143.53049, 26.921022, 30.741028, 1.0000819]\n",
      "global_step 219325 , loss 5.301181\n",
      "global_step 219425 , loss 7.120101\n",
      "global_step 219525 , loss 6.062497\n",
      "global_step 219625 , loss 6.2840395\n",
      "global_step 219725 , loss 6.672797\n",
      "global_step 219825 , loss 5.313183\n",
      "global_step 219925 , loss 6.8770266\n",
      "global_step 220025 , loss 7.297415\n",
      "global_step 220125 , loss 6.489122\n",
      "global_step 220225 , loss 6.206583\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    1.    0.   58.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   57.]]\n",
      " true labels train [ 57.  60. 100. 483.  11.   1. 467. 100.  58. 757.]\n",
      " pred labels train [ 54.6523  63.8308  98.6923 482.6788  14.2823   0.9998 459.6403  94.6459\n",
      "  55.1647 761.6111]\n",
      " all vars norms [259.77176, 0.5370453, 143.78247, 26.983973, 30.760998, 0.9999268]\n",
      "global_step 220325 , loss 6.3562\n",
      "global_step 220425 , loss 8.812286\n",
      "global_step 220525 , loss 5.191661\n",
      "global_step 220625 , loss 7.849761\n",
      "global_step 220725 , loss 8.709777\n",
      "global_step 220825 , loss 7.9491167\n",
      "global_step 220925 , loss 7.7204227\n",
      "global_step 221025 , loss 6.2647314\n",
      "global_step 221125 , loss 7.634473\n",
      "global_step 221225 , loss 6.4575663\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    1.    0.    0.  773.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  306.]]\n",
      " true labels train [  1.  13. 100.   1.  10.   1.  24.  10. 141.  14.]\n",
      " pred labels train [  1.      10.7745 109.7656   1.0018  11.205    1.      24.5709  10.758\n",
      " 151.9902  12.8755]\n",
      " all vars norms [260.168, 0.5374167, 144.06499, 27.029915, 30.795784, 0.99993926]\n",
      "global_step 221325 , loss 5.9639473\n",
      "global_step 221425 , loss 7.548684\n",
      "global_step 221525 , loss 6.9618444\n",
      "global_step 221625 , loss 5.82039\n",
      "global_step 221725 , loss 6.089641\n",
      "global_step 221825 , loss 8.368647\n",
      "global_step 221925 , loss 5.6053963\n",
      "global_step 222025 , loss 6.738369\n",
      "global_step 222125 , loss 6.879956\n",
      "global_step 222225 , loss 6.2361093\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    1.  628.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  210.]]\n",
      " true labels train [100. 223. 100. 100. 457.   1.   1. 371.   1. 952.]\n",
      " pred labels train [102.7033 232.5804  99.5748  97.4531 457.8753   6.4655   1.     371.3411\n",
      "   1.     953.9391]\n",
      " all vars norms [260.61145, 0.5372256, 144.33456, 27.081594, 30.810196, 0.99997467]\n",
      "global_step 222325 , loss 7.4186926\n",
      "global_step 222425 , loss 5.659487\n",
      "global_step 222525 , loss 7.0546894\n",
      "global_step 222625 , loss 6.8464203\n",
      "global_step 222725 , loss 7.327826\n",
      "global_step 222825 , loss 7.212327\n",
      "global_step 222925 , loss 5.8239803\n",
      "global_step 223025 , loss 5.9904146\n",
      "global_step 223125 , loss 7.726677\n",
      "global_step 223225 , loss 6.9931445\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  953.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   85.]]\n",
      " true labels train [  1.   1. 895. 108.   1.   1.   1.   1.  10. 292.]\n",
      " pred labels train [  0.9998   0.9998 876.1691 109.9059   2.1656   0.9998   0.9998   0.9998\n",
      "  11.4069 288.5421]\n",
      " all vars norms [261.0233, 0.5370444, 144.57062, 27.13535, 30.830153, 0.9998353]\n",
      "global_step 223325 , loss 5.437894\n",
      "global_step 223425 , loss 5.2916155\n",
      "global_step 223525 , loss 6.595912\n",
      "global_step 223625 , loss 6.2477083\n",
      "global_step 223725 , loss 8.855006\n",
      "global_step 223825 , loss 7.523411\n",
      "global_step 223925 , loss 6.1105433\n",
      "global_step 224025 , loss 6.1305847\n",
      "global_step 224125 , loss 8.131305\n",
      "INFO:tensorflow:global_step/sec: 375.039\n",
      "global_step 224225 , loss 7.045755\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  224.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  655.]]\n",
      " true labels train [   1.    6.  185.  878.    1.  661.   21.   10. 1000.    1.]\n",
      " pred labels train [  0.9996  10.4639 194.4549 869.9587   2.9051 668.9945  28.0401  18.1436\n",
      " 954.082    2.3807]\n",
      " all vars norms [261.5063, 0.537527, 144.84572, 27.187834, 30.861687, 0.99960977]\n",
      "global_step 224325 , loss 5.9251776\n",
      "global_step 224425 , loss 6.0985413\n",
      "global_step 224525 , loss 5.9260044\n",
      "global_step 224625 , loss 6.3700333\n",
      "global_step 224725 , loss 7.2173285\n",
      "global_step 224825 , loss 6.2923136\n",
      "global_step 224925 , loss 9.206968\n",
      "global_step 225025 , loss 5.347558\n",
      "global_step 225125 , loss 6.214917\n",
      "global_step 225225 , loss 8.520288\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  242.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  136.]]\n",
      " true labels train [  1. 878. 699.   1.  10.  56.  71. 100.  51.   1.]\n",
      " pred labels train [  1.     875.4985 717.0043   1.      10.4601  96.4652  74.1471 114.5229\n",
      "  48.11     1.    ]\n",
      " all vars norms [261.95752, 0.5373526, 145.11906, 27.236044, 30.908594, 0.9999002]\n",
      "global_step 225325 , loss 7.6187973\n",
      "global_step 225425 , loss 5.985317\n",
      "global_step 225525 , loss 7.136252\n",
      "global_step 225625 , loss 5.580543\n",
      "global_step 225725 , loss 7.9343166\n",
      "global_step 225825 , loss 6.1984186\n",
      "global_step 225925 , loss 8.224442\n",
      "global_step 226025 , loss 5.531349\n",
      "global_step 226125 , loss 7.1913247\n",
      "global_step 226225 , loss 6.881219\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    1.    0.  383.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  833.]]\n",
      " true labels train [100.  10.  10.  74. 725.  10. 834.   1.   1.   1.]\n",
      " pred labels train [9.6937e+01 1.1152e+01 1.1202e+01 7.1723e+01 7.2189e+02 1.0586e+01\n",
      " 8.2381e+02 9.9989e-01 6.8765e-01 9.9989e-01]\n",
      " all vars norms [262.37173, 0.5373922, 145.36493, 27.288197, 30.918457, 0.9998357]\n",
      "global_step 226325 , loss 7.4152174\n",
      "global_step 226425 , loss 5.629176\n",
      "global_step 226525 , loss 8.580052\n",
      "global_step 226625 , loss 10.8110695\n",
      "global_step 226725 , loss 7.1938696\n",
      "global_step 226825 , loss 5.9501696\n",
      "global_step 226925 , loss 8.191818\n",
      "global_step 227025 , loss 5.212851\n",
      "global_step 227125 , loss 5.9724054\n",
      "global_step 227225 , loss 4.8477845\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    1.  647.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  417.]]\n",
      " true labels train [ 100. 1000.    1.  100.  786.    1.  911.  960.  602. 1000.]\n",
      " pred labels train [1.0771e+02 9.9376e+02 9.9979e-01 9.9189e+01 7.7112e+02 9.9979e-01\n",
      " 9.1740e+02 9.7217e+02 5.9791e+02 1.0182e+03]\n",
      " all vars norms [262.83142, 0.53740776, 145.64417, 27.33619, 30.947718, 0.9997789]\n",
      "global_step 227325 , loss 6.956235\n",
      "global_step 227425 , loss 7.4073043\n",
      "INFO:tensorflow:Saving checkpoints for 227441 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 227525 , loss 8.419013\n",
      "global_step 227625 , loss 8.39607\n",
      "global_step 227725 , loss 6.49446\n",
      "global_step 227825 , loss 6.54154\n",
      "global_step 227925 , loss 7.219478\n",
      "global_step 228025 , loss 5.7592444\n",
      "global_step 228125 , loss 6.1812906\n",
      "global_step 228225 , loss 6.47184\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  273.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    1.    0.    0.    0.    0.  645.]]\n",
      " true labels train [1000.    1.    1.  860. 1000.  122.   58.    1.   70.    1.]\n",
      " pred labels train [995.1068   1.0003   1.4437 857.5472 940.8823 182.8256  70.151    1.0003\n",
      "  86.5106   1.0003]\n",
      " all vars norms [263.23984, 0.5373077, 145.88654, 27.39506, 30.97864, 1.0001644]\n",
      "global_step 228325 , loss 5.829693\n",
      "global_step 228425 , loss 6.65151\n",
      "global_step 228525 , loss 5.719218\n",
      "global_step 228625 , loss 6.0357428\n",
      "global_step 228725 , loss 6.8207874\n",
      "global_step 228825 , loss 7.4747553\n",
      "global_step 228925 , loss 5.190195\n",
      "global_step 229025 , loss 5.7589464\n",
      "global_step 229125 , loss 5.1264524\n",
      "INFO:tensorflow:global_step/sec: 367.971\n",
      "global_step 229225 , loss 6.425396\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    1.   82.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    2.]]\n",
      " true labels train [  79. 1000.   10.    1.  389.    2.   15.    1.    1.    1.]\n",
      " pred labels train [8.8245e+01 1.0255e+03 1.0158e+01 1.0002e+00 3.9140e+02 2.4814e+00\n",
      " 1.1082e+01 1.0002e+00 1.0002e+00 1.0002e+00]\n",
      " all vars norms [263.67233, 0.5373974, 146.1188, 27.450058, 30.997662, 1.0001949]\n",
      "global_step 229325 , loss 5.735996\n",
      "global_step 229425 , loss 5.8409595\n",
      "global_step 229525 , loss 6.3373733\n",
      "global_step 229625 , loss 6.973575\n",
      "global_step 229725 , loss 8.969999\n",
      "global_step 229825 , loss 8.87977\n",
      "global_step 229925 , loss 6.1434374\n",
      "global_step 230025 , loss 8.416844\n",
      "global_step 230125 , loss 7.952504\n",
      "global_step 230225 , loss 6.7734013\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  535.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    1.   15.]]\n",
      " true labels train [447.  18. 785. 881.  10.   1. 464. 956.   1. 872.]\n",
      " pred labels train [453.386   23.2871 821.0958 895.0198   9.465    1.     460.3901 945.356\n",
      "   3.3661 873.2236]\n",
      " all vars norms [264.13025, 0.5373043, 146.37718, 27.50054, 31.040548, 1.0000541]\n",
      "global_step 230325 , loss 6.885813\n",
      "global_step 230425 , loss 7.017516\n",
      "global_step 230525 , loss 4.511921\n",
      "global_step 230625 , loss 7.1418624\n",
      "global_step 230725 , loss 7.0772257\n",
      "global_step 230825 , loss 6.8085527\n",
      "global_step 230925 , loss 7.089859\n",
      "global_step 231025 , loss 6.3094196\n",
      "global_step 231125 , loss 5.6957636\n",
      "global_step 231225 , loss 7.211205\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  341.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   77.]]\n",
      " true labels train [1000. 1000.  404.  547.  100.   85.    1.    1.  322.  979.]\n",
      " pred labels train [9.8222e+02 1.0024e+03 4.1609e+02 5.6059e+02 9.7942e+01 9.0174e+01\n",
      " 9.9994e-01 9.9994e-01 3.3564e+02 9.8744e+02]\n",
      " all vars norms [264.59933, 0.53756, 146.61655, 27.551357, 31.070724, 1.000109]\n",
      "global_step 231325 , loss 5.6014433\n",
      "global_step 231425 , loss 8.149186\n",
      "global_step 231525 , loss 7.3180504\n",
      "global_step 231625 , loss 6.2533007\n",
      "global_step 231725 , loss 6.9869494\n",
      "global_step 231825 , loss 6.300005\n",
      "global_step 231925 , loss 6.7406874\n",
      "global_step 232025 , loss 7.8573813\n",
      "global_step 232125 , loss 7.1117334\n",
      "global_step 232225 , loss 7.807313\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    1.    0.    0.    0.   96.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  900.]]\n",
      " true labels train [  1.  12. 412. 292.  10. 952.   1. 202.  10. 858.]\n",
      " pred labels train [  3.0917  12.4246 413.1462 294.2654   4.5716 950.3604   0.9999 173.5391\n",
      "  11.5078 859.7578]\n",
      " all vars norms [265.07822, 0.53776306, 146.83504, 27.599783, 31.098825, 0.99989253]\n",
      "global_step 232325 , loss 6.1024504\n",
      "global_step 232425 , loss 6.090908\n",
      "global_step 232525 , loss 8.276298\n",
      "global_step 232625 , loss 6.0654583\n",
      "global_step 232725 , loss 6.003093\n",
      "global_step 232825 , loss 7.0093994\n",
      "global_step 232925 , loss 8.731932\n",
      "global_step 233025 , loss 7.2997437\n",
      "global_step 233125 , loss 6.3053603\n",
      "global_step 233225 , loss 6.587902\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  305.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  634.]]\n",
      " true labels train [ 710.  389.  984.  100.  525. 1000.  100.  100.   31.    8.]\n",
      " pred labels train [ 713.9892  392.5038  988.4087  105.9904  537.764  1006.0804   99.0263\n",
      "  103.4849   27.6382   12.0147]\n",
      " all vars norms [265.51083, 0.5374037, 147.10564, 27.643555, 31.11747, 0.9999584]\n",
      "global_step 233325 , loss 9.425888\n",
      "global_step 233425 , loss 7.6205707\n",
      "global_step 233525 , loss 6.556881\n",
      "global_step 233625 , loss 6.5550094\n",
      "global_step 233725 , loss 6.009695\n",
      "global_step 233825 , loss 6.878296\n",
      "global_step 233925 , loss 5.817879\n",
      "global_step 234025 , loss 7.726896\n",
      "global_step 234125 , loss 5.8891797\n",
      "INFO:tensorflow:global_step/sec: 368.006\n",
      "global_step 234225 , loss 6.242426\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  458.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  115.]]\n",
      " true labels train [470. 134.  21. 133.  60.  10.   1.   1.   1.  56.]\n",
      " pred labels train [472.8129 149.6827  21.1461 114.8012  56.0017  10.6661   1.0001  -1.2524\n",
      "   1.0001  57.1702]\n",
      " all vars norms [265.92838, 0.53768533, 147.34627, 27.688725, 31.12736, 1.0000539]\n",
      "global_step 234325 , loss 6.9477887\n",
      "global_step 234425 , loss 6.6846952\n",
      "global_step 234525 , loss 6.6584663\n",
      "global_step 234625 , loss 8.370522\n",
      "global_step 234725 , loss 5.531\n",
      "global_step 234825 , loss 6.0398755\n",
      "global_step 234925 , loss 6.516412\n",
      "global_step 235025 , loss 6.4117594\n",
      "global_step 235125 , loss 6.543692\n",
      "global_step 235225 , loss 6.30433\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    1.    0.    0.    0.    0.   70.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  800.]]\n",
      " true labels train [  5.   1.  10.   1. 808. 558.   1. 100. 100. 364.]\n",
      " pred labels train [  1.8271   4.0634   9.7786   2.6951 810.706  564.5739   1.     101.7397\n",
      " 100.7425 383.7166]\n",
      " all vars norms [266.29672, 0.5378925, 147.59503, 27.746048, 31.15463, 1.0001497]\n",
      "global_step 235325 , loss 11.473769\n",
      "global_step 235425 , loss 10.523431\n",
      "global_step 235525 , loss 6.6420903\n",
      "global_step 235625 , loss 6.88858\n",
      "global_step 235725 , loss 6.9678326\n",
      "global_step 235825 , loss 5.699422\n",
      "global_step 235925 , loss 5.052073\n",
      "global_step 236025 , loss 5.8125505\n",
      "global_step 236125 , loss 6.3829765\n",
      "global_step 236225 , loss 5.7326555\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    1.    0.    0.    0.   21.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  242.]]\n",
      " true labels train [ 100.    1. 1000.    1.   79.   93.  312.  100.   71.   10.]\n",
      " pred labels train [8.0249e+01 2.1065e+00 1.0026e+03 1.0001e+00 7.5604e+01 9.3278e+01\n",
      " 3.3095e+02 9.4542e+01 5.6513e+01 9.0178e+00]\n",
      " all vars norms [266.77792, 0.53771365, 147.81764, 27.790483, 31.183605, 1.0000563]\n",
      "global_step 236325 , loss 6.3069453\n",
      "global_step 236425 , loss 7.0929947\n",
      "global_step 236525 , loss 6.218375\n",
      "global_step 236625 , loss 8.897469\n",
      "global_step 236725 , loss 7.173015\n",
      "global_step 236825 , loss 5.6260085\n",
      "global_step 236925 , loss 5.654465\n",
      "global_step 237025 , loss 5.76906\n",
      "global_step 237125 , loss 4.664648\n",
      "global_step 237225 , loss 6.3467784\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  685.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    1.    0.    0.    0.    0.  297.]]\n",
      " true labels train [ 11.   1.   1. 535.   1. 849. 394.   1. 100.  95.]\n",
      " pred labels train [ 10.1077   0.9999   0.9999 538.4182   0.9999 845.6542 376.2212   0.9999\n",
      "  86.3185  94.948 ]\n",
      " all vars norms [267.2392, 0.5376538, 148.04442, 27.839436, 31.211842, 0.9999554]\n",
      "global_step 237325 , loss 7.2784224\n",
      "global_step 237425 , loss 5.673053\n",
      "global_step 237525 , loss 5.95638\n",
      "global_step 237625 , loss 5.588298\n",
      "global_step 237725 , loss 5.358946\n",
      "global_step 237825 , loss 5.94733\n",
      "global_step 237925 , loss 8.576653\n",
      "global_step 238025 , loss 6.755186\n",
      "global_step 238125 , loss 7.4858584\n",
      "global_step 238225 , loss 7.3913145\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  580.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  286.]]\n",
      " true labels train [ 394.  728.  924.   10. 1000.    1.  938.  885.  630.    1.]\n",
      " pred labels train [399.1503 734.3798 922.8892  10.7283 977.1652   1.0004 923.1129 878.8022\n",
      " 617.8013   1.0004]\n",
      " all vars norms [267.65024, 0.5376994, 148.30394, 27.90289, 31.24766, 1.000428]\n",
      "global_step 238325 , loss 5.0629587\n",
      "global_step 238425 , loss 5.937519\n",
      "global_step 238525 , loss 6.399645\n",
      "global_step 238625 , loss 6.22861\n",
      "global_step 238725 , loss 7.342618\n",
      "global_step 238825 , loss 8.067695\n",
      "global_step 238925 , loss 6.6196585\n",
      "global_step 239025 , loss 7.9954886\n",
      "global_step 239125 , loss 6.5593424\n",
      "INFO:tensorflow:global_step/sec: 378.046\n",
      "global_step 239225 , loss 6.330387\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  205.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   87.]]\n",
      " true labels train [ 220.  920.    9.   10.  100.    1. 1000.  239.  447.    1.]\n",
      " pred labels train [227.5657 924.1581  45.0869   9.6847 100.0411   1.0001 995.3232 221.911\n",
      " 438.0851   1.0001]\n",
      " all vars norms [268.098, 0.5380087, 148.55124, 27.945726, 31.288166, 1.0000923]\n",
      "global_step 239325 , loss 8.101351\n",
      "global_step 239425 , loss 5.615555\n",
      "global_step 239525 , loss 4.9780135\n",
      "global_step 239625 , loss 7.1960883\n",
      "global_step 239725 , loss 7.335896\n",
      "global_step 239825 , loss 6.4072227\n",
      "global_step 239925 , loss 5.750056\n",
      "global_step 240025 , loss 6.6774335\n",
      "global_step 240125 , loss 5.928825\n",
      "global_step 240225 , loss 7.5714664\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  564.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    1.    0.   64.]]\n",
      " true labels train [  1.  63.  77.   1. 866. 567.   1. 454. 100.  10.]\n",
      " pred labels train [  1.0002  64.4165  52.5636   1.0002 868.8483 576.5179   1.0002 458.9539\n",
      "  94.8496   9.9063]\n",
      " all vars norms [268.47812, 0.53804284, 148.77107, 27.998337, 31.31086, 1.000212]\n",
      "global_step 240325 , loss 6.954093\n",
      "global_step 240425 , loss 5.6415553\n",
      "global_step 240525 , loss 6.4930563\n",
      "global_step 240625 , loss 7.779315\n",
      "global_step 240725 , loss 7.965541\n",
      "global_step 240825 , loss 6.5101876\n",
      "global_step 240925 , loss 5.234557\n",
      "global_step 241025 , loss 8.12369\n",
      "global_step 241125 , loss 7.660532\n",
      "global_step 241225 , loss 7.8256044\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  274.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  817.]]\n",
      " true labels train [   1.  805.    1.    1.   58.   82.  969.  412.  421. 1000.]\n",
      " pred labels train [1.0005e+00 7.9225e+02 1.0005e+00 1.0005e+00 5.9352e+01 7.4877e+02\n",
      " 9.6821e+02 4.1316e+02 4.1221e+02 1.0079e+03]\n",
      " all vars norms [268.92755, 0.5378485, 149.03304, 28.049795, 31.34432, 1.0004412]\n",
      "global_step 241325 , loss 7.960873\n",
      "global_step 241425 , loss 7.007186\n",
      "global_step 241525 , loss 5.2970138\n",
      "global_step 241625 , loss 5.8294325\n",
      "global_step 241725 , loss 5.8715954\n",
      "global_step 241825 , loss 7.09662\n",
      "global_step 241925 , loss 8.927879\n",
      "global_step 242025 , loss 6.620739\n",
      "global_step 242125 , loss 6.7296324\n",
      "global_step 242225 , loss 6.6381793\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  881.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    1.    0.   58.]]\n",
      " true labels train [874.  57. 105.   1. 858. 765. 397.  79.  14. 672.]\n",
      " pred labels train [899.9204  58.5617  93.5539   1.0003 877.5117 768.6753 389.2774  75.25\n",
      "  12.99   675.0634]\n",
      " all vars norms [269.33795, 0.53770804, 149.2576, 28.10426, 31.372667, 1.0003238]\n",
      "global_step 242325 , loss 7.438118\n",
      "global_step 242425 , loss 7.564025\n",
      "global_step 242525 , loss 8.630779\n",
      "global_step 242625 , loss 6.172738\n",
      "global_step 242725 , loss 6.2732286\n",
      "global_step 242825 , loss 10.239003\n",
      "global_step 242925 , loss 9.849864\n",
      "global_step 243025 , loss 7.5528517\n",
      "global_step 243125 , loss 6.4664516\n",
      "global_step 243225 , loss 5.934545\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  459.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    1.    0.    0.  791.]]\n",
      " true labels train [561.   1.   1.   1.  67.   1.   1.   9.  88.   1.]\n",
      " pred labels train [548.179    0.9999   0.9999   0.9161  65.7704   0.9999   0.9999   9.9937\n",
      "  94.1665   0.9999]\n",
      " all vars norms [269.8231, 0.53789926, 149.51862, 28.15331, 31.421253, 1.0001318]\n",
      "global_step 243325 , loss 6.6995053\n",
      "global_step 243425 , loss 4.8149343\n",
      "global_step 243525 , loss 7.0338707\n",
      "global_step 243625 , loss 7.03899\n",
      "global_step 243725 , loss 5.612993\n",
      "global_step 243825 , loss 5.7459345\n",
      "global_step 243925 , loss 7.9109783\n",
      "global_step 244025 , loss 6.2759295\n",
      "global_step 244125 , loss 8.117282\n",
      "INFO:tensorflow:global_step/sec: 355.585\n",
      "global_step 244225 , loss 5.2962794\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  341.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  259.]]\n",
      " true labels train [348.   1.   1.   1.  44. 785. 178. 762.   3.  15.]\n",
      " pred labels train [365.2742   1.       1.       1.      46.3205 784.1278 167.3055 776.5363\n",
      "   0.7886  38.6324]\n",
      " all vars norms [270.23666, 0.5379781, 149.73184, 28.203497, 31.433516, 0.99984175]\n",
      "global_step 244325 , loss 6.89767\n",
      "global_step 244425 , loss 7.13293\n",
      "global_step 244525 , loss 7.716646\n",
      "global_step 244625 , loss 7.2665033\n",
      "global_step 244725 , loss 5.5854034\n",
      "global_step 244825 , loss 7.11747\n",
      "global_step 244925 , loss 5.2388263\n",
      "global_step 245025 , loss 7.2919655\n",
      "global_step 245125 , loss 7.226596\n",
      "global_step 245225 , loss 8.22234\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    1.    0.  376.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  169.]]\n",
      " true labels train [ 100. 1000.  866.   97.  455.   13.    1.    1.    1.  257.]\n",
      " pred labels train [103.0055 989.1179 872.9943 103.1377 456.9495  10.8364   1.3266   0.9998\n",
      "   0.9998 297.576 ]\n",
      " all vars norms [270.6492, 0.5382178, 149.96754, 28.25312, 31.430174, 0.99988097]\n",
      "global_step 245325 , loss 5.3956437\n",
      "global_step 245425 , loss 7.993849\n",
      "global_step 245525 , loss 5.8534513\n",
      "global_step 245625 , loss 6.2976723\n",
      "global_step 245725 , loss 6.202631\n",
      "global_step 245825 , loss 9.388129\n",
      "global_step 245925 , loss 7.2147408\n",
      "global_step 246025 , loss 5.4981575\n",
      "global_step 246125 , loss 6.723401\n",
      "global_step 246225 , loss 6.182299\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  877.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    1.    0.    0.    0.    0.    3.]]\n",
      " true labels train [ 12.   2.   1.   1. 485. 122.   1.   9.  12. 912.]\n",
      " pred labels train [ 11.7677   2.4688  -4.2864   1.0001 469.5472 133.4051   1.0001   8.7174\n",
      "  12.1296 913.9084]\n",
      " all vars norms [271.06076, 0.5382175, 150.18594, 28.300064, 31.46328, 1.0000293]\n",
      "global_step 246325 , loss 6.205054\n",
      "global_step 246425 , loss 5.8386106\n",
      "global_step 246525 , loss 5.005355\n",
      "global_step 246625 , loss 6.0057273\n",
      "global_step 246725 , loss 6.353614\n",
      "global_step 246825 , loss 7.3070307\n",
      "global_step 246925 , loss 7.939475\n",
      "global_step 247025 , loss 6.845109\n",
      "global_step 247125 , loss 6.5720434\n",
      "global_step 247225 , loss 6.632641\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  629.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  575.]]\n",
      " true labels train [ 382. 1000.    1.  873.    1. 1000.   10.   10.   76.   60.]\n",
      " pred labels train [3.7033e+02 1.0182e+03 1.0003e+00 8.7281e+02 1.0003e+00 1.0025e+03\n",
      " 7.4263e+00 1.0861e+01 7.9167e+01 6.5636e+01]\n",
      " all vars norms [271.5379, 0.5381334, 150.45, 28.342476, 31.486565, 1.0004574]\n",
      "global_step 247325 , loss 6.451875\n",
      "global_step 247425 , loss 7.918876\n",
      "global_step 247525 , loss 6.2498703\n",
      "global_step 247625 , loss 10.990227\n",
      "global_step 247725 , loss 6.175867\n",
      "global_step 247825 , loss 6.866987\n",
      "global_step 247925 , loss 8.191578\n",
      "global_step 248025 , loss 8.712095\n",
      "global_step 248125 , loss 8.198535\n",
      "global_step 248225 , loss 6.8718047\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  948.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  104.]]\n",
      " true labels train [952. 115.  33. 371. 532. 155. 960. 442.   9.   1.]\n",
      " pred labels train [954.9713 113.3459  34.278  371.9469 539.6347 156.344  934.8864 439.2398\n",
      "  12.0548   0.9999]\n",
      " all vars norms [271.97998, 0.5380987, 150.70396, 28.380743, 31.514606, 0.9999592]\n",
      "global_step 248325 , loss 8.435269\n",
      "global_step 248425 , loss 8.061806\n",
      "global_step 248525 , loss 6.814579\n",
      "global_step 248625 , loss 5.8962507\n",
      "global_step 248725 , loss 5.6371813\n",
      "global_step 248825 , loss 6.4432235\n",
      "global_step 248925 , loss 6.824685\n",
      "global_step 249025 , loss 7.6560388\n",
      "global_step 249125 , loss 5.8406224\n",
      "INFO:tensorflow:Saving checkpoints for 249136 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 344.389\n",
      "global_step 249225 , loss 6.265057\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  351.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   27.]]\n",
      " true labels train [ 665.    9.   44.  118.   10. 1000. 1000.  342.    1.    8.]\n",
      " pred labels train [653.8154   9.8561  45.94   115.8831   9.8114 986.737  988.3842 337.9743\n",
      "   8.137   10.1115]\n",
      " all vars norms [272.45026, 0.5379881, 150.92992, 28.414282, 31.55378, 1.0000175]\n",
      "global_step 249325 , loss 6.9912453\n",
      "global_step 249425 , loss 7.0971274\n",
      "global_step 249525 , loss 7.810608\n",
      "global_step 249625 , loss 7.703834\n",
      "global_step 249725 , loss 9.129601\n",
      "global_step 249825 , loss 6.846605\n",
      "global_step 249925 , loss 8.779402\n",
      "global_step 250025 , loss 5.4923687\n",
      "global_step 250125 , loss 5.586613\n",
      "global_step 250225 , loss 6.2365437\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  855.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  609.]]\n",
      " true labels train [1000.  421.    1.    1.  527.    1.  783.   86. 1000.  979.]\n",
      " pred labels train [1.0083e+03 4.1540e+02 1.0003e+00 1.0003e+00 5.2902e+02 1.0003e+00\n",
      " 7.7949e+02 8.0794e+01 9.9988e+02 9.9821e+02]\n",
      " all vars norms [272.85092, 0.5378051, 151.13348, 28.468178, 31.56906, 1.0002491]\n",
      "global_step 250325 , loss 9.152561\n",
      "global_step 250425 , loss 6.2561693\n",
      "global_step 250525 , loss 5.6087117\n",
      "global_step 250625 , loss 5.1880274\n",
      "global_step 250725 , loss 7.2408056\n",
      "global_step 250825 , loss 5.7887044\n",
      "global_step 250925 , loss 6.9338875\n",
      "global_step 251025 , loss 5.916646\n",
      "global_step 251125 , loss 9.193689\n",
      "global_step 251225 , loss 6.1967325\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  382.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   22.]]\n",
      " true labels train [615.  14.   1. 292.  33. 119. 100. 462. 611.  11.]\n",
      " pred labels train [623.5635  10.3459   1.     285.2909  24.6175 123.7798 103.161  462.7415\n",
      " 608.3975  10.238 ]\n",
      " all vars norms [273.23788, 0.5381473, 151.33846, 28.523487, 31.582327, 1.0000541]\n",
      "global_step 251325 , loss 6.7137375\n",
      "global_step 251425 , loss 7.158453\n",
      "global_step 251525 , loss 5.925574\n",
      "global_step 251625 , loss 6.248895\n",
      "global_step 251725 , loss 7.7738733\n",
      "global_step 251825 , loss 7.7959\n",
      "global_step 251925 , loss 8.017269\n",
      "global_step 252025 , loss 6.482992\n",
      "global_step 252125 , loss 6.950841\n",
      "global_step 252225 , loss 5.7381954\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  999.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  107.]]\n",
      " true labels train [1000.    1.    1.  194.   68.   13.  952.   19.  216.    1.]\n",
      " pred labels train [1.0107e+03 1.0000e+00 1.0000e+00 1.8563e+02 7.0693e+01 1.0722e+01\n",
      " 9.5598e+02 1.6477e+01 2.2884e+02 1.0000e+00]\n",
      " all vars norms [273.74542, 0.53825116, 151.59962, 28.556675, 31.62142, 1.0001028]\n",
      "global_step 252325 , loss 8.047052\n",
      "global_step 252425 , loss 8.235359\n",
      "global_step 252525 , loss 6.7840633\n",
      "global_step 252625 , loss 6.3813157\n",
      "global_step 252725 , loss 6.635807\n",
      "global_step 252825 , loss 6.167576\n",
      "global_step 252925 , loss 5.667863\n",
      "global_step 253025 , loss 5.91613\n",
      "global_step 253125 , loss 4.774457\n",
      "global_step 253225 , loss 8.575355\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  659.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  108.]]\n",
      " true labels train [ 351.  907.   10.    1.  420.    1.    1.  680.    1. 1000.]\n",
      " pred labels train [3.4500e+02 9.0289e+02 1.0009e+01 1.0000e+00 4.2672e+02 5.5794e+00\n",
      " 1.0000e+00 6.8266e+02 1.0000e+00 1.0182e+03]\n",
      " all vars norms [274.1431, 0.5379283, 151.80608, 28.609652, 31.640007, 1.0000311]\n",
      "global_step 253325 , loss 7.6197925\n",
      "global_step 253425 , loss 6.908782\n",
      "global_step 253525 , loss 6.523219\n",
      "global_step 253625 , loss 7.626021\n",
      "global_step 253725 , loss 5.331853\n",
      "global_step 253825 , loss 6.5321684\n",
      "global_step 253925 , loss 8.979467\n",
      "global_step 254025 , loss 6.7453775\n",
      "global_step 254125 , loss 6.271983\n",
      "INFO:tensorflow:global_step/sec: 350.387\n",
      "global_step 254225 , loss 8.269635\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  458.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   73.]]\n",
      " true labels train [  1.  78. 444. 119.  71.   1. 873. 100.   1. 533.]\n",
      " pred labels train [  1.0001  68.3614 446.6015 101.779   66.2472   1.0001 876.6656 103.7177\n",
      "   1.0001 538.3727]\n",
      " all vars norms [274.56808, 0.5387158, 152.03777, 28.654913, 31.656744, 1.0000414]\n",
      "global_step 254325 , loss 7.359805\n",
      "global_step 254425 , loss 6.267363\n",
      "global_step 254525 , loss 6.6454396\n",
      "global_step 254625 , loss 5.2342896\n",
      "global_step 254725 , loss 6.192141\n",
      "global_step 254825 , loss 5.4464097\n",
      "global_step 254925 , loss 6.1995044\n",
      "global_step 255025 , loss 6.788077\n",
      "global_step 255125 , loss 7.0960646\n",
      "global_step 255225 , loss 5.5597553\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  253.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  985.]]\n",
      " true labels train [   1.   10.  426.   12.   71.  255.    1. 1000.    1.  762.]\n",
      " pred labels train [ 1.0000e+00  1.0007e+01  4.3620e+02  2.1779e+01  6.0853e+01  2.6592e+02\n",
      "  1.0000e+00  1.0267e+03 -1.8658e+00  7.7272e+02]\n",
      " all vars norms [275.02924, 0.53834856, 152.27693, 28.699774, 31.692287, 0.9999111]\n",
      "global_step 255325 , loss 6.2688246\n",
      "global_step 255425 , loss 6.659947\n",
      "global_step 255525 , loss 6.9926424\n",
      "global_step 255625 , loss 6.155527\n",
      "global_step 255725 , loss 5.3733463\n",
      "global_step 255825 , loss 5.3494487\n",
      "global_step 255925 , loss 7.9153185\n",
      "global_step 256025 , loss 8.128953\n",
      "global_step 256125 , loss 9.907403\n",
      "global_step 256225 , loss 6.2068624\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  938.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  841.]]\n",
      " true labels train [  1. 178. 100.   1. 562.   1. 100.   1. 801. 804.]\n",
      " pred labels train [  1.     183.7764 107.8564   1.     581.2738   1.     100.7939   1.\n",
      " 810.4635 809.2106]\n",
      " all vars norms [275.44403, 0.5378928, 152.52686, 28.752754, 31.707727, 0.9999614]\n",
      "global_step 256325 , loss 7.5451865\n",
      "global_step 256425 , loss 6.8122497\n",
      "global_step 256525 , loss 7.1489906\n",
      "global_step 256625 , loss 5.8922977\n",
      "global_step 256725 , loss 6.9670563\n",
      "global_step 256825 , loss 5.644843\n",
      "global_step 256925 , loss 10.310034\n",
      "global_step 257025 , loss 5.1429825\n",
      "global_step 257125 , loss 6.1774025\n",
      "global_step 257225 , loss 5.7020936\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  163.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  336.]]\n",
      " true labels train [ 154. 1000.  197.    1. 1000.  934. 1000.  911.    1.  100.]\n",
      " pred labels train [1.5908e+02 1.0170e+03 2.0486e+02 1.0001e+00 1.0045e+03 9.1508e+02\n",
      " 1.0053e+03 9.1371e+02 1.0001e+00 9.9890e+01]\n",
      " all vars norms [275.85474, 0.538155, 152.76308, 28.80621, 31.715593, 1.0000387]\n",
      "global_step 257325 , loss 5.4932814\n",
      "global_step 257425 , loss 5.3475485\n",
      "global_step 257525 , loss 6.1477475\n",
      "global_step 257625 , loss 6.3821654\n",
      "global_step 257725 , loss 5.8115335\n",
      "global_step 257825 , loss 4.9081526\n",
      "global_step 257925 , loss 5.323266\n",
      "global_step 258025 , loss 6.125984\n",
      "global_step 258125 , loss 6.5544076\n",
      "global_step 258225 , loss 6.300314\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    1.    0.  826.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  623.]]\n",
      " true labels train [100. 629.  10.   1.   1. 629.   9.  15. 632.   1.]\n",
      " pred labels train [ 91.7495 626.4195   4.7913   1.       1.4505 625.1705   1.       9.9122\n",
      " 644.9795   1.    ]\n",
      " all vars norms [276.33334, 0.53824455, 153.012, 28.840101, 31.735477, 1.0000727]\n",
      "global_step 258325 , loss 5.1692405\n",
      "global_step 258425 , loss 6.8892336\n",
      "global_step 258525 , loss 6.591098\n",
      "global_step 258625 , loss 5.446814\n",
      "global_step 258725 , loss 6.8038726\n",
      "global_step 258825 , loss 5.7661753\n",
      "global_step 258925 , loss 8.830009\n",
      "global_step 259025 , loss 5.769725\n",
      "global_step 259125 , loss 6.4481664\n",
      "INFO:tensorflow:global_step/sec: 343.25\n",
      "global_step 259225 , loss 6.55642\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  140.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  576.]]\n",
      " true labels train [ 865.    1.    1.   10. 1000.   88.  525.  100.  999.    5.]\n",
      " pred labels train [868.382    3.6473   0.9999   8.7807 995.8871  76.942  507.4828  96.0426\n",
      " 996.8259   2.0086]\n",
      " all vars norms [276.80698, 0.5386666, 153.24184, 28.89151, 31.773355, 0.9998539]\n",
      "global_step 259325 , loss 7.2309837\n",
      "global_step 259425 , loss 7.3710866\n",
      "global_step 259525 , loss 6.768968\n",
      "global_step 259625 , loss 6.9553614\n",
      "global_step 259725 , loss 9.054632\n",
      "global_step 259825 , loss 6.919873\n",
      "global_step 259925 , loss 5.5400867\n",
      "global_step 260025 , loss 5.7094126\n",
      "global_step 260125 , loss 6.243651\n",
      "global_step 260225 , loss 7.0394044\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  588.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  122.]]\n",
      " true labels train [426. 142.  83.   1. 120.  10.  10.   7.   1. 907.]\n",
      " pred labels train [418.9409 145.361   91.8102   0.9999 113.4044   9.5488   9.5883   7.7979\n",
      "   0.9999 901.585 ]\n",
      " all vars norms [277.19855, 0.5381445, 153.50458, 28.936062, 31.81115, 0.999961]\n",
      "global_step 260325 , loss 6.6196766\n",
      "global_step 260425 , loss 5.8471956\n",
      "global_step 260525 , loss 5.042326\n",
      "global_step 260625 , loss 7.452659\n",
      "global_step 260725 , loss 8.266451\n",
      "global_step 260825 , loss 6.084041\n",
      "global_step 260925 , loss 6.9447107\n",
      "global_step 261025 , loss 6.2386675\n",
      "global_step 261125 , loss 8.669806\n",
      "global_step 261225 , loss 7.98055\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  341.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  519.]]\n",
      " true labels train [1000.  242.    1.   15.  292.  911.   12.  287.   10.  561.]\n",
      " pred labels train [997.8539   4.4337   1.0002  12.6988 294.588  907.5853  10.6196 300.3149\n",
      "   8.0396 574.2422]\n",
      " all vars norms [277.6453, 0.5383927, 153.70862, 28.986471, 31.840704, 1.0001144]\n",
      "global_step 261325 , loss 7.0184402\n",
      "global_step 261425 , loss 7.9384036\n",
      "global_step 261525 , loss 6.6300325\n",
      "global_step 261625 , loss 5.3420095\n",
      "global_step 261725 , loss 5.7226896\n",
      "global_step 261825 , loss 6.4004717\n",
      "global_step 261925 , loss 7.1460094\n",
      "global_step 262025 , loss 6.5141597\n",
      "global_step 262125 , loss 6.2100964\n",
      "global_step 262225 , loss 7.016593\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  583.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  836.]]\n",
      " true labels train [420.   1. 154. 847. 193.   1. 792. 108. 920.   1.]\n",
      " pred labels train [421.9887   1.0001 158.7833 846.5781 204.5092   3.9126 787.5442 108.2139\n",
      " 918.3426   1.0001]\n",
      " all vars norms [278.09824, 0.5384597, 153.97813, 29.024496, 31.84567, 0.999998]\n",
      "global_step 262325 , loss 6.4290314\n",
      "global_step 262425 , loss 8.039543\n",
      "global_step 262525 , loss 7.9314585\n",
      "global_step 262625 , loss 5.119042\n",
      "global_step 262725 , loss 6.524253\n",
      "global_step 262825 , loss 6.9653087\n",
      "global_step 262925 , loss 10.071487\n",
      "global_step 263025 , loss 6.502101\n",
      "global_step 263125 , loss 5.8035073\n",
      "global_step 263225 , loss 6.6735306\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   31.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  260.]]\n",
      " true labels train [  1.  12.  10.   1.  30.   1.  95. 980.  11. 479.]\n",
      " pred labels train [  0.9999  11.0493   8.0911   0.9999  32.0581   0.9999  92.5429 971.871\n",
      "  11.8979 483.8188]\n",
      " all vars norms [278.51163, 0.53802365, 154.21736, 29.057074, 31.87476, 0.99993527]\n",
      "global_step 263325 , loss 7.2986193\n",
      "global_step 263425 , loss 7.4652214\n",
      "global_step 263525 , loss 6.7862396\n",
      "global_step 263625 , loss 6.6126757\n",
      "global_step 263725 , loss 6.2384615\n",
      "global_step 263825 , loss 8.156158\n",
      "global_step 263925 , loss 9.153128\n",
      "global_step 264025 , loss 5.69374\n",
      "global_step 264125 , loss 6.3829727\n",
      "INFO:tensorflow:global_step/sec: 359.189\n",
      "global_step 264225 , loss 5.9705334\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  996.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    1.  607.]]\n",
      " true labels train [ 14. 100.  44.   1. 961.   1. 100.   1. 780.   7.]\n",
      " pred labels train [ 11.2499 100.2639  49.8553   1.0001 981.3643   1.0001 102.9656   1.0001\n",
      " 785.6623  11.1714]\n",
      " all vars norms [278.9626, 0.5383229, 154.43118, 29.101982, 31.903435, 0.9999555]\n",
      "global_step 264325 , loss 7.2413187\n",
      "global_step 264425 , loss 6.6253996\n",
      "global_step 264525 , loss 5.9509892\n",
      "global_step 264625 , loss 6.5762568\n",
      "global_step 264725 , loss 5.2000155\n",
      "global_step 264825 , loss 6.051162\n",
      "global_step 264925 , loss 7.1800222\n",
      "global_step 265025 , loss 5.2076993\n",
      "global_step 265125 , loss 7.509248\n",
      "global_step 265225 , loss 8.56887\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  489.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  856.]]\n",
      " true labels train [ 82.   1.  11.  10. 562. 100. 301. 194.   1. 222.]\n",
      " pred labels train [866.6244   1.      12.6403  17.8087 558.8899 101.0491 328.9279 184.3996\n",
      "   1.     245.175 ]\n",
      " all vars norms [279.39288, 0.53838825, 154.6511, 29.140373, 31.899786, 0.99993753]\n",
      "global_step 265325 , loss 4.8214107\n",
      "global_step 265425 , loss 5.9662914\n",
      "global_step 265525 , loss 6.8739624\n",
      "global_step 265625 , loss 8.09132\n",
      "global_step 265725 , loss 7.105288\n",
      "global_step 265825 , loss 7.412425\n",
      "global_step 265925 , loss 5.4635277\n",
      "global_step 266025 , loss 5.687524\n",
      "global_step 266125 , loss 6.249712\n",
      "global_step 266225 , loss 6.260908\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  252.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  246.]]\n",
      " true labels train [  1. 740.   9.   1. 100.  28. 329.  10.   1.   1.]\n",
      " pred labels train [  1.0002 738.9258  14.6518   1.0002  87.231   28.2432 295.0238   9.6021\n",
      "   1.0002  -8.7423]\n",
      " all vars norms [279.7985, 0.53837085, 154.86223, 29.19559, 31.92502, 1.0003282]\n",
      "global_step 266325 , loss 7.992709\n",
      "global_step 266425 , loss 7.832078\n",
      "global_step 266525 , loss 7.778269\n",
      "global_step 266625 , loss 6.9984236\n",
      "global_step 266725 , loss 5.032276\n",
      "global_step 266825 , loss 5.9049616\n",
      "global_step 266925 , loss 6.0527887\n",
      "global_step 267025 , loss 8.587013\n",
      "global_step 267125 , loss 5.128967\n",
      "global_step 267225 , loss 8.19767\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  981.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    1.    0.    0.   85.]]\n",
      " true labels train [   1.   14. 1000.  100.    7.   10.  283.    1.   10.   10.]\n",
      " pred labels train [9.9996e-01 1.5213e+01 1.0043e+03 1.0419e+02 1.0006e+01 9.9596e+00\n",
      " 2.6906e+02 4.2734e+00 1.0819e+01 1.1526e+01]\n",
      " all vars norms [280.26303, 0.5387791, 155.09158, 29.241022, 31.9503, 1.0000045]\n",
      "global_step 267325 , loss 5.552297\n",
      "global_step 267425 , loss 5.2024794\n",
      "global_step 267525 , loss 6.4464884\n",
      "global_step 267625 , loss 7.3406286\n",
      "global_step 267725 , loss 6.037327\n",
      "global_step 267825 , loss 5.0537214\n",
      "global_step 267925 , loss 7.110125\n",
      "global_step 268025 , loss 7.071328\n",
      "global_step 268125 , loss 6.1413164\n",
      "global_step 268225 , loss 5.896225\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    1.    0.  183.]\n",
      " [  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   46.]]\n",
      " true labels train [100.   1. 511.   7.   9.   1.  12.  91.  11. 292.]\n",
      " pred labels train [ 96.8406   1.     514.7849   4.0905  10.1634   1.      10.8511  92.228\n",
      "  10.3736 302.0224]\n",
      " all vars norms [280.7413, 0.5386744, 155.30684, 29.284992, 31.97302, 1.0000993]\n",
      "global_step 268325 , loss 8.038828\n",
      "global_step 268425 , loss 6.5434766\n",
      "global_step 268525 , loss 5.69771\n",
      "global_step 268625 , loss 5.9913855\n",
      "global_step 268725 , loss 4.8334527\n",
      "global_step 268825 , loss 8.545022\n",
      "global_step 268925 , loss 7.219298\n",
      "global_step 269025 , loss 5.330779\n",
      "global_step 269125 , loss 5.211761\n",
      "INFO:tensorflow:global_step/sec: 343.982\n",
      "global_step 269225 , loss 7.3711596\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  540.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    1.    0.    0.    0.   46.]]\n",
      " true labels train [459.  56.  15. 570.   1.   1.   1.  84.   2. 896.]\n",
      " pred labels train [461.8467  61.4485  20.8571 573.2507   1.       1.       1.      81.328\n",
      "   2.4063 887.1887]\n",
      " all vars norms [281.14798, 0.53829366, 155.5355, 29.331678, 31.986816, 1.0000399]\n",
      "global_step 269325 , loss 4.89586\n",
      "global_step 269425 , loss 7.398089\n",
      "global_step 269525 , loss 9.879965\n",
      "global_step 269625 , loss 7.2461166\n",
      "global_step 269725 , loss 7.797533\n",
      "global_step 269825 , loss 6.1304784\n",
      "global_step 269925 , loss 7.323577\n",
      "INFO:tensorflow:Saving checkpoints for 269962 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 270025 , loss 5.9579463\n",
      "global_step 270125 , loss 6.8005085\n",
      "global_step 270225 , loss 7.619087\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  929.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  773.]]\n",
      " true labels train [  1. 239.   1. 611.  12. 708.  10.  39.   1.   9.]\n",
      " pred labels train [  1.0001 210.7405   1.0001 593.3195  11.6891 709.8342  12.2807 107.6302\n",
      "   2.3787   9.6432]\n",
      " all vars norms [281.78836, 0.53866816, 155.76059, 29.36257, 32.00403, 0.9999559]\n",
      "global_step 270325 , loss 6.7118354\n",
      "global_step 270425 , loss 5.869077\n",
      "global_step 270525 , loss 5.396412\n",
      "global_step 270625 , loss 9.681594\n",
      "global_step 270725 , loss 7.7470675\n",
      "global_step 270825 , loss 6.868048\n",
      "global_step 270925 , loss 5.951256\n",
      "global_step 271025 , loss 6.5958047\n",
      "global_step 271125 , loss 5.154434\n",
      "global_step 271225 , loss 5.9831066\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  369.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  757.]]\n",
      " true labels train [  1.  12.   1.   1.  75.   1.  10. 100. 942.  80.]\n",
      " pred labels train [  1.701   11.6362   1.0001   1.6508  69.3982   1.0001  11.6828 102.0815\n",
      " 939.8117  81.2107]\n",
      " all vars norms [282.15582, 0.53827006, 155.99286, 29.407042, 32.016624, 1.0000496]\n",
      "global_step 271325 , loss 6.4031067\n",
      "global_step 271425 , loss 6.5906067\n",
      "global_step 271525 , loss 6.8509007\n",
      "global_step 271625 , loss 5.7996764\n",
      "global_step 271725 , loss 8.630731\n",
      "global_step 271825 , loss 5.637413\n",
      "global_step 271925 , loss 6.344885\n",
      "global_step 272025 , loss 6.7312593\n",
      "global_step 272125 , loss 7.5569735\n",
      "global_step 272225 , loss 9.04271\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    1.  857.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   56.]]\n",
      " true labels train [100.  68. 518. 725. 891. 192.  30.   1. 249. 100.]\n",
      " pred labels train [109.0829  66.4631 516.0696 739.5908 882.1384 193.2213  30.5834  29.3115\n",
      " 234.3784 101.4681]\n",
      " all vars norms [282.64328, 0.53876245, 156.23608, 29.447992, 32.04627, 0.99987715]\n",
      "global_step 272325 , loss 5.4877253\n",
      "global_step 272425 , loss 5.266608\n",
      "global_step 272525 , loss 5.482934\n",
      "global_step 272625 , loss 6.5993824\n",
      "global_step 272725 , loss 5.891609\n",
      "global_step 272825 , loss 6.5383306\n",
      "global_step 272925 , loss 5.438572\n",
      "global_step 273025 , loss 7.30569\n",
      "global_step 273125 , loss 6.0551653\n",
      "global_step 273225 , loss 6.2324677\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  851.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  749.]]\n",
      " true labels train [ 829.  748.  728.   15.  292.  423.    1.   17. 1000.   26.]\n",
      " pred labels train [8.4770e+02 7.5523e+02 7.3902e+02 1.0035e+01 2.8259e+02 4.4184e+02\n",
      " 1.0002e+00 1.8192e+01 1.0070e+03 2.3210e+01]\n",
      " all vars norms [283.06287, 0.5382902, 156.45067, 29.486935, 32.058407, 1.0002242]\n",
      "global_step 273325 , loss 6.229892\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-634f2379e263>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#     while True:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         _, loss_val, global_step_val, true_feat_train, true_labels_train, pred_labels_train = sess.run(\n\u001b[0;32m---> 25\u001b[0;31m             [train_step, loss, global_step,  feature_batch, label_batch, out])\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    544\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1023\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train.\n",
    "sess_args = {\n",
    "             'checkpoint_dir': os.getcwd(),\n",
    "             'save_checkpoint_secs': 60, \n",
    "             'save_summaries_secs': 15,\n",
    "             'log_step_count_steps': 5000,\n",
    "             'hooks': [tf.train.NanTensorHook(loss),\n",
    "                       tf.train.StopAtStepHook(last_step=2000000),\n",
    "#                       tf.train.LoggingTensorHook([global_step, loss], every_n_iter=500)\n",
    "                      ],\n",
    "            }\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "loss_vals = collections.deque(maxlen=40)\n",
    "i = 0\n",
    "with tf.train.MonitoredTrainingSession(**sess_args) as sess:\n",
    "    sess.run(iterator_init)\n",
    "    while not sess.should_stop():\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     running_test_loss = 0.0\n",
    "#     while True:\n",
    "        _, loss_val, global_step_val, true_feat_train, true_labels_train, pred_labels_train = sess.run(\n",
    "            [train_step, loss, global_step,  feature_batch, label_batch, out])\n",
    "\n",
    "        if i % 100 == 0:\n",
    "#             sess.run(test_iterator_init)\n",
    "#             test_loss_val, actual_labels, predicted_labels = sess.run([loss, label_batch, out])\n",
    "\n",
    "#             loss_vals.append(test_loss_val)\n",
    "#             avg_test_loss = np.mean(loss_vals)\n",
    "#             print('global_step', global_step_val, ', loss', loss_val, ', avg test loss', avg_test_loss)\n",
    "            print('global_step', global_step_val, ', loss', loss_val)\n",
    "            if i % 1000 == 0:\n",
    "#                 print(' true labels', actual_labels[:20].reshape(-1,))\n",
    "#                 print(' pred labels', predicted_labels[:20].reshape(-1,))\n",
    "                print(' true feats train', true_feat_train[:2])\n",
    "                print(' true labels train', true_labels_train[:10].reshape(-1,))\n",
    "                print(' pred labels train', pred_labels_train[:10].reshape(-1,))\n",
    "                print(' all vars norms', sess.run(all_vars_norms))\n",
    "        i += 1\n",
    "#         if i >= 10000:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
