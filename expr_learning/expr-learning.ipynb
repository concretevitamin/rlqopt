{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zongheng/anaconda/envs/ray-0321/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "# TODO(zongheng): visualization via tensorboard.\n",
    "# TODO(zongheng): print some prediction from test set\n",
    "\n",
    "dropout_keepprob = None\n",
    "\n",
    "# With gaussian weights.\n",
    "# 500 training pts; 1000 testing.\n",
    "PATH = \"5rel-10numAttrs-22totalAttrs-100maxTblSize-10buckets-3000.csv\"\n",
    "NUM_FIELDS = 34\n",
    "TRAIN_PATH = \"data/train-{}\".format(PATH)\n",
    "TEST_PATH = \"data/test-{}\".format(PATH)\n",
    "net = [64,64]; lr =  1e-3\n",
    "batch_size = 500\n",
    "num_steps = 5500\n",
    "\n",
    "# With 5 random op types.\n",
    "PATH = \"5rel-10numAttrs-28totalAttrs-100maxTblSize-10buckets-3000-1526330982.csv\"\n",
    "NUM_FIELDS = 40\n",
    "TRAIN_PATH = \"data/train-{}\".format(PATH)\n",
    "TEST_PATH = \"data/test-{}\".format(PATH)\n",
    "net = [128,128]; lr =  5e-3\n",
    "batch_size = 1024\n",
    "\n",
    "# 5 random op types.  Larger maxTblSize & buckets. \n",
    "PATH = \"5rel-10numAttrs-24totalAttrs-1000maxTblSize-100buckets-3000-1526336271.csv\"\n",
    "NUM_FIELDS = 36\n",
    "TRAIN_PATH = \"data/train-{}\".format(PATH)\n",
    "TEST_PATH = \"data/test-{}\".format(PATH)\n",
    "net = [128,128]; lr =  3e-3\n",
    "lr_bounds = [2000, 6000,]; lr_vals = [3e-3, 1e-3, 1e-4]\n",
    "batch_size = 512\n",
    "dropout_keepprob = 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1526336271\n",
    "no whitening, net = [128,128]; lr =  3e-3; batch_size = 512; dropout_keepprob = 0.9\n",
    "![sup](./1.png)\n",
    "lr_bounds = [2000, 6000,]; lr_vals = [3e-3, 1e-3, 5e-4]\n",
    "![inf](./2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tf.float32, tf.float32)\n",
      "(TensorShape([Dimension(None), Dimension(35)]), TensorShape([Dimension(None)]))\n",
      "(tf.float32, tf.float32)\n",
      "(TensorShape([Dimension(None), Dimension(35)]), TensorShape([Dimension(None)]))\n"
     ]
    }
   ],
   "source": [
    "def DatasetFromPath(pathname):\n",
    "    dataset = tf.data.TextLineDataset(pathname)\n",
    "\n",
    "    def ParseLine(line):\n",
    "        fields = tf.decode_csv(line, [[0.0]] * NUM_FIELDS)\n",
    "        # Last number is label.\n",
    "        return tf.reshape(tf.stack(fields[:-1]), [-1]), fields[-1]\n",
    "\n",
    "    def MeanCenterBatch(feat, lab):\n",
    "        feat_mean, feat_var = tf.nn.moments(feat, axes=[0])\n",
    "        lab_mean, lab_var = tf.nn.moments(lab, axes=[0])\n",
    "        feat = (feat - feat_mean) / (tf.sqrt(feat_var) + 1e-8)\n",
    "        lab = (lab - lab_mean) / (tf.sqrt(lab_var) + 1e-8)\n",
    "        return feat, lab\n",
    "    \n",
    "#     # K-point dataset, for sanity checking.\n",
    "#     K = 10\n",
    "#     dataset = dataset.take(K).map(ParseLine)\n",
    "#     dataset = dataset.shuffle(20000, reshuffle_each_iteration=False) \\\n",
    "#         .batch(K).map(MeanCenterBatch) \\\n",
    "#         .repeat()\n",
    "\n",
    "    dataset = dataset.cache().map(ParseLine)\n",
    "    dataset = dataset.shuffle(20000, reshuffle_each_iteration=True) \\\n",
    "        .repeat() \\\n",
    "        .batch(batch_size) #\\\n",
    "#         .map(MeanCenterBatch) \n",
    "\n",
    "    print(dataset.output_types)\n",
    "    print(dataset.output_shapes)\n",
    "    return dataset\n",
    "\n",
    "# Train.\n",
    "dataset = DatasetFromPath(TRAIN_PATH)\n",
    "iterator = tf.data.Iterator.from_structure(\n",
    "    dataset.output_types, dataset.output_shapes)\n",
    "iterator_init = iterator.make_initializer(dataset)\n",
    "# Test.\n",
    "test_dataset = DatasetFromPath(TEST_PATH)\n",
    "test_iterator_init = iterator.make_initializer(test_dataset)\n",
    "# Shared.\n",
    "feature_batch, label_batch = iterator.get_next()\n",
    "\n",
    "    \n",
    "\n",
    "# mean, var = tf.nn.moments(feature_batch, axes=[0])\n",
    "# feature_batch = (feature_batch - mean) / tf.sqrt(var)\n",
    "# mean, var = tf.nn.moments(label_batch, axes=[0])\n",
    "# label_batch = (label_batch - mean) / var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'learning_rate:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def manual_stepping(global_step, boundaries, rates):\n",
    "  \"\"\"Manually stepped learning rate schedule.\n",
    "\n",
    "  This function provides fine grained control over learning rates.  One must\n",
    "  specify a sequence of learning rates as well as a set of integer steps\n",
    "  at which the current learning rate must transition to the next.  For example,\n",
    "  if boundaries = [5, 10] and rates = [.1, .01, .001], then the learning\n",
    "  rate returned by this function is .1 for global_step=0,...,4, .01 for\n",
    "  global_step=5...9, and .001 for global_step=10 and onward.\n",
    "\n",
    "  Args:\n",
    "    global_step: int64 (scalar) tensor representing global step.\n",
    "    boundaries: a list of global steps at which to switch learning\n",
    "      rates.  This list is assumed to consist of increasing positive integers.\n",
    "    rates: a list of (float) learning rates corresponding to intervals between\n",
    "      the boundaries.  The length of this list must be exactly\n",
    "      len(boundaries) + 1.\n",
    "\n",
    "  Returns:\n",
    "    a (scalar) float tensor representing learning rate\n",
    "  Raises:\n",
    "    ValueError: if one of the following checks fails:\n",
    "      1. boundaries is a strictly increasing list of positive integers\n",
    "      2. len(rates) == len(boundaries) + 1\n",
    "  \"\"\"\n",
    "  if any([b < 0 for b in boundaries]) or any(\n",
    "      [not isinstance(b, int) for b in boundaries]):\n",
    "    raise ValueError('boundaries must be a list of positive integers')\n",
    "  if any([bnext <= b for bnext, b in zip(boundaries[1:], boundaries[:-1])]):\n",
    "    raise ValueError('Entries in boundaries must be strictly increasing.')\n",
    "  if any([not isinstance(r, float) for r in rates]):\n",
    "    raise ValueError('Learning rates must be floats')\n",
    "  if len(rates) != len(boundaries) + 1:\n",
    "    raise ValueError('Number of provided learning rates must exceed '\n",
    "                     'number of boundary points by exactly 1.')\n",
    "  step_boundaries = tf.constant(boundaries, tf.int64)\n",
    "  learning_rates = tf.constant(rates, tf.float32)\n",
    "  unreached_boundaries = tf.reshape(\n",
    "      tf.where(tf.greater(step_boundaries, global_step)), [-1])\n",
    "  unreached_boundaries = tf.concat([unreached_boundaries, [len(boundaries)]], 0)\n",
    "  index = tf.reshape(tf.reduce_min(unreached_boundaries), [1])\n",
    "  return tf.reshape(tf.slice(learning_rates, index, [1]), [])\n",
    "\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "lr = manual_stepping(global_step, lr_bounds, lr_vals)\n",
    "\n",
    "lr = tf.train.exponential_decay(learning_rate=1e-3, \n",
    "                                global_step=global_step, \n",
    "                                decay_steps=5000, \n",
    "                                decay_rate=0.9, \n",
    "                                staircase=True)\n",
    "lr = 1e-3\n",
    "tf.summary.scalar('learning_rate', lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zongheng/anaconda/envs/ray-0321/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "out Tensor(\"dense_2/BiasAdd:0\", shape=(?, 1), dtype=float32) label_batch Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=float32)\n",
      "INFO:tensorflow:Summary name Train Loss is illegal; using Train_Loss instead.\n",
      "INFO:tensorflow:Summary name dense/kernel:0 is illegal; using dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense/bias:0 is illegal; using dense/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0 is illegal; using dense_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0 is illegal; using dense_2/bias_0 instead.\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Graph definition.\n",
    "dense = feature_batch\n",
    "for i in range(len(net)):\n",
    "    dense = tf.layers.dense(\n",
    "        dense,\n",
    "        net[i],\n",
    "#         kernel_initializer=tf.truncated_normal_initializer(stddev=20.0),\n",
    "#         kernel_initializer=tf.initializers.variance_scaling(scale=10.0),\n",
    "        kernel_initializer=tf.initializers.variance_scaling(),\n",
    "#         kernel_initializer=tf.initializers.orthogonal(),\n",
    "#         kernel_initializer=tf.initializers.uniform_unit_scaling(),\n",
    "#         kernel_initializer=tf.initializers.random_normal(stddev=10),\n",
    "#         kernel_initializer=tf.initializers.random_uniform(-100, 100),\n",
    "#         kernel_initializer=tf.initializers.zeros(),\n",
    "#         bias_initializer=tf.initializers.zeros(),\n",
    "#         activation=tf.nn.sigmoid,\n",
    "        activation=tf.nn.relu,\n",
    "#         activation=tf.nn.tanh,\n",
    "    )\n",
    "    if dropout_keepprob is not None:\n",
    "        dense = tf.nn.dropout(dense, dropout_keepprob, seed=1234)\n",
    "out = tf.layers.dense(\n",
    "    dense,\n",
    "    1,\n",
    "#         kernel_initializer=tf.truncated_normal_initializer(stddev=20.0),\n",
    "#         kernel_initializer=tf.initializers.variance_scaling(scale=10.0),\n",
    "#         kernel_initializer=tf.initializers.orthogonal(),\n",
    "#         kernel_initializer=tf.initializers.uniform_unit_scaling(),\n",
    "#         kernel_initializer=tf.initializers.random_normal(stddev=10),\n",
    "        kernel_initializer=tf.initializers.variance_scaling(),\n",
    "#         kernel_initializer=tf.initializers.random_uniform(-100, 100),\n",
    "#         kernel_initializer=tf.initializers.zeros(),\n",
    "#         bias_initializer=tf.initializers.zeros(),\n",
    ")\n",
    "\n",
    "\n",
    "all_vars = tf.trainable_variables()\n",
    "regularizer = tf.contrib.layers.l1_regularizer(scale=0.0)  # TODO: scale=?\n",
    "# regularizer = tf.contrib.layers.l1_l2_regularizer()\n",
    "regularization_penalty = tf.contrib.layers.apply_regularization(\n",
    "    regularizer, all_vars)\n",
    "print('out', out, 'label_batch', label_batch)\n",
    "# NOTE: critical to reshape / or keep the order correct...\n",
    "# out: [B, 1]\n",
    "# label_batch [B]\n",
    "# loss = tf.reduce_mean(tf.square(out - label_batch))\n",
    "# loss = tf.reduce_mean(tf.square(out - label_batch)) \n",
    "loss = tf.reduce_mean(tf.abs(\n",
    "    tf.reshape(out,[-1]) - label_batch)) + regularization_penalty\n",
    "\n",
    "# loss = tf.reduce_mean(tf.abs(tf.reshape(out,[-1]) - label_batch))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train_step = optimizer.minimize(\n",
    "    loss, global_step=global_step)\n",
    "\n",
    "# For visualization.\n",
    "tf.summary.scalar('Train Loss', loss)\n",
    "for v in all_vars:\n",
    "    tf.summary.histogram(v.name, v)\n",
    "all_vars_norms = [tf.norm(v) for v in all_vars]\n",
    "print(len(all_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 1 , loss 323.02454\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  527.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  593.]]\n",
      " true labels train [ 532.  404.    1.  535.   14.    1.   30.  560. 1000.    9.]\n",
      " pred labels train [-127.7618  -16.0136 -115.4042  -63.1726  -35.4986  -21.5173  -72.7145\n",
      "  -77.908   -83.6564 -106.9639]\n",
      " all vars norms [9.98856, 0.008887818, 10.036998, 0.010580313, 0.87678003, 0.0009999997]\n",
      "global_step 101 , loss 236.20462\n",
      "global_step 201 , loss 267.07416\n",
      "global_step 301 , loss 253.91406\n",
      "global_step 401 , loss 250.95099\n",
      "global_step 501 , loss 247.84448\n",
      "global_step 601 , loss 244.24185\n",
      "global_step 701 , loss 236.23582\n",
      "global_step 801 , loss 238.91174\n",
      "global_step 901 , loss 240.28238\n",
      "global_step 1001 , loss 244.2555\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  172.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  963.]]\n",
      " true labels train [   1.   10.  100.  453. 1000.  603.    1.  100.  570.   16.]\n",
      " pred labels train [129.4875  13.2882  95.532  237.7402 156.0977 252.4852  95.6964 159.4137\n",
      " 252.7449  37.8117]\n",
      " all vars norms [48.234932, 0.3821042, 11.781275, 0.16925135, 1.1414877, 0.016297435]\n",
      "global_step 1101 , loss 200.77069\n",
      "global_step 1201 , loss 184.11154\n",
      "global_step 1301 , loss 166.82956\n",
      "INFO:tensorflow:Saving checkpoints for 1337 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 1401 , loss 154.33249\n",
      "global_step 1501 , loss 129.70197\n",
      "global_step 1601 , loss 144.06392\n",
      "global_step 1701 , loss 145.02826\n",
      "global_step 1801 , loss 131.44012\n",
      "global_step 1901 , loss 105.59564\n",
      "global_step 2001 , loss 104.41293\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    1.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  465.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    1.    0.    0.    0.  265.]]\n",
      " true labels train [  1.   1.   9. 624.  68. 867. 740. 353. 665.   1.]\n",
      " pred labels train [  1.0762   2.0493   6.5236 496.4966 183.2509 797.198  696.9074 444.7497\n",
      " 476.3601   7.3109]\n",
      " all vars norms [76.60777, 0.6588336, 20.057098, 0.8624808, 3.662273, 0.10005481]\n",
      "global_step 2101 , loss 80.412735\n",
      "global_step 2201 , loss 78.56752\n",
      "global_step 2301 , loss 59.568314\n",
      "global_step 2401 , loss 68.63611\n",
      "global_step 2501 , loss 59.375835\n",
      "global_step 2601 , loss 53.61508\n",
      "global_step 2701 , loss 47.953102\n",
      "INFO:tensorflow:Saving checkpoints for 2747 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 2801 , loss 52.27771\n",
      "global_step 2901 , loss 61.4927\n",
      "global_step 3001 , loss 46.933205\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    1.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  970.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  869.]]\n",
      " true labels train [ 980.    1.   14.   13.   11.    1. 1000.    1.  312.    1.]\n",
      " pred labels train [876.697   66.0489   6.9092   7.3853   8.9882  -3.2258 627.9464   4.7774\n",
      " 293.9189  17.3907]\n",
      " all vars norms [84.81064, 0.6875018, 24.213556, 1.8927524, 5.265327, 0.20417804]\n",
      "global_step 3101 , loss 47.95303\n",
      "global_step 3201 , loss 48.616573\n",
      "global_step 3301 , loss 45.07425\n",
      "global_step 3401 , loss 42.720814\n",
      "global_step 3501 , loss 46.86739\n",
      "global_step 3601 , loss 51.65291\n",
      "global_step 3701 , loss 42.085136\n",
      "global_step 3801 , loss 38.93258\n",
      "global_step 3901 , loss 44.43319\n",
      "global_step 4001 , loss 37.82669\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  730.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   27.]]\n",
      " true labels train [  1. 986. 100.  12.   2.  10.   1.   1. 233.   1.]\n",
      " pred labels train [  1.2437 703.2841 135.6147  16.805    4.5485  31.641    4.1524  15.4643\n",
      " 209.7442   3.0716]\n",
      " all vars norms [89.61858, 0.692355, 26.754984, 2.6556587, 5.921605, 0.30227673]\n",
      "global_step 4101 , loss 42.471382\n",
      "INFO:tensorflow:Saving checkpoints for 4155 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 4201 , loss 42.880947\n",
      "global_step 4301 , loss 37.379906\n",
      "global_step 4401 , loss 48.435913\n",
      "global_step 4501 , loss 44.850258\n",
      "global_step 4601 , loss 40.40145\n",
      "global_step 4701 , loss 35.61892\n",
      "global_step 4801 , loss 37.364758\n",
      "global_step 4901 , loss 34.44027\n",
      "INFO:tensorflow:global_step/sec: 23.1194\n",
      "global_step 5001 , loss 48.68952\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  392.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  469.]]\n",
      " true labels train [   1. 1000.    7.  732.   16.  100.    1.    1.  376.  965.]\n",
      " pred labels train [  1.8535 521.5554  12.5471 660.0016   8.544   91.494    4.4843   1.5\n",
      " 314.5349 739.5299]\n",
      " all vars norms [93.50971, 0.69355834, 28.811155, 3.3679416, 6.410191, 0.38660383]\n",
      "global_step 5101 , loss 35.670845\n",
      "global_step 5201 , loss 36.961773\n",
      "global_step 5301 , loss 36.6683\n",
      "global_step 5401 , loss 34.294876\n",
      "global_step 5501 , loss 31.089283\n",
      "INFO:tensorflow:Saving checkpoints for 5505 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 5601 , loss 32.51165\n",
      "global_step 5701 , loss 31.527082\n",
      "global_step 5801 , loss 29.096983\n",
      "global_step 5901 , loss 31.939444\n",
      "global_step 6001 , loss 36.350723\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    0.    0.    1.    0.   91.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    1.    0.    0.  178.]]\n",
      " true labels train [  95.    1.   16.  951.  518.   56. 1000.  691.  617.   10.]\n",
      " pred labels train [  48.3839   12.8046   16.6231  893.3393  552.5609   51.2605 1013.2768\n",
      "  724.7016  606.9442    5.7542]\n",
      " all vars norms [97.31867, 0.6919401, 30.703894, 3.9986007, 6.8544364, 0.4520923]\n",
      "global_step 6101 , loss 32.56665\n",
      "global_step 6201 , loss 32.779625\n",
      "global_step 6301 , loss 33.86277\n",
      "global_step 6401 , loss 37.92458\n",
      "global_step 6501 , loss 29.585531\n",
      "global_step 6601 , loss 31.663485\n",
      "global_step 6701 , loss 33.75659\n",
      "INFO:tensorflow:Saving checkpoints for 6789 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 6801 , loss 30.293526\n",
      "global_step 6901 , loss 31.819477\n",
      "global_step 7001 , loss 32.468742\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    7.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    0.    1.  857.]]\n",
      " true labels train [ 10. 100.  39. 382.  10. 413. 293. 242.  10.  11.]\n",
      " pred labels train [ 18.0623 115.8692  31.888  458.6246  20.8362 444.1347 354.1216   4.9712\n",
      "  15.6748  19.7575]\n",
      " all vars norms [101.24506, 0.69052905, 32.73197, 4.501158, 7.331631, 0.5102125]\n",
      "global_step 7101 , loss 28.102467\n",
      "global_step 7201 , loss 28.974094\n",
      "global_step 7301 , loss 32.281876\n",
      "global_step 7401 , loss 27.64354\n",
      "global_step 7501 , loss 25.625126\n",
      "global_step 7601 , loss 26.514801\n",
      "global_step 7701 , loss 30.258364\n",
      "global_step 7801 , loss 30.198835\n",
      "global_step 7901 , loss 25.212692\n",
      "global_step 8001 , loss 27.191153\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    1.    0.    0.    0.    0.    1.    0.  300.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   64.]]\n",
      " true labels train [100.  89. 335.  12. 384. 676.   1.  39.   1. 926.]\n",
      " pred labels train [1.0338e+02 7.8304e+01 2.8857e+02 6.7242e+00 4.3566e+02 6.9071e+02\n",
      " 1.4953e-01 4.2667e+01 3.3961e+00 9.1500e+02]\n",
      " all vars norms [104.76748, 0.68993026, 34.770065, 4.967188, 7.7761292, 0.57358336]\n",
      "INFO:tensorflow:Saving checkpoints for 8100 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 8101 , loss 30.921234\n",
      "global_step 8201 , loss 29.151882\n",
      "global_step 8301 , loss 25.863483\n",
      "global_step 8401 , loss 28.634392\n",
      "global_step 8501 , loss 27.886719\n",
      "global_step 8601 , loss 29.83416\n",
      "global_step 8701 , loss 30.308075\n",
      "global_step 8801 , loss 26.245235\n",
      "global_step 8901 , loss 29.090405\n",
      "global_step 9001 , loss 30.844856\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    1.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   11.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  588.]]\n",
      " true labels train [ 984.    9.    1.    9.   51. 1000.  302.   70.  394. 1000.]\n",
      " pred labels train [1109.5673   10.589    -1.4809    9.9624   52.8349  863.4227  311.3609\n",
      "   61.3382  403.2744 1156.2771]\n",
      " all vars norms [108.54121, 0.68895966, 37.080437, 5.393151, 8.245156, 0.638758]\n",
      "global_step 9101 , loss 27.373344\n",
      "global_step 9201 , loss 24.138763\n",
      "global_step 9301 , loss 34.040833\n",
      "global_step 9401 , loss 27.230349\n",
      "INFO:tensorflow:Saving checkpoints for 9474 into /Users/zongheng/Dropbox/workspace/riselab/rlqopt/expr_learning/model.ckpt.\n",
      "global_step 9501 , loss 29.441187\n",
      "global_step 9601 , loss 27.976927\n",
      "global_step 9701 , loss 27.206413\n",
      "global_step 9801 , loss 24.088215\n",
      "global_step 9901 , loss 30.960958\n",
      "INFO:tensorflow:global_step/sec: 21.9867\n",
      "global_step 10001 , loss 26.744871\n",
      " true feats train [[  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    1.    0.    0.    0.    0.    1.    0.    0.    0.    1.]\n",
      " [  10. 1000. 1000. 1000.  100.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  208.]]\n",
      " true labels train [ 100.  195.   95.   75.  362.    1.    1.    1.  982. 1000.]\n",
      " pred labels train [ 9.9537e+01  1.9065e+02  1.0292e+02  7.2495e+01  3.9217e+02  9.8781e-01\n",
      " -7.1406e-02  6.3322e+01  5.7477e+02  7.7563e+02]\n",
      " all vars norms [111.87214, 0.69032276, 39.39783, 5.7846365, 8.685113, 0.7095709]\n",
      "global_step 10101 , loss 29.313164\n",
      "global_step 10201 , loss 24.991798\n",
      "global_step 10301 , loss 24.956795\n",
      "global_step 10401 , loss 23.602226\n",
      "global_step 10501 , loss 27.876234\n"
     ]
    }
   ],
   "source": [
    "# Train.\n",
    "sess_args = {\n",
    "             'checkpoint_dir': os.getcwd(),\n",
    "             'save_checkpoint_secs': 60, \n",
    "             'save_summaries_secs': 15,\n",
    "             'log_step_count_steps': 5000,\n",
    "             'hooks': [tf.train.NanTensorHook(loss),\n",
    "                       tf.train.StopAtStepHook(last_step=2000000),\n",
    "#                       tf.train.LoggingTensorHook([global_step, loss], every_n_iter=500)\n",
    "                      ],\n",
    "            }\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "loss_vals = collections.deque(maxlen=40)\n",
    "i = 0\n",
    "with tf.train.MonitoredTrainingSession(**sess_args) as sess:\n",
    "    sess.run(iterator_init)\n",
    "    while not sess.should_stop():\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     running_test_loss = 0.0\n",
    "#     while True:\n",
    "        _, loss_val, global_step_val, true_feat_train, true_labels_train, pred_labels_train = sess.run(\n",
    "            [train_step, loss, global_step,  feature_batch, label_batch, out])\n",
    "\n",
    "        if i % 100 == 0:\n",
    "#             sess.run(test_iterator_init)\n",
    "#             test_loss_val, actual_labels, predicted_labels = sess.run([loss, label_batch, out])\n",
    "\n",
    "#             loss_vals.append(test_loss_val)\n",
    "#             avg_test_loss = np.mean(loss_vals)\n",
    "#             print('global_step', global_step_val, ', loss', loss_val, ', avg test loss', avg_test_loss)\n",
    "            print('global_step', global_step_val, ', loss', loss_val)\n",
    "            if i % 1000 == 0:\n",
    "#                 print(' true labels', actual_labels[:20].reshape(-1,))\n",
    "#                 print(' pred labels', predicted_labels[:20].reshape(-1,))\n",
    "                print(' true feats train', true_feat_train[:2])\n",
    "                print(' true labels train', true_labels_train[:10].reshape(-1,))\n",
    "                print(' pred labels train', pred_labels_train[:10].reshape(-1,))\n",
    "                print(' all vars norms', sess.run(all_vars_norms))\n",
    "        i += 1\n",
    "#         if i >= 10000:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
